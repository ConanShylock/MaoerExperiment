{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ad56ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--------开始时间： 2024-03-19 07:57:25.230949 -------------\n"
     ]
    }
   ],
   "source": [
    "# 对比算法 maoer_user_pay_pred_model_DNN\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, recall_score, precision_score, roc_curve, confusion_matrix\n",
    "from _collections import OrderedDict  # 导入 OrderedDict 来保持字典中键值对的顺序\n",
    "\n",
    "print('||--------开始时间：',datetime.datetime.now(),'-------------')\n",
    "# data input\n",
    "data_time_windows_list =['1101_1130','1115_1215','1201_1231','1215_0115']\n",
    "# data_time_windows = '0101_0131'\n",
    "# path = './Dataset/' + data_time_windows + '_user_pay_pred_feature_deal.csv'\n",
    "# dataset_spilt_path = './Dataset/' + data_time_windows + '_user_pay_pred_feature_spilt_BiLSTM.csv'\n",
    "# # output_weight_result_path = './Dataset/' + data_time_windows + '_user_pay_pred_result_weight.csv'\n",
    "# data_feature_continue_discrete_namelist_path = './Dataset/maoer_timewindows_continue_discrete_feature_column.csv'    # 连续与离散划分表\n",
    "\n",
    "# 参数设置\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "num_heads = 10\n",
    "feature_dim = 200\n",
    "max_history_len = 15\n",
    "num_experts = 3\n",
    "num_tasks = 2\n",
    "# 设置嵌入维度\n",
    "continue_embedding_dim = 200\n",
    "discrete_embedding_dim = 200\n",
    "lr = 0.1\n",
    "batch_size = 128\n",
    "threshold = 0.5\n",
    "\n",
    "\n",
    "# 获取时间窗内连续与离散特征名的列表\n",
    "def get_continue_discrete_feature_namelist(time_windows, datapath):\n",
    "    data = pd.read_csv(datapath)\n",
    "    time_windows_data = data[(data['DataSet'] == time_windows)]\n",
    "    user_history_pay_QOE_continue_column = eval([time_windows_data['QOE_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_CHONGHE_continue_column = eval([time_windows_data['CHONGHE_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_FUFEI_continue_column = eval([time_windows_data['FUFEI_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_QOE_discrete_column = eval([time_windows_data['QOE_discrete'].values.tolist()][0][0])\n",
    "    user_history_pay_CHONGHE_discrete_column = eval([time_windows_data['CHONGHE_discrete'].values.tolist()][0][0])\n",
    "    user_history_pay_FUFEI_discrete_column = eval([time_windows_data['FUFEI_discrete'].values.tolist()][0][0])\n",
    "\n",
    "\n",
    "    return user_history_pay_QOE_continue_column, user_history_pay_CHONGHE_continue_column,user_history_pay_FUFEI_continue_column,\\\n",
    "            user_history_pay_QOE_discrete_column,user_history_pay_CHONGHE_discrete_column,user_history_pay_FUFEI_discrete_column\n",
    "\n",
    "# # 获取时间窗内连续与离散特征名的列表\n",
    "# user_history_pay_QOE_continue_column, user_history_pay_CHONGHE_continue_column, \\\n",
    "#         user_history_pay_FUFEI_continue_column, user_history_pay_QOE_discrete_column,\\\n",
    "#         user_history_pay_CHONGHE_discrete_column, user_history_pay_FUFEI_discrete_column = get_continue_discrete_feature_namelist(data_time_windows, data_feature_continue_discrete_namelist_path)\n",
    "# user_feature_continue_column = []\n",
    "# user_feature_discrete_column = []\n",
    "\n",
    "# # total continue feature\n",
    "# total_continue_feature = user_feature_continue_column+user_history_pay_QOE_continue_column+user_history_pay_CHONGHE_continue_column+user_history_pay_FUFEI_continue_column\n",
    "# total_discrete_feature = user_feature_discrete_column+user_history_pay_QOE_discrete_column+user_history_pay_CHONGHE_discrete_column+user_history_pay_FUFEI_discrete_column\n",
    "# total_discrete_feature_add_D = user_feature_discrete_column+user_history_pay_QOE_discrete_column+user_history_pay_CHONGHE_discrete_column+user_history_pay_FUFEI_discrete_column\n",
    "# total_discrete_feature_add_D.append('user_in_drama_is_pay_for_drama_in_next_time')\n",
    "# D = 'user_in_drama_is_pay_for_drama_in_next_time'\n",
    "# tensor_dict_idx = ['pay_QOE_continue','pay_QOE_discrete','pay_CHONGHE_continue','pay_CHONGHE_discrete','pay_FUFEI_continue','pay_FUFEI_discrete','target_QOE_continue','target_QOE_discrete','target_CHONGHE_continue','target_CHONGHE_discrete','target_FUFEI_continue','target_FUFEI_discrete']\n",
    "# # print(len(user_history_pay_QOE_continue_column),len(user_history_pay_CHONGHE_continue_column),len(user_history_pay_FUFEI_continue_column))\n",
    "# # 形成对应需要的特征名称列表\n",
    "# feature_column_dict = {\n",
    "#     'total_continue_feature': total_continue_feature,\n",
    "#     'total_discrete_feature': total_discrete_feature,\n",
    "#     'D':D\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ebecf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.数据处理+划分训练、验证、测试集\n",
    "\n",
    "# 划分数据集 给定输出后固定结果 输出形式定为存储user_id 形成train_dataset,val_dataset,test_dataset\n",
    "def split_data_unique(input_file, output_file, train_ratio, val_ratio, test_ratio):\n",
    "    df = pd.read_csv(input_file)\n",
    "#     data = df[df.columns[0]].unique()  # 提取第一列数据并去重\n",
    "    data = np.arange(df.shape[0])  #一个从 0 到行数减 1 的整数数组\n",
    "\n",
    "    np.random.shuffle(data)  # 随机打乱数据\n",
    "    # 划分数据\n",
    "    total_len = len(data)\n",
    "    x_end = int(total_len * train_ratio)\n",
    "    y_end = x_end + int(total_len * val_ratio)\n",
    "    train_data = data[:x_end]\n",
    "    val_data = data[x_end:y_end]\n",
    "    test_data = data[y_end:]\n",
    "    # 存储结果是去重的user_id\n",
    "    result = {\n",
    "        'Train': train_data,\n",
    "        'Val': val_data,\n",
    "        'Test': test_data\n",
    "    }   \n",
    "    # 创建每个子集的DataFrame  \n",
    "    train_df = pd.DataFrame(train_data, columns=['Train'])\n",
    "    val_df = pd.DataFrame(val_data, columns=['Val'])\n",
    "    test_df = pd.DataFrame(test_data, columns=['Test'])\n",
    "    # 将每个DataFrame转换为一列Series  \n",
    "    train_series = train_df.iloc[:, 0]\n",
    "    val_series = val_df.iloc[:, 0]\n",
    "    test_series = test_df.iloc[:, 0]\n",
    "    # 为了确保所有Series有相同的长度，我们需要找到最大长度并截断较短的Series  \n",
    "    max_len = max(len(train_series), len(val_series), len(test_series))\n",
    "    train_series = train_series.reindex(range(max_len)).fillna(value=pd.NA)\n",
    "    val_series = val_series.reindex(range(max_len)).fillna(value=pd.NA)\n",
    "    test_series = test_series.reindex(range(max_len)).fillna(value=pd.NA)\n",
    "    # 创建一个新的DataFrame，将Series作为列  \n",
    "    combined_df = pd.DataFrame({\n",
    "        'Train': train_series,\n",
    "        'Val': val_series,\n",
    "        'Test': test_series\n",
    "    })\n",
    "    # 写入CSV文件，不包含索引和列名  \n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print('已输出划分数据集结果')\n",
    "\n",
    "# 数据预处理 将连续特征变离散特征 分桶 不处理user_id、sound_id、drama_id、time\n",
    "def data_pre_deal(input_path,continue_feature_list):\n",
    "    df = pd.read_csv(input_path)\n",
    "    deal_data_df = [] # 待修改********\n",
    "    # # 获取离散特征的类别数量，并存储为字典\n",
    "    # category_counts = {}\n",
    "    # for column in deal_data_df.columns:\n",
    "    #     unique_values = deal_data_df[column].nunique()  # 获取列的唯一值数量\n",
    "    #     category_counts[column] = unique_values\n",
    "    print('数据预处理结束')\n",
    "    return df\n",
    "\n",
    "# 根据划分好的数据集中user_id 找到对应csv文件中对应user_id的所有行数据取出，即包含了历史数据（付费+非付费）+目标数据（最后一次行为）\n",
    "# def find_data_by_list(user_list, intput_data_df, data_hash):\n",
    "#     df = intput_data_df\n",
    "#     # result_list = []\n",
    "#     # 遍历列表中的值，在CSV文件中找到所有匹配的行数据并加入结果列表\n",
    "#     for user_id in user_list:\n",
    "#         result_df = df[df[df.columns[0]] == user_id]\n",
    "#         # result_list.append(result_df)\n",
    "#         if user_id in data_hash:\n",
    "#             data_hash[user_id].update({col: result_df for col in df.columns})  # 使用列名作为键\n",
    "#         else:\n",
    "#             data_hash[user_id] = {col: result_df for col in df.columns}\n",
    "#     #result = pd.concat(result_list)  # 合并所有匹配的行数据\n",
    "#     return data_hash\n",
    "\n",
    "# 改过 根据 BiLSTM单独改的 根据下标获取数据\n",
    "def find_data_by_list(index_list, intput_data_df, data_hash):  \n",
    "    for index in index_list:  \n",
    "        index = int(index)\n",
    "        index_list = []\n",
    "        index_list.append(index)\n",
    "        result_df = intput_data_df.iloc[index_list]  \n",
    "        data_hash[index] = result_df  # 直接存储DataFrame对象  \n",
    "        if result_df.shape[0]==0:\n",
    "            print('result_df出现空')\n",
    "    return data_hash\n",
    "    \n",
    "# 获取列唯一值数量表，并对离散特征的值转化为从0开始的索引\n",
    "def get_unique_feature_num_and_discrete_valueChange(datadf,discrete_feature_column_list):\n",
    "    # 获取离散特征的类别数量，并存储为字典\n",
    "    feature_category_num_dict = {}\n",
    "    for column in datadf.columns:\n",
    "        unique_values_len = datadf[column].nunique()  # 获取列的唯一值数量\n",
    "        feature_category_num_dict[column] = unique_values_len\n",
    "        if column in discrete_feature_column_list:\n",
    "            unique_values = datadf[column].unique()\n",
    "            value_mapping_dict = {value: index for index, value in enumerate(unique_values) if\n",
    "                              value != -1 and value != '' and value is not None}\n",
    "            datadf[column] = datadf[column].map(value_mapping_dict)\n",
    "    return feature_category_num_dict,datadf\n",
    "\n",
    "# 总的特征输入，生成划分后数据集及其输入\n",
    "def data_input(data_time_windows, path, spilt_outpath, train_ratio, val_ratio, test_ratio, total_continue_feature):\n",
    "    dataset_path = path  # 待修改********\n",
    "    dataset_spilt_path = spilt_outpath  # 待修改********\n",
    "    if os.path.exists(dataset_spilt_path):  # 划分训练、验证、测试集\n",
    "        print(\"划分文件已存在，不再进行数据划分\")\n",
    "    else:\n",
    "        split_data_unique(dataset_path, dataset_spilt_path, train_ratio, val_ratio, test_ratio)\n",
    "    deal_data_df = data_pre_deal(dataset_path, total_continue_feature)  # 数据预处理\n",
    "    # 获取离散特征的类别数量，并存储为字典\n",
    "    feature_category_num_dict,deal_data_df  = get_unique_feature_num_and_discrete_valueChange(deal_data_df,total_discrete_feature)\n",
    "    # 读取划分文件的结果\n",
    "    spilt_data_df = pd.read_csv(dataset_spilt_path)\n",
    "    # 输出每一列数据为列表\n",
    "    train_list = spilt_data_df['Train'].tolist()\n",
    "    val_list = spilt_data_df['Val'].tolist()\n",
    "    test_list = spilt_data_df['Test'].tolist()\n",
    "    train_list = [x for x in train_list if not math.isnan(x)]\n",
    "    val_list = [x for x in val_list if not math.isnan(x)]\n",
    "    test_list = [x for x in test_list if not math.isnan(x)]\n",
    "    # print('训练集、验证集、测试集大小=', len(train_list),len(val_list),len(test_list))\n",
    "    # 根据划分好的生成以user_id为key的hash（特征集合）将最后一行看做目标数据\n",
    "    data_hash = {}  # 存成一个hash形式\n",
    "    find_data_by_list(train_list, deal_data_df, data_hash)\n",
    "    find_data_by_list(val_list, deal_data_df, data_hash)\n",
    "    find_data_by_list(test_list, deal_data_df, data_hash)\n",
    "    print('数据划分完成')\n",
    "    # print(feature_category_num_dict)\n",
    "    return train_list, val_list, test_list, data_hash, feature_category_num_dict\n",
    "\n",
    "# test\n",
    "# 数据集 train、val、test划分及总数据hash表(以user_id为key的存储对应对应行的hash表)及不同类特征数存储的字典\n",
    "# train_list, val_list, test_list, data_hash, feature_category_num_dict = data_input(data_time_windows, path,dataset_spilt_path, train_ratio, val_ratio, test_ratio, total_continue_feature)\n",
    "# print(data_hash[3617476])\n",
    "# print(feature_category_num_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "326ed936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 形成张量矩阵 目标特征为：（batch,1,feature_num; 用户历史行为特征为（batch,max_history_len(固定长度的历史记录数),feature_num）\n",
    "\n",
    "# mask 对用户历史行为长度的固定\n",
    "# 转换 history 列为长度为max_history_len的数组\n",
    "def process_history(history, max_history_len):\n",
    "    if len(history) >= max_history_len:\n",
    "        processed_history = history[-max_history_len:]\n",
    "    else:\n",
    "        processed_history = [-1] * (max_history_len - len(history)) + history\n",
    "    return processed_history\n",
    "# 将填充-1的位置标记为True\n",
    "def create_mask(history):\n",
    "    mask = [True if item == -1 else False for item in history]\n",
    "    return mask\n",
    "# 将历史行为记录处理为固定长度并进行mask\n",
    "def history_feature_mask(user_history_feature_index, data_matrix_user_history, max_history_len):\n",
    "    mask_history_feature_matrix = []\n",
    "    origin_history_feature_matrix = []\n",
    "    for feature_index in range(len(user_history_feature_index)):\n",
    "        feature_data = [data_row[feature_index] for data_row in data_matrix_user_history]  # 获取一列特征值\n",
    "        processed_feature_data = process_history(feature_data, max_history_len)  # 处理为固定长度 max_history_len\n",
    "        origin_history_feature_matrix.append(processed_feature_data)\n",
    "        mask_feature_data = create_mask(processed_feature_data)  # 将空的mask\n",
    "        mask_history_feature_matrix.append(mask_feature_data)\n",
    "        \n",
    "    # print('mask',len(origin_history_feature_matrix),len(origin_history_feature_matrix[0]))\n",
    "    return origin_history_feature_matrix, mask_history_feature_matrix\n",
    "# 将记录mask\n",
    "# def history_feature_mask(user_history_feature_index, data_matrix_user_history, max_history_len):\n",
    "#     mask_history_feature_matrix = []\n",
    "#     origin_history_feature_matrix = []\n",
    "#     for feature_index in range(len(user_history_feature_index)):\n",
    "#         feature_data = [data_row[feature_index] for data_row in data_matrix_user_history]  # 获取一列特征值\n",
    "#         origin_history_feature_matrix.append(feature_data)\n",
    "#         mask_feature_data = create_mask(feature_data)  # 将空的mask\n",
    "#         mask_history_feature_matrix.append(mask_feature_data)\n",
    "#         \n",
    "#     # print('mask',len(origin_history_feature_matrix),len(origin_history_feature_matrix[0]))\n",
    "#     return origin_history_feature_matrix, mask_history_feature_matrix\n",
    "\n",
    "# 将输入形成的data_hash和连续、离散特征列名,按照划分的训练或测试的user_id的列表，提取用户特征形成张量矩阵存储到data_tensor_hash中，以user_id为key，多个张量矩阵为value\n",
    "def get_feature_to_matrix(train_or_val_or_test_list, data_hash, feature_column_dict):\n",
    "    # 存储新的张量hash\n",
    "    data_tensor_hash = {}\n",
    "    # 存储历史记录的掩码矩阵\n",
    "    data_tensor_history_mask_hash = {}\n",
    "    target_label = []  # 预测目标值的标签\n",
    "\n",
    "    for user_id in train_or_val_or_test_list:\n",
    "        user_data = data_hash[user_id]\n",
    "        # 创建空的二维矩阵\n",
    "        data_matrix_history_continue = []\n",
    "        data_matrix_history_discrete = []\n",
    "        data_matrix_target_continue = []\n",
    "        data_matrix_target_discrete = []\n",
    "#         target_label = []\n",
    "        # 提取特征列对应的索引\n",
    "        # user_feature_continue_index = [user_data.columns.get_loc(col) for col in feature_column_dict['user_info_continue'] if col in user_data.columns]\n",
    "        # user_feature_discrete_index = [user_data.columns.get_loc(col) for col in feature_column_dict['user_info_discrete'] if\n",
    "        #                                col in user_data.columns]\n",
    "        total_continue_index = [user_data.columns.get_loc(col) for col in feature_column_dict['total_continue_feature'] if col in user_data.columns]\n",
    "        total_discrete_index = [user_data.columns.get_loc(col) for col in feature_column_dict['total_discrete_feature'] if col in user_data.columns]\n",
    "        D_index = [user_data.columns.get_loc(col) for col in feature_column_dict['D'] if col in user_data.columns]\n",
    "                \n",
    "        # 填充数据矩阵\n",
    "        for i in range(len(user_data)):\n",
    "            data_matrix_history_continue.append(\n",
    "                [user_data.iloc[i, col] for col in total_continue_index])  # 用户历史连续特征\n",
    "            data_matrix_history_discrete.append(\n",
    "                [user_data.iloc[i, col] for col in total_discrete_index])  # 用户历史离散特征\n",
    "            target_label.append(user_data.iloc[i, -1])  # 预测目标的y值\n",
    "\n",
    "        # 将numpy数组转换为PyTorch张量       \n",
    "        # history   得到的data_matrix_user_history及data_tensor_pay_QOE_continue维度是(feature_num,history_len)需要转成tensor后转置\n",
    "\n",
    "        data_tensor_history_continue = torch.tensor(np.array(data_matrix_history_continue), dtype=torch.float32)\n",
    "        data_tensor_history_discrete = torch.tensor(np.array(data_matrix_history_discrete), dtype=torch.float32)\n",
    "        data_label_tensor = torch.tensor(np.array(target_label), dtype=torch.float32)\n",
    "#         print('data_label_tensor',data_label_tensor.shape)\n",
    "\n",
    "#         data_tensor_history_continue = torch.transpose(torch.tensor(np.array(data_matrix_history_continue), dtype=torch.float32),0,1)\n",
    "#         data_tensor_history_discrete = torch.transpose(torch.tensor(np.array(data_matrix_history_discrete), dtype=torch.float32),0,1)\n",
    "#         data_tensor_history_continue_mask = []\n",
    "#         data_tensor_history_discrete_mask = []\n",
    "#         print('data_tensor_history_discrete',data_tensor_history_discrete.shape)\n",
    "        \n",
    "        # user + target   输出维度为（1，feature_num）,一处第一个为1的维度变为（feature_num）\n",
    "#         data_tensor_target_continue = torch.squeeze(torch.tensor(np.array(data_matrix_target_continue), dtype=torch.float32),dim=0)\n",
    "#         data_tensor_target_discrete = torch.squeeze(torch.tensor(np.array(data_matrix_target_discrete), dtype=torch.float32),dim=0)\n",
    "#         data_label_tensor = torch.squeeze(data_label_tensor,dim=0)\n",
    "#         print('data_label_tensor',data_label_tensor.shape)\n",
    "        \n",
    "        # 生成hash值，按user_id为key存储成hash\n",
    "        tensor_hash_value = {\n",
    "            'history_continue': data_tensor_history_continue,\n",
    "            'history_discrete': data_tensor_history_discrete,\n",
    "#             'target_continue': data_tensor_target_continue,\n",
    "#             'target_discrete': data_tensor_target_discrete,\n",
    "            'label': data_label_tensor\n",
    "\n",
    "        }\n",
    "#         tensor_hash_value_history_mask = {\n",
    "#             'history_continue': data_tensor_history_continue_mask,\n",
    "#             'history_discrete': data_tensor_history_discrete_mask,\n",
    "#         }\n",
    "        if user_id in data_tensor_hash:\n",
    "            data_tensor_hash[user_id].update(tensor_hash_value)\n",
    "#             data_tensor_history_mask_hash[user_id].update(tensor_hash_value_history_mask)\n",
    "        else:\n",
    "            data_tensor_hash[user_id] = tensor_hash_value\n",
    "#             data_tensor_history_mask_hash[user_id] = tensor_hash_value_history_mask\n",
    "    \n",
    "    # 如果需要合并成一个张量，可以使用torch.cat方法\n",
    "    # combined_tensor = torch.cat((data_matrix_1_tensor, data_matrix_2_tensor), dim=1)\n",
    "    # data_tensor_hash中用户历史的输出维度(max_history_len,feature_num)，目标的输出维度是（feature_num）\n",
    "    return data_tensor_hash, target_label\n",
    "\n",
    "\n",
    "# 张量矩阵添加一个batch维度，并在用户特征与目标特征的张量中再添加一维使其与用户历史行为张量对齐， 形成两种：\n",
    "# 原数据为：1.用户特征与目标特征都为：（1,feature_num）; 2.用户历史行为特征为（max_history_len(固定长度的历史记录数),feature_num）\n",
    "# 新数据为：1.用户特征与目标特征都为：（batch,1,1,feature_num); 2.用户历史行为特征为（batch,max_history_len(固定长度的历史记录数),feature_num）\n",
    "# 形成batch维度的特征\n",
    "def generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, feature_category,is_label = False):  # 例:feature_category = 'user_info_continue' 就是上面生成的tensor_hash_value字典的键\n",
    "    tensor_list = []\n",
    "#     batch_feature_tensor = None\n",
    "    for user_id in train_or_val_or_test_list:  # 遍历data_tensor_hash的所有key (user_id)\n",
    "        if feature_category in data_tensor_hash[user_id]:\n",
    "            tensor = data_tensor_hash[user_id][feature_category]  # 获取feature_category对应的张量\n",
    "            tensor_list.append(tensor)  # 添加到tensor_list中\n",
    "    if is_label:\n",
    "        batch_feature_tensor = tensor_list[-1]\n",
    "    else:\n",
    "        batch_feature_tensor = torch.stack(tensor_list, dim=0)  # 在第一个维度上合并所有张量(其实相当于生成一个新维度)\n",
    "    return batch_feature_tensor\n",
    "# 生成batch再添加维度对齐张量（三个维度）\n",
    "def generate_user_feature_alignment_tensor(train_or_val_or_test_list,data_tensor_hash,is_mask=False):\n",
    "    # 用户历史行为矩阵（max_history_len(固定长度的历史记录数),feature_num）->（batch,max_history_len(固定长度的历史记录数),feature_num）\n",
    "    history_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'history_continue')\n",
    "    history_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'history_discrete')\n",
    "    table_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'label',is_label = True)\n",
    "    # 看是否是掩码矩阵，不是则xxx，是则没有user+target\n",
    "#     if is_mask==False:\n",
    "#         # 用户矩阵 (feature_num) ->(batch,feature_num)\n",
    "#         # user_info_continue_batch_feature_tensor = generate_batch_feature(data_tensor_hash, 'user_info_continue')\n",
    "#         # user_info_discrete_batch_feature_tensor = generate_batch_feature(data_tensor_hash, 'user_info_discrete')\n",
    "#         # 目标矩阵 (feature_num) ->(batch,feature_num)\n",
    "#         target_continue_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'target_continue')\n",
    "#         target_discrete_batch_feature_tensor = generate_batch_feature(train_or_val_or_test_list,data_tensor_hash, 'target_discrete')\n",
    "\n",
    "#         # 假设原始张量矩阵为 tensor，形状为 (batch_size, feature_num)将其加一个维度变为 (batch_size, 1, feature_num)\n",
    "#         # user_info_continue_batch_feature_tensor = torch.unsqueeze(user_info_continue_batch_feature_tensor, dim=1)\n",
    "#         # user_info_discrete_batch_feature_tensor = torch.unsqueeze(user_info_discrete_batch_feature_tensor, dim=1)\n",
    "#         target_continue_batch_feature_tensor = torch.unsqueeze(target_continue_batch_feature_tensor, dim=1)\n",
    "#         target_discrete_batch_feature_tensor = torch.unsqueeze(target_discrete_batch_feature_tensor, dim=1)\n",
    "\n",
    "#         batch_feature_tensor_dict = {\n",
    "#             'history_discrete': history_discrete_batch_feature_tensor,\n",
    "#             'history_continue': history_continue_batch_feature_tensor,\n",
    "#             'target_discrete': target_discrete_batch_feature_tensor,     \n",
    "#             'target_continue': target_continue_batch_feature_tensor,\n",
    "#         }\n",
    "#     else:\n",
    "    batch_feature_tensor_dict = {\n",
    "        'history_discrete': history_discrete_batch_feature_tensor,\n",
    "        'history_continue': history_continue_batch_feature_tensor,\n",
    "        'label':table_tensor\n",
    "    }\n",
    "    return batch_feature_tensor_dict  # 这里张量输出的全是三维 (batch_size, 1 or max_history_len, feature_num)\n",
    "\n",
    "\n",
    "# 由于模型输入得是张量，因此在之前将字典转化为了张量，现在将它转换回去\n",
    "class TensorDatasettoDict(Dataset):\n",
    "    def __init__(self, dataset, keys):\n",
    "        self.dataset = dataset\n",
    "        self.keys = keys\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        sample = {key: data[i] for i, key in enumerate(self.keys)}\n",
    "        return sample\n",
    "\n",
    "# test\n",
    "# 获取训练、验证、测试集对应的数据形成的向量hash存储及label\n",
    "# print(data_hash[3617476])\n",
    "# train_data_tensor_hash, train_label, train_data_tensor_hash_history_mask = get_feature_to_matrix(train_list, data_hash, feature_column_dict)\n",
    "# first_key = list(train_data_tensor_hash.keys())[0]\n",
    "# print(train_data_tensor_hash[first_key]['pay_QOE_discrete'][:,0])\n",
    "# print(train_label)\n",
    "# # print(train_data_tensor_hash[3617476])\n",
    "# dimensions1 = train_data_tensor_hash[3617476]['pay_QOE_continue'].size()\n",
    "# dimensions2 = train_data_tensor_hash[3617476]['pay_QOE_discrete'].size()\n",
    "# dimensions3 = train_data_tensor_hash[3617476]['pay_CHONGHE_continue'].size()\n",
    "# dimensions4 = train_data_tensor_hash[3617476]['target_QOE_continue'].size()\n",
    "# dimensions5 = train_data_tensor_hash[3617476]['target_QOE_discrete'].size()\n",
    "# dimensions6 = train_data_tensor_hash[3617476]['target_CHONGHE_continue'].size()\n",
    "# print(\"PyTorch张量的维度：\", dimensions1,dimensions2,dimensions3,dimensions4,dimensions5,dimensions6)\n",
    "# train_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(train_list,train_data_tensor_hash)\n",
    "# train_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(train_data_tensor_hash_history_mask,is_mask=True)\n",
    "# print(train_batch_feature_tensor_dict['pay_QOE_discrete'][0,:,0])\n",
    "# dimensions1 = train_data_tensor_hash[3617476]['pay_QOE_continue'].size()\n",
    "# dimensions2 = train_data_tensor_hash[3617476]['pay_QOE_discrete'].size()\n",
    "# dimensions3 = train_data_tensor_hash[3617476]['pay_CHONGHE_continue'].size()\n",
    "# dimensions4 = train_data_tensor_hash[3617476]['target_QOE_continue'].size()\n",
    "# dimensions5 = train_data_tensor_hash[3617476]['target_QOE_discrete'].size()\n",
    "# dimensions6 = train_data_tensor_hash[3617476]['target_CHONGHE_continue'].size()\n",
    "# print(\"PyTorch添加batch后张量的维度：\", dimensions1,dimensions2,dimensions3,dimensions4,dimensions5,dimensions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f1f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.基础模型 embedding、attention\n",
    "# 构建离散特征的embedding\n",
    "def discrete_embedding(feature_category_num_dict, feature_column_name_list, embedding_dim): # 输入特征取值大小的集合,特征数,维度\n",
    "    # 创建一个列表来存储每个嵌入层\n",
    "    embeddings = []\n",
    "    for i in range(0, len(feature_column_name_list)):\n",
    "        # print(feature_column_name_list[i], feature_category_num_dict[feature_column_name_list[i]])\n",
    "        embedding_layer1 = nn.Embedding(feature_category_num_dict[feature_column_name_list[i]]+2, embedding_dim)\n",
    "        embeddings.append(embedding_layer1)\n",
    "    #     print('embedding维度',feature_category_num_dict[feature_column_name_list[i]]+1)\n",
    "    # print('本轮embedding层：',len(feature_column_name_list))\n",
    "    return embeddings\n",
    "\n",
    "# 全连接层 MLP\n",
    "def dense_layer(in_features, out_features):\n",
    "    # in_features=hidden_size,out_features=1\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features, bias=True),\n",
    "        nn.ReLU())\n",
    "# 全连接层 MLP\n",
    "def dense_layer_noReLu(in_features, out_features):\n",
    "    # in_features=hidden_size,out_features=1\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features, bias=True))\n",
    "\n",
    "# 连续特征离散化\n",
    "def continuous_embedding(num_continuous_features, out_features):\n",
    "    continuous_embedding_layers = []\n",
    "    for i in range(0,len(num_continuous_features)):\n",
    "        num_continuous_feature = num_continuous_features[i]\n",
    "        embedding_layer = dense_layer(1, out_features)\n",
    "        continuous_embedding_layers.append(embedding_layer)\n",
    "    return continuous_embedding_layers\n",
    "\n",
    "# 根据全特征数量表及类别，得到类别下的对应特征数量  feature_column_name_list = feature_column_dict['user_info_continue']\n",
    "def category_feature_num(feature_category_num_dict, feature_column_name_list):\n",
    "    category_feature_num_list = []\n",
    "    for i in range(len(feature_column_name_list)):\n",
    "        category_feature_num_list.append(feature_category_num_dict[feature_column_name_list[i]])\n",
    "    # print('category_feature_num',len(category_feature_num_list))\n",
    "    return category_feature_num_list \n",
    "\n",
    "# SE层中找到合适的reduction使channel // reduction得到整数\n",
    "def find_reduction(channel, min_reduction=2, max_reduction=19):  \n",
    "    # 对于质数，直接取自己作为reduction  \n",
    "    if is_prime(channel):  \n",
    "        return channel  \n",
    "      \n",
    "    # 计算介于min_reduction和max_reduction之间的候选reduction值  \n",
    "    candidates = [i for i in range(min_reduction, max_reduction + 1) if channel % i == 0]  \n",
    "      \n",
    "    # 如果候选列表为空，则至少取2作为reduction  \n",
    "    if not candidates:  \n",
    "        return min_reduction  \n",
    "      \n",
    "    # 尝试找到最大的候选值，使得channel // reduction的结果尽可能大  \n",
    "    reduction = max(candidates)  \n",
    "      \n",
    "    return reduction  \n",
    "def is_prime(n):  \n",
    "    \"\"\"判断一个数是否为质数\"\"\"  \n",
    "    if n < 2:  \n",
    "        return False  \n",
    "    for i in range(2, int(math.sqrt(n)) + 1):  \n",
    "        if n % i == 0:  \n",
    "            return False  \n",
    "    return True  \n",
    "    \n",
    "# 输入(batch,feature_num,embedding_dim,1) ->(batch,feature_num,embedding_dim,1)->输出特征权重及权重乘后的(batch,embedding_dim) \n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.reduction = reduction\n",
    "        self.reduction = find_reduction(channel)\n",
    "        self.fc = nn.Sequential(       \n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        # print('b, c, h, w',b, c, h, w)\n",
    "        y = self.avg_pool(x).view(b, c)   \n",
    "        # print('y',y)\n",
    "        weight = self.fc(y).view(b, c, 1, 1)\n",
    "        new_x = x * weight.expand_as(x)  # 利用了 PyTorch 的广播机制，使得张量 weight 被复制成与输入 x 相同的形状，然后进行逐元素相乘 \n",
    "        # 加权平均 (batch, embedding_dim)\n",
    "        weighted_avg_out_x = new_x.mean(dim=1, keepdim=True)  # 在 feature_num维度上取平均，保持维度\n",
    "        # 调整维度\n",
    "        weighted_avg_out_x = weighted_avg_out_x.view(b, 1, h, w)\n",
    "        # 去除最后一维\n",
    "        new_x = new_x.squeeze(dim=3)\n",
    "        weighted_avg_out_x = weighted_avg_out_x.squeeze(dim=3)\n",
    "        \n",
    "        return  weight, weighted_avg_out_x,new_x\n",
    "   \n",
    "    # 多头自注意力\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, num_heads, feature_dim, max_history_len):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads  #10\n",
    "        self.feature_dim = feature_dim   #200\n",
    "        self.head_dim = feature_dim // num_heads\n",
    "        self.max_history_len = max_history_len\n",
    "\n",
    "        self.WQ = nn.Linear(feature_dim, feature_dim)\n",
    "        self.WK = nn.Linear(feature_dim, feature_dim)\n",
    "        self.WV = nn.Linear(feature_dim, feature_dim)\n",
    "\n",
    "    def forward(self, history_matrix, mask=None):\n",
    "        batch_size, history_len, _ = history_matrix.size()\n",
    "\n",
    "        Q = self.WQ(history_matrix)\n",
    "        K = self.WK(history_matrix)\n",
    "        V = self.WV(history_matrix)\n",
    "\n",
    "        Q = Q.view(batch_size, history_len, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  #(batch,num_heads,history_len,head_dim)\n",
    "        K = K.view(batch_size, history_len, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, history_len, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        attention_scores = torch.matmul(Q, K.permute(0, 1, 3, 2)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.permute(0, 2, 1)  # 二、三维度互换  变为(batch, feature_num, history)\n",
    "            temp_dim=mask.shape[1]\n",
    "            #（样本数*特征数,历史数）\n",
    "            mask=mask.reshape(-1,max_history_len)\n",
    "            attention_scores = attention_scores.masked_fill(mask.unsqueeze(1).unsqueeze(2).bool(), float('-inf'))  #()\n",
    "\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)  #shape(batch,head,history_len,history_len)\n",
    "        #(batch,history_len,200)\n",
    "        weighted_sum = torch.matmul(attention_weights, V).permute(0, 2, 1, 3).contiguous().view(batch_size, history_len,\n",
    "                                                                                                self.feature_dim)\n",
    "        # 计算加权平均\n",
    "        weighted_avg_out = weighted_sum.mean(dim=1, keepdim=True)  # 在 history_len 维度上取平均，保持维度\n",
    "        # 调整维度\n",
    "        weighted_avg_out = weighted_avg_out.view(batch_size, 1,self.feature_dim)\n",
    "        # print('weighted_sum',weighted_avg_out.shape)\n",
    "        \n",
    "        return attention_weights, weighted_avg_out, weighted_sum\n",
    "\n",
    "# 注意力机制 关于用\n",
    "class MultiHeadHistory_TargetAttention(nn.Module):\n",
    "    def __init__(self, num_heads, embed_dim, dropout=0.1):\n",
    "        super(MultiHeadHistory_TargetAttention, self).__init__()\n",
    "        \n",
    "        assert embed_dim % num_heads == 0, f\"Embedding dimension ({embed_dim}) should be divisible by the number of heads ({num_heads}).\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        # 定义权重矩阵\n",
    "        self.q_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.scaling = self.head_dim ** -0.5\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None):\n",
    "        batch_size = query.size(0)       \n",
    "        # 进行线性投影并分离成多个头\n",
    "        q = self.q_linear(query).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.k_linear(key).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_linear(value).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        # 计算注意力得分\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scaling\n",
    "        if attn_mask is not None:\n",
    "            scores.masked_fill_(attn_mask.unsqueeze(1), float('-inf'))\n",
    "        # 应用softmax函数\n",
    "        attn_weights = self.softmax(scores)\n",
    "        # 应用dropout\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        # 进行值的加权求和\n",
    "        context = torch.matmul(attn_weights, v).transpose(1, 2).contiguous().view(batch_size, -1, self.embed_dim)\n",
    "        # 输出层的线性变换\n",
    "        output = self.out_proj(context)\n",
    "        return attn_weights, output\n",
    "\n",
    "# BiLSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class BiLSTMWithBatchNorm(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):  \n",
    "        super(BiLSTMWithBatchNorm, self).__init__()  \n",
    "          \n",
    "        self.hidden_dim = hidden_dim  \n",
    "        self.num_layers = num_layers  \n",
    "          \n",
    "        # 定义BiLSTM层，使用nn.ModuleList来容纳多个层  \n",
    "        self.lstm_layers = nn.ModuleList([  \n",
    "            nn.LSTM(input_dim if i == 0 else hidden_dim * 2, hidden_dim, 1, batch_first=True, bidirectional=True)  \n",
    "            for i in range(num_layers)  \n",
    "        ])  \n",
    "          \n",
    "        # 定义BatchNorm层，与LSTM层数量相同  \n",
    "        self.batch_norm_layers = nn.ModuleList([  \n",
    "            nn.BatchNorm1d(hidden_dim * 2)  \n",
    "            for _ in range(num_layers)  \n",
    "        ])  \n",
    "          \n",
    "        # 全连接层  \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  \n",
    "        \n",
    "    def forward(self, x):  \n",
    "        # 初始化所有层的隐藏状态和细胞状态  \n",
    "        # 注意这里使用列表来存储每一层的隐藏状态和细胞状态  \n",
    "        h0 = [torch.zeros(2, x.size(0), self.hidden_dim).to(x.device) for _ in range(self.num_layers)]  \n",
    "        c0 = [torch.zeros(2, x.size(0), self.hidden_dim).to(x.device) for _ in range(self.num_layers)]  \n",
    "\n",
    "        # 遍历每一层LSTM  \n",
    "        for i, (lstm_layer, batch_norm_layer) in enumerate(zip(self.lstm_layers, self.batch_norm_layers)):  \n",
    "            # LSTM前向传播  \n",
    "            # 注意这里使用h0[i]和c0[i]作为当前层的初始隐藏状态和细胞状态  \n",
    "            out, (hn, cn) = lstm_layer(x, (h0[i], c0[i]))  \n",
    "            # 应用批量标准化  \n",
    "            out = batch_norm_layer(out.transpose(1, 2)).transpose(1, 2)  \n",
    "            # 更新x为当前层的输出，用于下一层的输入  \n",
    "            x = out  \n",
    "            # 更新当前层的隐藏状态和细胞状态，用于下一层  \n",
    "            h0[i] = hn  \n",
    "            c0[i] = cn  \n",
    "\n",
    "        # 取最后一个时间步的输出，注意此时out已经是最后一层的输出  \n",
    "        out = out[:, -1, :]  \n",
    "        # 全连接层  \n",
    "        out = self.fc(out)  \n",
    "\n",
    "        return out     \n",
    "#     def forward(self, x):  \n",
    "#         # 初始化隐藏状态和细胞状态  \n",
    "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim * 2).to(x.device)  \n",
    "#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim * 2).to(x.device)  \n",
    "          \n",
    "#         # 遍历每一层LSTM  \n",
    "#         for lstm_layer, batch_norm_layer in zip(self.lstm_layers, self.batch_norm_layers):  \n",
    "#             # LSTM前向传播  \n",
    "#             out, (hn, cn) = lstm_layer(x, (h0, c0))  \n",
    "#             # 应用批量标准化  \n",
    "#             out = batch_norm_layer(out.transpose(1, 2)).transpose(1, 2)  \n",
    "#             # 更新隐藏状态和细胞状态为下一层做准备  \n",
    "#             h0 = hn  \n",
    "#             c0 = cn  \n",
    "#             # 使用当前层的输出作为下一层的输入  \n",
    "#             x = out   \n",
    "#         # 取最后一个时间步的输出  \n",
    "#         out = out[:, -1, :]  \n",
    "#         # 全连接层  \n",
    "#         out = self.fc(out)  \n",
    "          \n",
    "#         return out  \n",
    "\n",
    "\n",
    "# class BiLSTMBN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size=64, num_layers=4, dropout=0.2, output_dim=1):\n",
    "#         super(BiLSTMBN, self).__init__()\n",
    "        \n",
    "#         # 定义每层双向LSTM和对应的批量归一化层\n",
    "#         self.lstm_layers = nn.ModuleList()\n",
    "#         self.bn_layers = nn.ModuleList()\n",
    "#         for _ in range(num_layers):\n",
    "#             lstm_layer = nn.LSTM(input_size if layer_num == 0 else hidden_size * 2, hidden_size,\n",
    "#                                 bidirectional=True, batch_first=True, dropout=dropout)\n",
    "#             bn_layer = nn.BatchNorm1d(hidden_size * 2)\n",
    "#             self.lstm_layers.append(lstm_layer)\n",
    "#             self.bn_layers.append(bn_layer)\n",
    "#             input_size = hidden_size * 2  # 下一层的输入维度是上一层输出的维度\n",
    "\n",
    "#         # 输出层，假设我们进行分类任务，类别数为output_dim\n",
    "#         self.fc = nn.Linear(hidden_size * 2, output_dim)  # 注意：因为是双向所以hidden_size要乘以2\n",
    "        \n",
    "#         # 初始化权重\n",
    "#         self.init_weights()\n",
    "        \n",
    "#     def init_weights(self):\n",
    "#         for name, param in self.named_parameters():\n",
    "#             if 'weight_ih' in name:\n",
    "#                 nn.init.xavier_uniform_(param.data)\n",
    "#             elif 'weight_hh' in name:\n",
    "#                 nn.init.orthogonal_(param.data)\n",
    "#             elif 'bias' in name:\n",
    "#                 param.data.fill_(0)\n",
    "\n",
    "#     def forward(self, inputs, lengths=None):\n",
    "#         packed_input = nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "#         hidden_states = []\n",
    "#         for i, (lstm_layer, bn_layer) in enumerate(zip(self.lstm_layers, self.bn_layers)):\n",
    "#             # 通过当前LSTM层\n",
    "#             lstm_outs, (hidden, cell) = lstm_layer(packed_input)\n",
    "            \n",
    "#             # 对隐藏状态应用批量归一化\n",
    "#             lstm_outs_unpacked, _ = nn.utils.rnn.pad_packed_sequence(lstm_outs, batch_first=True)\n",
    "#             hidden_forward = lstm_outs_unpacked[:, :, :hidden_size]\n",
    "#             hidden_backward = lstm_outs_unpacked[:, :, hidden_size:]\n",
    "#             normalized_hidden = torch.cat([bn_layer(hidden_forward), bn_layer(hidden_backward)], dim=-1)\n",
    "\n",
    "#             # 将处理后的隐藏状态存储起来，并作为下一层的输入\n",
    "#             hidden_states.append(normalized_hidden)\n",
    "#             packed_input = nn.utils.rnn.pack_padded_sequence(normalized_hidden, lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "#         # 取最后一层的隐藏状态\n",
    "#         concat_hidden = hidden_states[-1]\n",
    "\n",
    "#         # 经过全连接层进行分类\n",
    "#         out = self.fc(concat_hidden)\n",
    "\n",
    "#         return out\n",
    "\n",
    "# class BiLSTM(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size=64, num_layers=1, dropout=0.2):\n",
    "#         super(BiLSTM, self).__init__()\n",
    "        \n",
    "#         # 定义双向LSTM层\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, bidirectional=True, batch_first=True, dropout=dropout)\n",
    "        \n",
    "#         # 输出层，假设我们进行分类任务，类别数为output_dim\n",
    "#         self.fc = nn.Linear(hidden_size * 2, output_dim)  # 注意：因为是双向所以hidden_size要乘以2\n",
    "        \n",
    "#         # 初始化权重\n",
    "#         self.init_weights()\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         for name, param in self.named_parameters():\n",
    "#             if 'weight_ih' in name:\n",
    "#                 nn.init.xavier_uniform_(param.data)\n",
    "#             elif 'weight_hh' in name:\n",
    "#                 nn.init.orthogonal_(param.data)\n",
    "#             elif 'bias' in name:\n",
    "#                 param.data.fill_(0)\n",
    "\n",
    "#     def forward(self, inputs, lengths=None):\n",
    "#         # 对序列数据进行排序（按长度降序），然后反向恢复原顺序\n",
    "#         packed_input = nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "#         # 通过双向LSTM层\n",
    "#         lstm_outs, (hidden, cell) = self.lstm(packed_input)\n",
    "        \n",
    "#         # 对输出结果进行解压，并取最后一个时间步的隐藏状态作为最终特征表示\n",
    "#         lstm_outs, _ = nn.utils.rnn.pad_packed_sequence(lstm_outs, batch_first=True)\n",
    "#         last_time_step_output = lstm_outs[:, -1, :]\n",
    "        \n",
    "#         # 将双方向的隐藏状态拼接在一起，然后通过全连接层进行分类\n",
    "#         concat_hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "#         out = self.fc(concat_hidden)\n",
    "        \n",
    "#         return out\n",
    "\n",
    "# DNN\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e5e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Embedding层\n",
    "\n",
    "# user_history_feature 对于一个user的多个历史行为，将其拼接成一维向量 要先经过一层通道注意力机制得到最后结果\n",
    "# (样本数,history,20,200) ->多头 ->(样本数,20,200)->转置->(样本数,200,20) ->SE->特征权重->(样本数,200,20) ->转置-> 加权->(样本数,1，200)\n",
    "# user_pay_history_feature 加上batch的\n",
    "# 用户历史\n",
    "class UserPayHistoryEmbedding(nn.Module):\n",
    "    def __init__(self, continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict):\n",
    "        super(UserPayHistoryEmbedding, self).__init__()\n",
    "        # 连续特征\n",
    "        # 离散特征\n",
    "        self.feature_category_num_dict = feature_category_num_dict\n",
    "        # 离散embedding\n",
    "        self.history_discrete_embeddings = discrete_embedding(self.feature_category_num_dict,\n",
    "                                                                feature_column_dict['total_discrete_feature'],\n",
    "                                                                discrete_embedding_dim)\n",
    "        # MLP  连续embedding\n",
    "        self.history_continue_embedding = continuous_embedding(category_feature_num(feature_category_num_dict, feature_column_dict['total_continue_feature']), continue_embedding_dim)\n",
    "       \n",
    "    def forward(self, batch_feature_tensor_history_discrete,batch_feature_tensor_history_continue):\n",
    "        # user_history Embedding\n",
    "        # user_history_continue_features_embedding 得到(batch, 1, continue_feature_num, continue_embedding_dim)\n",
    "        # user_history_discrete_features_embedding 得到(batch, 1, discrete_feature_num, discrete_embedding_dim)\n",
    "        # history中有三种：QOE/CHONGHE/FUFEI,将其分别转化为embedding然后合并\n",
    "        # embedding的数据要求输入是整数类型 因此转为int，输入数据得是从0开始的索引后的数据，因此mask后得到-1以及在输入时得到了从0开始的索引后值，\n",
    "        # 现在所有discrete数据输入时+1，即 batch_feature_tensor_pay_QOE_discrete[:, :, i]+1 \n",
    "        # for i in range(batch_feature_tensor_pay_QOE_discrete.shape[2]):\n",
    "        #     print(i,batch_feature_tensor_pay_QOE_discrete.shape[2],batch_feature_tensor_pay_QOE_discrete[:, :, i]+1,self.user_pay_history_QOE_discrete_embeddings[i].num_embeddings )\n",
    "        batch_feature_tensor_history_discrete = batch_feature_tensor_history_discrete.int()\n",
    "        history_discrete_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_history_discrete[:, :, i]+1) for i, embedding_layer in\n",
    "             enumerate(self.history_discrete_embeddings)], dim=-2)\n",
    "        history_continue_column_discrete_features_embedding = torch.stack(\n",
    "            [embedding_layer(batch_feature_tensor_history_continue[:,:, i].unsqueeze(-1).float()) for i, embedding_layer in\n",
    "             enumerate(self.history_continue_embedding)], dim=-2)\n",
    "        history_vec = torch.cat(\n",
    "            [history_discrete_column_discrete_features_embedding, history_continue_column_discrete_features_embedding], dim=2)  # 特征级合并\n",
    "        \n",
    "        return history_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f85c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.整合模型\n",
    "\n",
    "# (batch,600)经过网络变成200 +(batch,featuer_user*200)经过网络变成200 -> (batch,200)\n",
    "# (batch,200) ->MLP ->(batch，1) ->sigmoid -> (batch,1)\n",
    "\n",
    "# 整合层\n",
    "class MatchingModel(nn.Module):\n",
    "    def __init__(self, feature_category_num_dict, feature_column_dict, continue_embedding_dim,\n",
    "                 discrete_embedding_dim,num_heads, feature_dim, max_history_len):\n",
    "        super(MatchingModel, self).__init__()\n",
    "        # Embedding层\n",
    "        # self.user_info_embedding_layer = UserInfoEmbedding(continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict)\n",
    "#         self.history_embedding_layer = UserPayHistoryEmbedding(continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict)\n",
    "        #print('embedding user_history结果')\n",
    "#         self.target_embedding_layer = TargetEmbedding(continue_embedding_dim, discrete_embedding_dim, feature_category_num_dict, feature_column_dict)\n",
    "        # BiLSTM层  每层64个神经元 输出进入批量归一化 共4层\n",
    "        feature_num = len(feature_column_dict['total_discrete_feature'])+len(feature_column_dict['total_continue_feature'])\n",
    "        self.dnn_layer = DNN(input_dim=feature_num, hidden_dim=64, output_dim=1)\n",
    "\n",
    "        # MLP\n",
    "        final_dim =200\n",
    "        self.pay_vec_MLP_layer = dense_layer_noReLu(final_dim, 1)\n",
    "\n",
    "\n",
    "    def forward(self, batch_feature_tensor_history_discrete,batch_feature_tensor_history_continue,\n",
    "                label_tensor):\n",
    "        # Embedding层 （batch,1,feature_num）\n",
    "#         history_vec= self.history_embedding_layer(batch_feature_tensor_history_discrete,batch_feature_tensor_history_continue)        \n",
    "#         target_vec = self.target_embedding_layer(batch_feature_tensor_target_discrete,batch_feature_tensor_target_continue)\n",
    "        history_vec = torch.cat([batch_feature_tensor_history_discrete, batch_feature_tensor_history_continue], dim=2)  \n",
    "#         print('history_vec',history_vec.shape)\n",
    "        # DNN层  (batch,1，1)转为（batch，1）\n",
    "        out_vec = self.dnn_layer(history_vec)\n",
    "        out_vec = out_vec.squeeze(dim=2) # 去除第三维\n",
    "#         print('DNN_out',out_vec.shape)\n",
    "        \n",
    "        # 使用softmax函数将logits转换为概率分布\n",
    "        sigmoid_score = torch.sigmoid(out_vec)  # 在类别维度（dim=1）上应用softmax\n",
    "        softmax_score = torch.softmax(out_vec, dim=1)\n",
    "\n",
    "        return softmax_score, sigmoid_score\n",
    "\n",
    "# 损失函数\n",
    "class LossFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossFunction, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target_label):\n",
    "        # pred是未经处理过的原值，target_label是0、1标签\n",
    "        # 计算第一个任务的二元交叉熵损失\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, target_label, reduction='none')\n",
    "        return loss\n",
    "\n",
    "\n",
    "# 自动评估阈值，计算ACC 、 Precision 等评估指标\n",
    "def evaluate(y_true, y_pred, digits=4, cutoff='auto'):\n",
    "    '''\n",
    "    Args:\n",
    "        y_true: list, labels, y_pred: list, predictions, digits: The number of decimals to use when rounding the number. Default is 4（保留小数后几位）\n",
    "        cutoff: float or 'auto'\n",
    "    Returns:\n",
    "        evaluation: dict\n",
    "    '''\n",
    "    # 根据预测概率值y_pred计算最佳的切分阈值\n",
    "    if cutoff == 'auto':\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        youden = tpr-fpr\n",
    "        cutoff = thresholds[np.argmax(youden)]\n",
    "    y_pred_t = [1 if i > cutoff else 0 for i in y_pred]\n",
    "\n",
    "    evaluation = OrderedDict()\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_t).ravel()\n",
    "    evaluation['auc'] = round(roc_auc_score(y_true, y_pred), digits)\n",
    "    evaluation['acc'] = round(accuracy_score(y_true, y_pred_t), digits)\n",
    "    evaluation['recall'] = round(recall_score(y_true, y_pred_t), digits)\n",
    "    evaluation['precision'] = round(precision_score(y_true, y_pred_t), digits)\n",
    "    evaluation['specificity'] = round(tn / (tn + fp), digits)\n",
    "    evaluation['F1'] = round(f1_score(y_true, y_pred_t), digits)\n",
    "    evaluation['cutoff'] = cutoff\n",
    "\n",
    "    return evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79ad8ee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_category_num_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2a02c3ead274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 创建大模型的实例 'drama_upuser_subscriptions_num,drama_sound_max_traffic_position_in_sound_avg,label1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = MatchingModel(feature_category_num_dict, feature_column_dict, continue_embedding_dim,\n\u001b[0m\u001b[1;32m      3\u001b[0m                  discrete_embedding_dim, num_heads, feature_dim, max_history_len)\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print('模型创建完成')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_category_num_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# 创建大模型的实例 'drama_upuser_subscriptions_num,drama_sound_max_traffic_position_in_sound_avg,label1'\n",
    "model = MatchingModel(feature_category_num_dict, feature_column_dict, continue_embedding_dim,\n",
    "                 discrete_embedding_dim, num_heads, feature_dim, max_history_len)\n",
    "# print('模型创建完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7e19bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.模型训练 Trainging\n",
    "\n",
    "def model_training(model,train_loader,val_loader, lossfunction,optimizer,EPOCH,device):\n",
    "    # 定义早停策略的参数\n",
    "    best_val_loss = float('inf')  # 初始化最佳验证损失为正无穷\n",
    "    patience = 1  # 容忍多少个epoch没有验证性能提升\n",
    "    early_stopping_counter = 0  # 初始化计数器\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        model.train()  # 设置模型为训练模式\n",
    "        total_classfier_loss = 0.0\n",
    "        total_loss = 0.0\n",
    "        train_time = 0\n",
    "        val_time = 0\n",
    "        for batch in train_loader:\n",
    "            batch = [data.to(device) for data in batch]\n",
    "            batch_feature_tensor_history_discrete,batch_feature_tensor_history_continue,train_label_tensor = batch  \n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer.zero_grad()\n",
    "            softmax_score, sigmoid_score = model(batch_feature_tensor_history_discrete,batch_feature_tensor_history_continue,\n",
    "                                                train_label_tensor)  \n",
    "\n",
    "            # sigmoid\n",
    "            # print('sigmoid_score',sigmoid_score)\n",
    "            sigmoid_score = sigmoid_score[:, 0]  # (样本数，1)\n",
    "            train_label_tensor = train_label_tensor[:, 0].to(device)  # (样本数，1)\n",
    "            train_label_tensor[train_label_tensor == 1] = 0\n",
    "            train_label_tensor[train_label_tensor == 2] = 1\n",
    "            # train_label_tensor = torch.where(train_label_tensor == 1, torch.tensor(0).to(device), torch.tensor(1).to(device))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            loss = lossfunction(sigmoid_score, train_label_tensor.float())\n",
    "            # softmax\n",
    "            # softmax_score = softmax_score[:, 0]  # (样本数，1)\n",
    "            # train_label_tensor = train_label_tensor[:, 0].to(device)  # (样本数，1)\n",
    "            # train_label_tensor = torch.where(train_label_tensor == 1, torch.tensor(0).to(device), torch.tensor(1).to(device))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            # loss = lossfunction(softmax_score, train_label_tensor.float())\n",
    "            loss.to(device)\n",
    "\n",
    "            \n",
    "             # loss回传检查\n",
    "            # for name, parms in model.named_parameters():\t\n",
    "            #     if parms.grad is not None:  # 检查梯度是否为None\n",
    "            #         grad_mean = torch.mean(parms.grad)  # 计算梯度的均值\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: {:.4f}'.format(grad_mean))\n",
    "            #     else:\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: None')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(\"=============更新之后===========\")\n",
    "            # for name, parms in model.named_parameters():\t\n",
    "            #     if parms.grad is not None:  # 检查梯度是否为None\n",
    "            #         grad_mean = torch.mean(parms.grad)  # 计算梯度的均值\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: {:.4f}'.format(grad_mean))\n",
    "            #     else:\n",
    "            #         print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '-->grad_mean: None')\n",
    "            # print(optimizer)\n",
    "            # input(\"=====迭代结束=====\")\n",
    "\n",
    "            # 损失\n",
    "            total_loss += loss.item()\n",
    "            train_time += 1\n",
    "#             print('||--训练：----------',train_time,'个batch运行时间：',datetime.datetime.now(),'-------------')\n",
    "        # 平均损失\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        \n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1},loss:{average_loss}\")\n",
    "\n",
    "            # 验证集评估\n",
    "            model.eval()  # 将模型切换为评估模式\n",
    "            with torch.no_grad():  # 在评估模式下不计算梯度\n",
    "                total_loss_val = 0.0\n",
    "                total_auc_val = 0.0\n",
    "                total_acc_val = 0\n",
    "                total_f1_val = 0\n",
    "                total_precision_val = 0\n",
    "                total_recall_val = 0\n",
    "                val_time = 0\n",
    "                for batch_val in val_loader:  # 假设你有一个名为 val_loader 的验证集数据加载器\n",
    "                    batch_val = [data.to(device) for data in batch_val]\n",
    "                    val_batch_feature_tensor_history_discrete,val_batch_feature_tensor_history_continue,val_label_tensor = batch_val \n",
    "                    softmax_score_val, sigmoid_score_val = model(val_batch_feature_tensor_history_discrete,val_batch_feature_tensor_history_continue,\n",
    "                                                                        val_label_tensor) \n",
    "\n",
    "                    # sigmoid                   \n",
    "                    sigmoid_score_val = sigmoid_score_val[:, 0]  # (样本数，1)\n",
    "                    sigmoid_score_val = sigmoid_score_val.cpu()# .detach()  # 转为CPU\n",
    "                    val_label_tensor = val_label_tensor[:, 0]  # (样本数，1)\n",
    "                    val_label_tensor = val_label_tensor.cpu()\n",
    "                    val_label_tensor[val_label_tensor == 1] = 0\n",
    "                    val_label_tensor[val_label_tensor == 2] = 1\n",
    "                    # val_label_tensor = torch.where(val_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "                    loss_val = lossfunction(sigmoid_score_val, val_label_tensor.float())\n",
    "                    # softmax\n",
    "                    # softmax_score_val = softmax_score_val[:, 0]  # (样本数，1)\n",
    "                    # softmax_score_val = softmax_score_val.cpu()# .detach()  # 转为CPU\n",
    "                    # val_label_tensor = val_label_tensor[:, 0]  # (样本数，1)\n",
    "                    # val_label_tensor = val_label_tensor.cpu()\n",
    "                    # val_label_tensor = torch.where(val_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "                    # loss_val = lossfunction(softmax_score_val, val_label_tensor.float())\n",
    "    \n",
    "                    # 损失\n",
    "                    total_loss_val += loss_val.item()\n",
    "                    # 计算验证集上的精度\n",
    "                    # predicted_classes_val = (sigmoid_score_val > 0.5).long()\n",
    "                    # total_acc_val += (predicted_classes_val == val_label_tensor).sum().item() / len(val_label_tensor)\n",
    "                    # total_f1_val += f1_score(val_label_tensor, predicted_classes_val)\n",
    "                    # total_recall_val += recall_score(val_label_tensor, predicted_classes_val)\n",
    "                    # precision_val = ((predicted_classes_val == 1) & (val_label_tensor == 1)).sum().item() / (predicted_classes_val == 1).sum().item()\n",
    "                    # total_precision_val += precision_val\n",
    "                    # total_auc_val += roc_auc_score(val_label_tensor, softmax_score_val)\n",
    "                    evaluation = evaluate(val_label_tensor,sigmoid_score_val)\n",
    "                    total_acc_val += evaluation['acc']\n",
    "                    total_f1_val += evaluation['F1']\n",
    "                    total_recall_val += evaluation['recall']\n",
    "                    total_precision_val += evaluation['precision']\n",
    "                    total_auc_val += evaluation['auc']\n",
    "                    \n",
    "                    val_time += 1\n",
    "#                     print('||--验证：----------',val_time,'个batch运行时间：',datetime.datetime.now(),'-------------')\n",
    "                # 平均损失\n",
    "                average_loss_val = total_loss_val / len(val_loader)\n",
    "                average_auc_val = total_auc_val / len(val_loader)\n",
    "                average_acc_val = total_acc_val / len(val_loader)\n",
    "                average_f1_val = total_f1_val / len(val_loader)\n",
    "                average_precision_val = total_precision_val / len(val_loader)\n",
    "                average_recall_val = total_recall_val / len(val_loader)\n",
    "                print(f\"Validation Loss: {average_loss_val},AUC: {average_auc_val},ACC:{average_acc_val},F1:{average_f1_val},Precision:{average_precision_val},Recall:{average_recall_val}\") \n",
    "\n",
    "                if average_loss_val < best_val_loss:\n",
    "                    best_val_loss = average_loss_val\n",
    "                    early_stopping_counter = 0\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "                if early_stopping_counter >= patience:\n",
    "                    print(f\"早停策略触发，停止训练在第 {epoch} 个epoch.\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b8a1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型测试 Test\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 在评估模式下不计算梯度\n",
    "        total_loss_test = 0.0\n",
    "        total_auc_test = 0.0\n",
    "        total_acc_test  = 0\n",
    "        total_f1_test = 0\n",
    "        total_precision_test = 0\n",
    "        total_recall_test = 0\n",
    "        test_time = 0\n",
    "        results = []  # 用于保存结果的列表\n",
    "        for batch_test in test_loader:  # 假设你有一个名为 val_loader 的验证集数据加载器\n",
    "            batch_test = [data.to(device) for data in batch_test]\n",
    "            test_batch_feature_tensor_history_discrete,test_batch_feature_tensor_history_continue,test_label_tensor = batch_test \n",
    "            softmax_score_test, sigmoid_score_test = model(test_batch_feature_tensor_history_discrete,test_batch_feature_tensor_history_continue,\n",
    "                                                                test_label_tensor)  \n",
    "            # sigmoid\n",
    "            sigmoid_score_test = sigmoid_score_test[:, 0]  # (样本数，1)\n",
    "            sigmoid_score_test = sigmoid_score_test.cpu()#.detach()  # 转为CPU\n",
    "            test_label_tensor = test_label_tensor[:, 0]  # (样本数，1)\n",
    "            test_label_tensor = test_label_tensor.cpu()\n",
    "            test_label_tensor[test_label_tensor == 1] = 0\n",
    "            test_label_tensor[test_label_tensor == 2] = 1\n",
    "            # test_label_tensor = torch.where(test_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            loss_test = lossfunction(sigmoid_score_test, test_label_tensor.float())\n",
    "            # softmax\n",
    "            # softmax_score_test = softmax_score_test[:, 0]  # (样本数，1)\n",
    "            # softmax_score_test = softmax_score_test.cpu()#.detach()  # 转为CPU\n",
    "            # test_label_tensor = test_label_tensor[:, 0]  # (样本数，1)\n",
    "            # test_label_tensor = test_label_tensor.cpu()\n",
    "            # test_label_tensor = torch.where(test_label_tensor == 1, torch.tensor(0), torch.tensor(1))  # 使用 torch.where 将 1 映射为 0，将 2 映射为 1\n",
    "            # loss_test = lossfunction(softmax_score_test, test_label_tensor.float())\n",
    "            \n",
    "            # 损失\n",
    "            total_loss_test += loss_test.item()\n",
    "            # 计算验证集上的精度\n",
    "            # predicted_classes_test = (sigmoid_score_test > 0.5).long()\n",
    "            # total_acc_test += (predicted_classes_test == test_label_tensor).sum().item() / len(test_label_tensor)\n",
    "            # total_f1_test += f1_score(test_label_tensor, predicted_classes_test)\n",
    "            # total_recall_test += recall_score(test_label_tensor, predicted_classes_test)\n",
    "            # precision_test = ((predicted_classes_test == 1) & (test_label_tensor == 1)).sum().item() / (predicted_classes_test == 1).sum().item()\n",
    "            # total_precision_test += precision_test\n",
    "            # total_auc_test += roc_auc_score(test_label_tensor, sigmoid_score_test)\n",
    "            evaluation = evaluate(test_label_tensor,sigmoid_score_test)\n",
    "            total_acc_test += evaluation['acc']\n",
    "            total_f1_test += evaluation['F1']\n",
    "            total_recall_test += evaluation['recall']\n",
    "            total_precision_test += evaluation['precision']\n",
    "            total_auc_test += evaluation['auc']\n",
    "\n",
    "            test_time += 1\n",
    "            print('||--测试：----------',test_time,'个batch运行时间：',datetime.datetime.now(),'-------------')\n",
    "        # 平均损失\n",
    "        average_loss_test = total_loss_test / len(test_loader)\n",
    "        average_auc_test = total_auc_test / len(test_loader)\n",
    "        average_acc_test = total_acc_test / len(test_loader)\n",
    "        average_f1_test = total_f1_test / len(test_loader)\n",
    "        average_precision_test = total_precision_test / len(test_loader)\n",
    "        average_recall_test = total_recall_test / len(test_loader)\n",
    "        print(\n",
    "            f\"Test Loss: {average_loss_test},AUC: {average_auc_test},ACC:{average_acc_test},F1:{average_f1_test},Precision:{average_precision_test},Recall:{average_recall_test}\")\n",
    "        return average_loss_test, average_auc_test,average_acc_test,average_f1_test,average_precision_test,average_recall_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdbf173b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=:1\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.684530486272076\n",
      "Validation Loss: 0.6836931052662077,AUC: 0.6131285714285714,ACC:0.6153309523809524,F1:0.559095238095238,Precision:0.638752380952381,Recall:0.5355880952380953\n",
      "Epoch 10,loss:0.6777400487051235\n",
      "Validation Loss: 0.6757951705228715,AUC: 0.6365357142857143,ACC:0.6432309523809524,F1:0.5530499999999999,Precision:0.7009095238095236,Recall:0.47019761904761903\n",
      "Epoch 15,loss:0.6720859502244183\n",
      "Validation Loss: 0.6692908562365032,AUC: 0.6482666666666669,ACC:0.6582904761904762,F1:0.5754523809523809,Precision:0.7216738095238098,Recall:0.4925428571428571\n",
      "Epoch 20,loss:0.6678502343771026\n",
      "Validation Loss: 0.6645795050121489,AUC: 0.6560119047619047,ACC:0.6625714285714285,F1:0.5791380952380952,Precision:0.7308428571428572,Recall:0.48994523809523793\n",
      "Epoch 25,loss:0.6647267435479352\n",
      "Validation Loss: 0.6612221428326198,AUC: 0.6587142857142859,ACC:0.6672190476190475,F1:0.5831333333333335,Precision:0.7415,Recall:0.4905\n",
      "Epoch 30,loss:0.6622617310426366\n",
      "Validation Loss: 0.6587740523474557,AUC: 0.6611904761904762,ACC:0.6687095238095238,F1:0.5794595238095239,Precision:0.753509523809524,Recall:0.478192857142857\n",
      "Epoch 35,loss:0.660373632832775\n",
      "Validation Loss: 0.6570396763937814,AUC: 0.6623761904761903,ACC:0.6713071428571427,F1:0.5810095238095238,Precision:0.7609095238095239,Recall:0.48011666666666664\n",
      "Epoch 40,loss:0.6589258097288176\n",
      "Validation Loss: 0.6557543589955285,AUC: 0.6635499999999999,ACC:0.6746571428571427,F1:0.5855976190476191,Precision:0.7641238095238092,Recall:0.4851214285714286\n",
      "Epoch 45,loss:0.6577837030718646\n",
      "Validation Loss: 0.654758693206878,AUC: 0.6647666666666665,ACC:0.676142857142857,F1:0.5857119047619047,Precision:0.7717214285714282,Recall:0.4845928571428571\n",
      "Epoch 50,loss:0.6568578063972353\n",
      "Validation Loss: 0.6539385120073954,AUC: 0.6652333333333335,ACC:0.678745238095238,F1:0.5879238095238095,Precision:0.7754,Recall:0.4840166666666667\n",
      "Epoch 55,loss:0.6560771901776471\n",
      "Validation Loss: 0.6532523816540128,AUC: 0.665097619047619,ACC:0.6796761904761904,F1:0.5906404761904761,Precision:0.7731309523809525,Recall:0.48800000000000004\n",
      "Epoch 60,loss:0.6554021624129588\n",
      "Validation Loss: 0.6526891929762704,AUC: 0.6655523809523811,ACC:0.6796809523809524,F1:0.5894428571428572,Precision:0.7748833333333335,Recall:0.484247619047619\n",
      "Epoch 65,loss:0.654813289642334\n",
      "Validation Loss: 0.6521912131990705,AUC: 0.6656333333333331,ACC:0.6785666666666665,F1:0.5897047619047618,Precision:0.7709142857142859,Recall:0.48722619047619037\n",
      "Epoch 70,loss:0.6542773134126438\n",
      "Validation Loss: 0.6517882758662814,AUC: 0.665952380952381,ACC:0.6791261904761905,F1:0.5918809523809523,Precision:0.7696357142857144,Recall:0.4899595238095237\n",
      "Epoch 75,loss:0.6538146058405478\n",
      "Validation Loss: 0.6514043155170622,AUC: 0.6659952380952382,ACC:0.6791261904761905,F1:0.5943761904761904,Precision:0.7643714285714286,Recall:0.4951452380952381\n",
      "Epoch 80,loss:0.6534014883942492\n",
      "Validation Loss: 0.6510405370167324,AUC: 0.6659880952380952,ACC:0.6793119047619048,F1:0.594447619047619,Precision:0.7652738095238097,Recall:0.49498333333333333\n",
      "Epoch 85,loss:0.6530154816747651\n",
      "Validation Loss: 0.650750763359524,AUC: 0.6662476190476191,ACC:0.6791261904761905,F1:0.5969642857142856,Precision:0.7617642857142859,Recall:0.4990928571428572\n",
      "Epoch 90,loss:0.6526544234884066\n",
      "Validation Loss: 0.650456075157438,AUC: 0.6665523809523808,ACC:0.679502380952381,F1:0.5946761904761905,Precision:0.7665785714285717,Recall:0.49371190476190485\n",
      "Epoch 95,loss:0.6523320632656728\n",
      "Validation Loss: 0.6501780790942056,AUC: 0.6669904761904764,ACC:0.680061904761905,F1:0.5964190476190476,Precision:0.7667166666666667,Recall:0.4967571428571429\n",
      "Epoch 100,loss:0.6520315985979996\n",
      "Validation Loss: 0.6499045732475462,AUC: 0.6671428571428573,ACC:0.6793166666666668,F1:0.595247619047619,Precision:0.766857142857143,Recall:0.49399523809523815\n",
      "Epoch 105,loss:0.6517424376930777\n",
      "Validation Loss: 0.649688021058128,AUC: 0.6672500000000001,ACC:0.6802452380952382,F1:0.596102380952381,Precision:0.7688095238095242,Recall:0.4942761904761904\n",
      "Epoch 110,loss:0.6514849268545316\n",
      "Validation Loss: 0.6493780215581259,AUC: 0.6672428571428572,ACC:0.6806142857142857,F1:0.5940714285714286,Precision:0.7724380952380953,Recall:0.4899166666666667\n",
      "Epoch 115,loss:0.6512226706414711\n",
      "Validation Loss: 0.6491915924208504,AUC: 0.667295238095238,ACC:0.6802428571428571,F1:0.5949,Precision:0.7702952380952381,Recall:0.4918595238095239\n",
      "Epoch 120,loss:0.6509454400520626\n",
      "Validation Loss: 0.6489534917331877,AUC: 0.6679261904761903,ACC:0.6802404761904761,F1:0.5938166666666665,Precision:0.7716380952380952,Recall:0.4893642857142858\n",
      "Epoch 125,loss:0.6506570704339996\n",
      "Validation Loss: 0.6488010925906045,AUC: 0.6681738095238094,ACC:0.6806142857142857,F1:0.5931642857142856,Precision:0.7740261904761906,Recall:0.48818809523809525\n",
      "Epoch 130,loss:0.6504129523367393\n",
      "Validation Loss: 0.6486468002909705,AUC: 0.6681238095238096,ACC:0.6813595238095237,F1:0.5918761904761904,Precision:0.779557142857143,Recall:0.48535952380952385\n",
      "Epoch 135,loss:0.650169302628735\n",
      "Validation Loss: 0.6484908631869725,AUC: 0.668435714285714,ACC:0.6811738095238095,F1:0.5910976190476189,Precision:0.7804880952380954,Recall:0.4840214285714286\n",
      "Epoch 140,loss:0.6499555829003101\n",
      "Validation Loss: 0.6482548515001932,AUC: 0.6687904761904763,ACC:0.6822880952380952,F1:0.587592857142857,Precision:0.7897285714285716,Recall:0.4775738095238096\n",
      "Epoch 145,loss:0.6497288576261265\n",
      "Validation Loss: 0.6481142625922248,AUC: 0.6687880952380952,ACC:0.6822880952380951,F1:0.5894404761904762,Precision:0.7863428571428572,Recall:0.4813095238095239\n",
      "Epoch 150,loss:0.649519342137134\n",
      "Validation Loss: 0.648001804238274,AUC: 0.6692095238095236,ACC:0.6824761904761905,F1:0.5905952380952381,Precision:0.784802380952381,Recall:0.4832333333333334\n",
      "Epoch 155,loss:0.6493119925964536\n",
      "Validation Loss: 0.6478751670746576,AUC: 0.6693309523809525,ACC:0.682845238095238,F1:0.5906619047619047,Precision:0.786947619047619,Recall:0.4827142857142858\n",
      "Epoch 160,loss:0.6491136396025109\n",
      "Validation Loss: 0.6477937726747423,AUC: 0.6695214285714286,ACC:0.6824738095238094,F1:0.5932738095238095,Precision:0.7816380952380952,Recall:0.4872595238095239\n",
      "Epoch 165,loss:0.6489278969802256\n",
      "Validation Loss: 0.6476779750415257,AUC: 0.6696761904761905,ACC:0.6826619047619046,F1:0.5956999999999999,Precision:0.7788595238095238,Recall:0.4900952380952382\n",
      "Epoch 170,loss:0.6487422914016904\n",
      "Validation Loss: 0.6475755657468524,AUC: 0.6697261904761904,ACC:0.6834071428571428,F1:0.5945404761904762,Precision:0.7827142857142856,Recall:0.4866428571428573\n",
      "Epoch 175,loss:0.6485571739241833\n",
      "Validation Loss: 0.6474848559924534,AUC: 0.6697166666666667,ACC:0.6839666666666665,F1:0.5935642857142857,Precision:0.7854952380952381,Recall:0.4841000000000001\n",
      "Epoch 180,loss:0.6483752577323613\n",
      "Validation Loss: 0.6473743745258876,AUC: 0.6700738095238097,ACC:0.6845238095238094,F1:0.5919880952380951,Precision:0.7897880952380953,Recall:0.4803642857142858\n",
      "Epoch 185,loss:0.6482001585284556\n",
      "Validation Loss: 0.6473113199075063,AUC: 0.6700380952380952,ACC:0.6845238095238094,F1:0.592845238095238,Precision:0.7885523809523809,Recall:0.48192619047619056\n",
      "Epoch 190,loss:0.6480196888052573\n",
      "Validation Loss: 0.647247409536725,AUC: 0.6700904761904762,ACC:0.6845238095238094,F1:0.5940857142857142,Precision:0.7858357142857144,Recall:0.48472857142857156\n",
      "Epoch 195,loss:0.647832994855295\n",
      "Validation Loss: 0.6472163171995253,AUC: 0.6703809523809524,ACC:0.6850833333333333,F1:0.5946071428571428,Precision:0.7874761904761904,Recall:0.48435952380952396\n",
      "Epoch 200,loss:0.6476441462208905\n",
      "Validation Loss: 0.6471740064166841,AUC: 0.6705357142857141,ACC:0.6847119047619048,F1:0.5938238095238094,Precision:0.7872785714285716,Recall:0.48371666666666674\n",
      "Epoch 205,loss:0.6474563929978319\n",
      "Validation Loss: 0.6471002130281358,AUC: 0.6709309523809524,ACC:0.6847095238095238,F1:0.5956857142857143,Precision:0.7836928571428572,Recall:0.4872452380952381\n",
      "Epoch 210,loss:0.6472548373102203\n",
      "Validation Loss: 0.647032197032656,AUC: 0.6712833333333335,ACC:0.6850785714285714,F1:0.5967357142857141,Precision:0.7833547619047619,Recall:0.48835238095238104\n",
      "Epoch 215,loss:0.6470667860639376\n",
      "Validation Loss: 0.6469880243142446,AUC: 0.671147619047619,ACC:0.6843357142857143,F1:0.5982047619047618,Precision:0.7766761904761904,Recall:0.4919095238095239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220,loss:0.6468679585794764\n",
      "Validation Loss: 0.6469390945775169,AUC: 0.6712642857142858,ACC:0.6843333333333333,F1:0.5962238095238096,Precision:0.7825595238095238,Recall:0.48853333333333343\n",
      "Epoch 225,loss:0.6466789794719126\n",
      "Validation Loss: 0.6468613133544013,AUC: 0.6715619047619048,ACC:0.68415,F1:0.5967738095238095,Precision:0.7818690476190475,Recall:0.4899238095238096\n",
      "Epoch 230,loss:0.6464834199176999\n",
      "Validation Loss: 0.6467817879858471,AUC: 0.6717071428571428,ACC:0.6837761904761904,F1:0.5996309523809524,Precision:0.7739619047619047,Recall:0.4953214285714286\n",
      "Epoch 235,loss:0.6462961730994577\n",
      "Validation Loss: 0.6467347585019612,AUC: 0.6718857142857144,ACC:0.6843404761904762,F1:0.5931023809523811,Precision:0.7882023809523808,Recall:0.4829190476190477\n",
      "Epoch 240,loss:0.6461125682658098\n",
      "Validation Loss: 0.6466734040351141,AUC: 0.6720452380952382,ACC:0.6852714285714286,F1:0.5924428571428573,Precision:0.7938,Recall:0.4806595238095238\n",
      "Epoch 245,loss:0.6459304690361023\n",
      "Validation Loss: 0.6466141314733596,AUC: 0.672052380952381,ACC:0.6845285714285715,F1:0.5923214285714286,Precision:0.7914380952380953,Recall:0.48154761904761906\n",
      "Epoch 250,loss:0.6457457059011684\n",
      "Validation Loss: 0.6465671530791691,AUC: 0.6722857142857144,ACC:0.6841571428571429,F1:0.5917261904761904,Precision:0.7914880952380953,Recall:0.48031904761904765\n",
      "Epoch 255,loss:0.6455637291660459\n",
      "Validation Loss: 0.6465271413326263,AUC: 0.6721976190476191,ACC:0.6841571428571429,F1:0.5934476190476189,Precision:0.7879214285714286,Recall:0.4834452380952381\n",
      "Epoch 260,loss:0.645385805546768\n",
      "Validation Loss: 0.6464840429169791,AUC: 0.6721785714285715,ACC:0.6849000000000001,F1:0.597247619047619,Precision:0.7839976190476192,Recall:0.48953333333333326\n",
      "Epoch 265,loss:0.6452235072616517\n",
      "Validation Loss: 0.6464374860127767,AUC: 0.6729404761904763,ACC:0.6847142857142858,F1:0.594197619047619,Precision:0.7885976190476194,Recall:0.48480476190476185\n",
      "Epoch 270,loss:0.6450570258568591\n",
      "Validation Loss: 0.6464003508999234,AUC: 0.6731833333333331,ACC:0.6850857142857143,F1:0.594997619047619,Precision:0.7875547619047623,Recall:0.4861642857142857\n",
      "Epoch 275,loss:0.6448966738745923\n",
      "Validation Loss: 0.6463754049369267,AUC: 0.6734142857142856,ACC:0.6852714285714286,F1:0.5970714285714285,Precision:0.785409523809524,Recall:0.4903928571428572\n",
      "Epoch 280,loss:0.6447496653541805\n",
      "Validation Loss: 0.6463572865440732,AUC: 0.6740904761904764,ACC:0.685457142857143,F1:0.5968499999999999,Precision:0.7870190476190478,Recall:0.48963095238095233\n",
      "Epoch 285,loss:0.6445837555907843\n",
      "Validation Loss: 0.646271865992319,AUC: 0.6744190476190477,ACC:0.6845285714285715,F1:0.5944190476190476,Precision:0.7880238095238097,Recall:0.4866833333333333\n",
      "Epoch 290,loss:0.6444352104907899\n",
      "Validation Loss: 0.6461962262789408,AUC: 0.6746142857142857,ACC:0.6847142857142858,F1:0.5961380952380952,Precision:0.7859904761904766,Recall:0.4892999999999999\n",
      "Epoch 295,loss:0.6442899948030006\n",
      "Validation Loss: 0.6461536784966787,AUC: 0.6748761904761905,ACC:0.6845285714285715,F1:0.5955428571428572,Precision:0.7862761904761909,Recall:0.4885523809523809\n",
      "Epoch 300,loss:0.6441487998474301\n",
      "Validation Loss: 0.6461176630996522,AUC: 0.6746547619047618,ACC:0.6850857142857143,F1:0.5960023809523809,Precision:0.7873595238095239,Recall:0.4885166666666666\n",
      "Epoch 305,loss:0.6440051667333588\n",
      "Validation Loss: 0.6460315769626981,AUC: 0.6749357142857142,ACC:0.6862,F1:0.5961214285714286,Precision:0.7913142857142859,Recall:0.48643095238095235\n",
      "Epoch 310,loss:0.643860585576906\n",
      "Validation Loss: 0.6459581951300303,AUC: 0.6751476190476191,ACC:0.6862,F1:0.5950571428571428,Precision:0.793447619047619,Recall:0.4847095238095239\n",
      "Epoch 315,loss:0.6437296266630879\n",
      "Validation Loss: 0.6459239834830874,AUC: 0.6755404761904762,ACC:0.6867571428571428,F1:0.5955476190476192,Precision:0.7954428571428571,Recall:0.48435238095238087\n",
      "Epoch 320,loss:0.6435986048593296\n",
      "Validation Loss: 0.6458588739236196,AUC: 0.6754214285714284,ACC:0.6871309523809525,F1:0.5974452380952381,Precision:0.792492857142857,Recall:0.4877880952380952\n",
      "Epoch 325,loss:0.6434768963986495\n",
      "Validation Loss: 0.6457926531632742,AUC: 0.6747571428571428,ACC:0.6858285714285716,F1:0.5973380952380951,Precision:0.7881928571428573,Recall:0.49009047619047613\n",
      "Epoch 330,loss:0.6433461364798658\n",
      "Validation Loss: 0.6457427030517942,AUC: 0.6748119047619048,ACC:0.6862,F1:0.5996857142857142,Precision:0.7849595238095236,Recall:0.49508095238095234\n",
      "Epoch 335,loss:0.6432270219945532\n",
      "Validation Loss: 0.6457089966251737,AUC: 0.6746238095238094,ACC:0.6867571428571428,F1:0.5990309523809522,Precision:0.7876833333333332,Recall:0.49310238095238096\n",
      "Epoch 340,loss:0.6431075315775834\n",
      "Validation Loss: 0.645638861826488,AUC: 0.674747619047619,ACC:0.6863857142857144,F1:0.5987119047619047,Precision:0.7883333333333333,Recall:0.49203095238095235\n",
      "Epoch 345,loss:0.64300556211021\n",
      "Validation Loss: 0.6456163028875986,AUC: 0.6748619047619048,ACC:0.6863857142857143,F1:0.5965738095238096,Precision:0.788152380952381,Recall:0.487647619047619\n",
      "Epoch 350,loss:0.6428991481075137\n",
      "Validation Loss: 0.6455636521180471,AUC: 0.6754642857142856,ACC:0.6862,F1:0.5953047619047619,Precision:0.7898595238095238,Recall:0.4854571428571428\n",
      "Epoch 355,loss:0.6427869153773691\n",
      "Validation Loss: 0.6455401153791518,AUC: 0.6759690476190476,ACC:0.6862023809523811,F1:0.5954928571428572,Precision:0.7901428571428573,Recall:0.4859142857142858\n",
      "Epoch 360,loss:0.6426808937328068\n",
      "Validation Loss: 0.6455198285125551,AUC: 0.6759595238095238,ACC:0.6869476190476193,F1:0.5955047619047621,Precision:0.7924285714285715,Recall:0.48499047619047614\n",
      "Epoch 365,loss:0.6425801130730336\n",
      "Validation Loss: 0.6454664312657856,AUC: 0.675942857142857,ACC:0.6878785714285717,F1:0.5977119047619049,Precision:0.7914095238095239,Recall:0.4880952380952382\n",
      "Epoch 370,loss:0.6424612632886632\n",
      "Validation Loss: 0.6454258930115473,AUC: 0.6760452380952382,ACC:0.6873190476190477,F1:0.597354761904762,Precision:0.7890809523809527,Recall:0.48783333333333345\n",
      "Epoch 375,loss:0.6423424810875119\n",
      "Validation Loss: 0.6453504335312616,AUC: 0.6760309523809527,ACC:0.6873214285714287,F1:0.5970142857142859,Precision:0.7899833333333333,Recall:0.4875238095238096\n",
      "Epoch 380,loss:0.6422269095586041\n",
      "Validation Loss: 0.6452609045164925,AUC: 0.6758714285714289,ACC:0.6880666666666668,F1:0.5974000000000002,Precision:0.7945690476190477,Recall:0.4855857142857143\n",
      "Epoch 390,loss:0.6419997280976903\n",
      "Validation Loss: 0.6451044437431154,AUC: 0.6763238095238095,ACC:0.6901142857142859,F1:0.5994333333333335,Precision:0.7961809523809525,Recall:0.48702857142857153\n",
      "Epoch 405,loss:0.641649518895337\n",
      "Validation Loss: 0.6450180936427343,AUC: 0.6769809523809523,ACC:0.6921523809523811,F1:0.599657142857143,Precision:0.8020023809523812,Recall:0.4857857142857143\n",
      "早停策略触发，停止训练在第 404 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 08:43:06.205806 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 08:43:06.218103 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 08:43:06.229986 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 08:43:06.241863 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 08:43:06.254163 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 08:43:06.266093 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 08:43:06.277957 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 08:43:06.290042 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 08:43:06.301929 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 08:43:06.314332 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 08:43:06.326581 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 08:43:06.338524 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 08:43:06.350465 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 08:43:06.362760 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 08:43:06.374611 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 08:43:06.386530 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 08:43:06.398355 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 08:43:06.411001 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 08:43:06.423015 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 08:43:06.435298 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 08:43:06.447182 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 08:43:06.459083 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 08:43:06.471385 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 08:43:06.483185 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 08:43:06.495035 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 08:43:06.506996 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 08:43:06.518838 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 08:43:06.531152 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 08:43:06.543143 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 08:43:06.555476 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 08:43:06.567462 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 08:43:06.579315 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 08:43:06.591259 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 08:43:06.603200 -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 08:43:06.615773 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 08:43:06.627728 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 08:43:06.639619 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 08:43:06.651560 -------------\n",
      "||--测试：---------- 38 个batch运行时间： 2024-03-19 08:43:06.663388 -------------\n",
      "||--测试：---------- 39 个batch运行时间： 2024-03-19 08:43:06.675263 -------------\n",
      "||--测试：---------- 40 个batch运行时间： 2024-03-19 08:43:06.687138 -------------\n",
      "||--测试：---------- 41 个batch运行时间： 2024-03-19 08:43:06.699064 -------------\n",
      "||--测试：---------- 42 个batch运行时间： 2024-03-19 08:43:06.711902 -------------\n",
      "Test Loss: 0.6456307839779627,AUC: 0.6853404761904761,ACC:0.6979238095238095,F1:0.6103571428571429,Precision:0.7830238095238097,Recall:0.5080619047619047\n",
      "i=:2\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6859526000623628\n",
      "Validation Loss: 0.6850892745313191,AUC: 0.6109309523809523,ACC:0.6151428571428572,F1:0.5702642857142857,Precision:0.6302523809523809,Recall:0.5596166666666667\n",
      "Epoch 10,loss:0.6777620972610834\n",
      "Validation Loss: 0.6751756114619119,AUC: 0.6453928571428573,ACC:0.6519666666666667,F1:0.5780357142857142,Precision:0.7014690476190475,Recall:0.5122357142857142\n",
      "Epoch 15,loss:0.671463286313485\n",
      "Validation Loss: 0.667889437505177,AUC: 0.6589809523809523,ACC:0.6674095238095238,F1:0.5893214285714288,Precision:0.7303166666666667,Recall:0.5071904761904762\n",
      "Epoch 20,loss:0.6668477307154438\n",
      "Validation Loss: 0.6628509135473342,AUC: 0.665795238095238,ACC:0.6737285714285713,F1:0.5925166666666668,Precision:0.743857142857143,Recall:0.5005880952380951\n",
      "Epoch 25,loss:0.6634612679481506\n",
      "Validation Loss: 0.6595065664677393,AUC: 0.6693714285714285,ACC:0.6763285714285713,F1:0.590492857142857,Precision:0.759192857142857,Recall:0.49069523809523813\n",
      "Epoch 30,loss:0.6609387547951046\n",
      "Validation Loss: 0.6571561452888307,AUC: 0.6719428571428571,ACC:0.6789380952380951,F1:0.597195238095238,Precision:0.7568452380952381,Recall:0.5012857142857144\n",
      "Epoch 35,loss:0.6590089262939813\n",
      "Validation Loss: 0.6554278490089235,AUC: 0.6740642857142857,ACC:0.6815404761904761,F1:0.5948571428571428,Precision:0.7712785714285714,Recall:0.4932071428571428\n",
      "Epoch 40,loss:0.6574850213809276\n",
      "Validation Loss: 0.6540874356315249,AUC: 0.674902380952381,ACC:0.6826619047619048,F1:0.6014214285714286,Precision:0.7643404761904764,Recall:0.5043023809523809\n",
      "Epoch 45,loss:0.6562605899149977\n",
      "Validation Loss: 0.6530321382340931,AUC: 0.6759904761904759,ACC:0.6841499999999999,F1:0.5953428571428572,Precision:0.7806738095238094,Recall:0.49169761904761905\n",
      "Epoch 50,loss:0.6552450924407779\n",
      "Validation Loss: 0.6521862702710288,AUC: 0.6766809523809522,ACC:0.6845261904761906,F1:0.5980738095238095,Precision:0.7779285714285715,Recall:0.4956547619047619\n",
      "Epoch 55,loss:0.6543351852987694\n",
      "Validation Loss: 0.651483667748315,AUC: 0.6772452380952378,ACC:0.6856380952380952,F1:0.6019404761904762,Precision:0.7749809523809523,Recall:0.5036428571428571\n",
      "Epoch 60,loss:0.6535475221205884\n",
      "Validation Loss: 0.6508608829407465,AUC: 0.676697619047619,ACC:0.6858261904761904,F1:0.6021357142857143,Precision:0.7757023809523809,Recall:0.5034761904761904\n",
      "Epoch 65,loss:0.6528533152707918\n",
      "Validation Loss: 0.6502869554928371,AUC: 0.6772333333333332,ACC:0.6856404761904762,F1:0.6013571428571429,Precision:0.7800738095238098,Recall:0.5026047619047619\n",
      "Epoch 70,loss:0.6522475940974679\n",
      "Validation Loss: 0.6497772123132434,AUC: 0.6780166666666667,ACC:0.6854523809523808,F1:0.6021357142857142,Precision:0.7764666666666665,Recall:0.5041880952380953\n",
      "Epoch 75,loss:0.6517088676062156\n",
      "Validation Loss: 0.6493513328688485,AUC: 0.6785047619047619,ACC:0.6865690476190475,F1:0.6029214285714284,Precision:0.7812976190476193,Recall:0.503897619047619\n",
      "Epoch 80,loss:0.6511305509589789\n",
      "Validation Loss: 0.6489708040441785,AUC: 0.6791238095238098,ACC:0.686195238095238,F1:0.6036071428571427,Precision:0.7806666666666666,Recall:0.5040809523809523\n",
      "Epoch 85,loss:0.6506907888284819\n",
      "Validation Loss: 0.6485777695973715,AUC: 0.6793761904761905,ACC:0.686940476190476,F1:0.6026761904761903,Precision:0.784847619047619,Recall:0.5011238095238095\n",
      "Epoch 90,loss:0.6501557273188914\n",
      "Validation Loss: 0.6482254153206235,AUC: 0.6799666666666668,ACC:0.6873142857142858,F1:0.605545238095238,Precision:0.7783547619047619,Recall:0.5066785714285713\n",
      "Epoch 95,loss:0.6496774521399671\n",
      "Validation Loss: 0.6479332901182628,AUC: 0.6806547619047618,ACC:0.6878761904761904,F1:0.6063785714285713,Precision:0.7785833333333334,Recall:0.507647619047619\n",
      "Epoch 100,loss:0.6492505862018255\n",
      "Validation Loss: 0.6476664330278125,AUC: 0.6807166666666665,ACC:0.6880642857142857,F1:0.6087547619047619,Precision:0.7759904761904762,Recall:0.5117690476190476\n",
      "Epoch 105,loss:0.6488670913253244\n",
      "Validation Loss: 0.6474305930591765,AUC: 0.6812428571428574,ACC:0.6880642857142858,F1:0.6089095238095238,Precision:0.774454761904762,Recall:0.511852380952381\n",
      "Epoch 110,loss:0.6485142651505358\n",
      "Validation Loss: 0.6471928627718062,AUC: 0.681616666666667,ACC:0.6884357142857143,F1:0.6097690476190477,Precision:0.7740833333333332,Recall:0.5129904761904761\n",
      "Epoch 115,loss:0.6481757051362766\n",
      "Validation Loss: 0.6469478692327227,AUC: 0.681952380952381,ACC:0.6893642857142857,F1:0.6135833333333334,Precision:0.7720738095238096,Recall:0.5209190476190475\n",
      "Epoch 120,loss:0.6478552808911782\n",
      "Validation Loss: 0.6467163562774658,AUC: 0.6820761904761906,ACC:0.6901095238095238,F1:0.6131404761904763,Precision:0.7769642857142859,Recall:0.5195238095238095\n",
      "Epoch 125,loss:0.6475707550687114\n",
      "Validation Loss: 0.6466595658234188,AUC: 0.6822000000000001,ACC:0.6893666666666667,F1:0.6116357142857142,Precision:0.7754595238095238,Recall:0.5173476190476188\n",
      "Epoch 130,loss:0.6472826013414879\n",
      "Validation Loss: 0.646655607791174,AUC: 0.6823119047619046,ACC:0.6897357142857142,F1:0.6131214285714285,Precision:0.7718142857142858,Recall:0.5188761904761904\n",
      "Epoch 135,loss:0.6469795290879378\n",
      "Validation Loss: 0.6463115087577275,AUC: 0.6826714285714287,ACC:0.6901071428571428,F1:0.6132714285714286,Precision:0.7748214285714287,Recall:0.5188095238095238\n",
      "Epoch 140,loss:0.6467824662764241\n",
      "Validation Loss: 0.646112200759706,AUC: 0.6827571428571427,ACC:0.6899214285714285,F1:0.6139452380952383,Precision:0.7732166666666667,Recall:0.5205285714285713\n",
      "Epoch 145,loss:0.6465280928949672\n",
      "Validation Loss: 0.645996820359003,AUC: 0.6831000000000002,ACC:0.6912214285714284,F1:0.6149500000000001,Precision:0.7748714285714284,Recall:0.5206190476190475\n",
      "Epoch 150,loss:0.6462977486332571\n",
      "Validation Loss: 0.6457506560143971,AUC: 0.6827714285714285,ACC:0.6904761904761904,F1:0.6105261904761905,Precision:0.7824928571428571,Recall:0.5139761904761905\n",
      "Epoch 155,loss:0.6460796106518722\n",
      "Validation Loss: 0.6456324344589597,AUC: 0.6831642857142856,ACC:0.6908452380952379,F1:0.6119857142857145,Precision:0.7806285714285712,Recall:0.5147619047619048\n",
      "Epoch 160,loss:0.6458499356517642\n",
      "Validation Loss: 0.6454013926642281,AUC: 0.6834857142857143,ACC:0.6908476190476188,F1:0.6093857142857144,Precision:0.7879547619047622,Recall:0.5102928571428569\n",
      "Epoch 165,loss:0.6456407205326351\n",
      "Validation Loss: 0.6452582152116866,AUC: 0.6837928571428571,ACC:0.6906619047619046,F1:0.6099428571428572,Precision:0.7851880952380955,Recall:0.5114833333333332\n",
      "Epoch 170,loss:0.6455085653019702\n",
      "Validation Loss: 0.6451686805202848,AUC: 0.6837880952380953,ACC:0.6912190476190475,F1:0.6120952380952382,Precision:0.7852333333333336,Recall:0.5150547619047617\n",
      "Epoch 175,loss:0.6453656934377715\n",
      "Validation Loss: 0.6453207177775246,AUC: 0.6843214285714286,ACC:0.6910380952380951,F1:0.6196976190476192,Precision:0.7711642857142859,Recall:0.532590476190476\n",
      "早停策略触发，停止训练在第 174 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 09:04:30.597004 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 09:04:30.612166 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 09:04:30.625372 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 09:04:30.638335 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 09:04:30.651430 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 09:04:30.664214 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 09:04:30.677083 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 09:04:30.689895 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 09:04:30.702621 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 09:04:30.715759 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 09:04:30.728843 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 09:04:30.741573 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 09:04:30.754300 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 09:04:30.767245 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 09:04:30.780066 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 09:04:30.793218 -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 09:04:30.806477 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 09:04:30.819477 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 09:04:30.832313 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 09:04:30.845453 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 09:04:30.858664 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 09:04:30.871904 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 09:04:30.884627 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 09:04:30.897590 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 09:04:30.910347 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 09:04:30.923101 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 09:04:30.935801 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 09:04:30.948492 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 09:04:30.961178 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 09:04:30.973892 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 09:04:30.986641 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 09:04:31.000433 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 09:04:31.014048 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 09:04:31.026900 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 09:04:31.040042 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 09:04:31.052726 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 09:04:31.065433 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 09:04:31.078350 -------------\n",
      "||--测试：---------- 38 个batch运行时间： 2024-03-19 09:04:31.091128 -------------\n",
      "||--测试：---------- 39 个batch运行时间： 2024-03-19 09:04:31.103824 -------------\n",
      "||--测试：---------- 40 个batch运行时间： 2024-03-19 09:04:31.116803 -------------\n",
      "||--测试：---------- 41 个batch运行时间： 2024-03-19 09:04:31.129807 -------------\n",
      "||--测试：---------- 42 个batch运行时间： 2024-03-19 09:04:31.142867 -------------\n",
      "Test Loss: 0.6464159843467531,AUC: 0.6933499999999998,ACC:0.6995976190476193,F1:0.6172190476190474,Precision:0.7807809523809526,Recall:0.5195285714285716\n",
      "i=:3\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6831810436849519\n",
      "Validation Loss: 0.6815982773190453,AUC: 0.6221,ACC:0.6248142857142857,F1:0.5593595238095239,Precision:0.6554261904761907,Recall:0.5135119047619047\n",
      "Epoch 10,loss:0.6758365635796795\n",
      "Validation Loss: 0.6730680593422481,AUC: 0.6423357142857146,ACC:0.6519714285714286,F1:0.570409523809524,Precision:0.7081714285714286,Recall:0.49160000000000004\n",
      "Epoch 15,loss:0.6703836349990424\n",
      "Validation Loss: 0.6667630118983132,AUC: 0.6501166666666668,ACC:0.6597833333333332,F1:0.5705142857142859,Precision:0.7318523809523809,Recall:0.47919761904761904\n",
      "Epoch 20,loss:0.6664066882584039\n",
      "Validation Loss: 0.6623163294224512,AUC: 0.6563047619047621,ACC:0.666854761904762,F1:0.5835238095238096,Precision:0.7409023809523811,Recall:0.4931809523809523\n",
      "Epoch 25,loss:0.6634731945090406\n",
      "Validation Loss: 0.6592778733798436,AUC: 0.6594095238095237,ACC:0.6713142857142856,F1:0.5847214285714287,Precision:0.7501428571428572,Recall:0.4884238095238094\n",
      "Epoch 30,loss:0.6612339719073979\n",
      "Validation Loss: 0.657244663862955,AUC: 0.661952380952381,ACC:0.6728,F1:0.5936619047619048,Precision:0.7451499999999998,Recall:0.5030404761904762\n",
      "Epoch 35,loss:0.6595489246638742\n",
      "Validation Loss: 0.6558022868065607,AUC: 0.6634428571428572,ACC:0.6737309523809524,F1:0.5908309523809523,Precision:0.7548309523809523,Recall:0.49453571428571425\n",
      "Epoch 40,loss:0.6582470170156224\n",
      "Validation Loss: 0.6547561089197794,AUC: 0.6630595238095239,ACC:0.674840476190476,F1:0.5914809523809523,Precision:0.7568333333333334,Recall:0.4944690476190479\n",
      "Epoch 45,loss:0.6572294488666565\n",
      "Validation Loss: 0.6539339550903865,AUC: 0.6632142857142858,ACC:0.6757666666666665,F1:0.5924119047619046,Precision:0.7588309523809523,Recall:0.4947952380952383\n",
      "Epoch 50,loss:0.6564100403485336\n",
      "Validation Loss: 0.653252131882168,AUC: 0.6641738095238097,ACC:0.6770690476190475,F1:0.5960880952380953,Precision:0.7577071428571431,Recall:0.5007952380952383\n",
      "Epoch 55,loss:0.6556921422950864\n",
      "Validation Loss: 0.6525785766896748,AUC: 0.6647214285714286,ACC:0.6783738095238093,F1:0.5923000000000002,Precision:0.7666261904761907,Recall:0.4907\n",
      "Epoch 60,loss:0.6550653407892842\n",
      "Validation Loss: 0.6520783674149286,AUC: 0.6651690476190476,ACC:0.67875,F1:0.5912928571428572,Precision:0.7688571428571429,Recall:0.48856666666666665\n",
      "Epoch 65,loss:0.6545279176216426\n",
      "Validation Loss: 0.6516438935484204,AUC: 0.6653190476190476,ACC:0.6791214285714285,F1:0.5927452380952382,Precision:0.7677761904761905,Recall:0.491842857142857\n",
      "Epoch 70,loss:0.6540475614427581\n",
      "Validation Loss: 0.6512462369033268,AUC: 0.665747619047619,ACC:0.6798666666666667,F1:0.5920333333333334,Precision:0.7705547619047619,Recall:0.4891119047619047\n",
      "Epoch 75,loss:0.6536029797839368\n",
      "Validation Loss: 0.6509210893086025,AUC: 0.6661023809523811,ACC:0.6798666666666666,F1:0.5921809523809524,Precision:0.7701119047619047,Recall:0.48950476190476183\n",
      "Epoch 80,loss:0.6531967633352505\n",
      "Validation Loss: 0.6506192102318719,AUC: 0.6665857142857146,ACC:0.6783809523809523,F1:0.5927523809523809,Precision:0.7637238095238095,Recall:0.4905166666666667\n",
      "Epoch 85,loss:0.6528150697392742\n",
      "Validation Loss: 0.6503580212593079,AUC: 0.6667738095238095,ACC:0.6780095238095237,F1:0.5942095238095239,Precision:0.7601309523809522,Recall:0.4940809523809523\n",
      "Epoch 90,loss:0.65247588833486\n",
      "Validation Loss: 0.6501287846338182,AUC: 0.6664428571428572,ACC:0.6787523809523809,F1:0.5908238095238095,Precision:0.769447619047619,Recall:0.48634047619047616\n",
      "Epoch 95,loss:0.6521563422022842\n",
      "Validation Loss: 0.6499105635143462,AUC: 0.6666642857142857,ACC:0.6787523809523809,F1:0.5945333333333335,Precision:0.7617809523809523,Recall:0.49350714285714276\n",
      "Epoch 100,loss:0.6518547028068482\n",
      "Validation Loss: 0.6497296492258707,AUC: 0.6664785714285715,ACC:0.6789357142857142,F1:0.5953880952380954,Precision:0.7622047619047617,Recall:0.4952761904761904\n",
      "Epoch 105,loss:0.6515651978845671\n",
      "Validation Loss: 0.6495768200783503,AUC: 0.6664571428571427,ACC:0.67875,F1:0.5937595238095239,Precision:0.7641571428571429,Recall:0.4917166666666665\n",
      "Epoch 110,loss:0.6512900933505982\n",
      "Validation Loss: 0.6493879088333675,AUC: 0.6662285714285712,ACC:0.6796880952380951,F1:0.5930904761904764,Precision:0.7683071428571429,Recall:0.4894761904761903\n",
      "Epoch 115,loss:0.6510154187209963\n",
      "Validation Loss: 0.649217487800689,AUC: 0.666459523809524,ACC:0.6808023809523809,F1:0.5979309523809526,Precision:0.765745238095238,Recall:0.4986238095238094\n",
      "Epoch 120,loss:0.6507543996563108\n",
      "Validation Loss: 0.6490639164334252,AUC: 0.6666880952380954,ACC:0.6811785714285714,F1:0.5970666666666667,Precision:0.7695619047619049,Recall:0.4955904761904761\n",
      "Epoch 125,loss:0.6505173083365433\n",
      "Validation Loss: 0.6489142406554449,AUC: 0.6669023809523812,ACC:0.6817357142857142,F1:0.5981857142857144,Precision:0.7681928571428573,Recall:0.49752619047619057\n",
      "Epoch 130,loss:0.6502970072228139\n",
      "Validation Loss: 0.6487519059862409,AUC: 0.6675738095238096,ACC:0.6822928571428571,F1:0.5983380952380954,Precision:0.7690928571428572,Recall:0.4968357142857143\n",
      "Epoch 135,loss:0.6500880319302477\n",
      "Validation Loss: 0.648624986410141,AUC: 0.667592857142857,ACC:0.6824785714285714,F1:0.5970142857142859,Precision:0.7723642857142858,Recall:0.493547619047619\n",
      "Epoch 140,loss:0.6498901102486558\n",
      "Validation Loss: 0.6485291932310376,AUC: 0.6680095238095237,ACC:0.6834071428571429,F1:0.5967452380952383,Precision:0.7749595238095239,Recall:0.4919880952380952\n",
      "Epoch 145,loss:0.6496987633817778\n",
      "Validation Loss: 0.6484375737962269,AUC: 0.6685333333333334,ACC:0.682852380952381,F1:0.5966690476190477,Precision:0.7746023809523811,Recall:0.492052380952381\n",
      "Epoch 150,loss:0.6495125232719061\n",
      "Validation Loss: 0.648315117472694,AUC: 0.6689595238095238,ACC:0.6843380952380953,F1:0.5963523809523812,Precision:0.7802714285714286,Recall:0.4891952380952381\n",
      "Epoch 155,loss:0.6493351511129244\n",
      "Validation Loss: 0.6482235704149518,AUC: 0.6691452380952383,ACC:0.6845309523809525,F1:0.5972309523809526,Precision:0.7788523809523809,Recall:0.4907190476190476\n",
      "Epoch 160,loss:0.6491586519038584\n",
      "Validation Loss: 0.6481487098194304,AUC: 0.6692571428571428,ACC:0.6832238095238096,F1:0.5963714285714288,Precision:0.7753880952380954,Recall:0.49059285714285705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165,loss:0.6489741727123111\n",
      "Validation Loss: 0.6480073148295993,AUC: 0.6695142857142855,ACC:0.6839666666666666,F1:0.5937333333333336,Precision:0.7805095238095238,Recall:0.4850714285714285\n",
      "Epoch 170,loss:0.6487999483356326\n",
      "Validation Loss: 0.6479659194038028,AUC: 0.6693976190476191,ACC:0.6841547619047619,F1:0.5943357142857145,Precision:0.7802738095238096,Recall:0.4858261904761904\n",
      "Epoch 175,loss:0.6486355239950766\n",
      "Validation Loss: 0.6479691792102087,AUC: 0.6693595238095237,ACC:0.684897619047619,F1:0.5950000000000002,Precision:0.7826309523809526,Recall:0.485802380952381\n",
      "早停策略触发，停止训练在第 174 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 09:25:35.506740 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 09:25:35.520839 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 09:25:35.533459 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 09:25:35.546357 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 09:25:35.558977 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 09:25:35.571451 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 09:25:35.584963 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 09:25:35.597858 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 09:25:35.610405 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 09:25:35.623016 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 09:25:35.635553 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 09:25:35.648038 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 09:25:35.660930 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 09:25:35.673408 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 09:25:35.686248 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 09:25:35.699316 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 09:25:35.712364 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 09:25:35.724947 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 09:25:35.737409 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 09:25:35.749872 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 09:25:35.762308 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 09:25:35.774783 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 09:25:35.787604 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 09:25:35.800080 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 09:25:35.812463 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 09:25:35.824919 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 09:25:35.838272 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 09:25:35.850957 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 09:25:35.863808 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 09:25:35.876202 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 09:25:35.889086 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 09:25:35.901506 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 09:25:35.914508 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 09:25:35.927135 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 09:25:35.939695 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 09:25:35.952152 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 09:25:35.964865 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 09:25:35.977341 -------------\n",
      "||--测试：---------- 38 个batch运行时间： 2024-03-19 09:25:35.989973 -------------\n",
      "||--测试：---------- 39 个batch运行时间： 2024-03-19 09:25:36.002519 -------------\n",
      "||--测试：---------- 40 个batch运行时间： 2024-03-19 09:25:36.015884 -------------\n",
      "||--测试：---------- 41 个batch运行时间： 2024-03-19 09:25:36.028501 -------------\n",
      "||--测试：---------- 42 个batch运行时间： 2024-03-19 09:25:36.041036 -------------\n",
      "Test Loss: 0.6498700862839109,AUC: 0.672695238095238,ACC:0.6888071428571431,F1:0.5964380952380952,Precision:0.7707714285714286,Recall:0.49275952380952376\n",
      "i=:4\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6835810884716004\n",
      "Validation Loss: 0.6826925448008946,AUC: 0.6207380952380951,ACC:0.620342857142857,F1:0.5760738095238096,Precision:0.6299190476190477,Recall:0.5562285714285715\n",
      "Epoch 10,loss:0.6764130057312372\n",
      "Validation Loss: 0.674036287126087,AUC: 0.6460857142857142,ACC:0.6517833333333335,F1:0.577302380952381,Precision:0.6980285714285713,Recall:0.5048285714285716\n",
      "Epoch 15,loss:0.6711432516105532\n",
      "Validation Loss: 0.6678824978215354,AUC: 0.6572452380952379,ACC:0.6629452380952381,F1:0.5789166666666666,Precision:0.7295642857142857,Recall:0.49109761904761906\n",
      "Epoch 20,loss:0.667265183343662\n",
      "Validation Loss: 0.6634908375285921,AUC: 0.6643595238095238,ACC:0.6687095238095238,F1:0.5845642857142856,Precision:0.7447238095238096,Recall:0.4934023809523809\n",
      "Epoch 25,loss:0.6642710782411531\n",
      "Validation Loss: 0.660395126967203,AUC: 0.6686523809523808,ACC:0.6722476190476191,F1:0.5850547619047621,Precision:0.7598952380952382,Recall:0.4884928571428572\n",
      "Epoch 30,loss:0.6619381613618746\n",
      "Validation Loss: 0.658209577912376,AUC: 0.6705642857142857,ACC:0.6740999999999999,F1:0.5849095238095238,Precision:0.763352380952381,Recall:0.4833333333333333\n",
      "Epoch 35,loss:0.6601006792286249\n",
      "Validation Loss: 0.656553484144665,AUC: 0.6723095238095237,ACC:0.6772619047619047,F1:0.5980619047619049,Precision:0.7572119047619049,Recall:0.5047404761904762\n",
      "Epoch 40,loss:0.6586345190138329\n",
      "Validation Loss: 0.6552574407486689,AUC: 0.6727999999999998,ACC:0.6787476190476189,F1:0.6020404761904762,Precision:0.754947619047619,Recall:0.5125047619047619\n",
      "Epoch 45,loss:0.6574711259894483\n",
      "Validation Loss: 0.654166362115315,AUC: 0.6733952380952378,ACC:0.6807976190476189,F1:0.6002023809523808,Precision:0.766554761904762,Recall:0.5054119047619048\n",
      "Epoch 50,loss:0.6565695958813345\n",
      "Validation Loss: 0.6532535893576485,AUC: 0.6731285714285716,ACC:0.6811738095238095,F1:0.6042357142857141,Precision:0.7590357142857143,Recall:0.5119380952380952\n",
      "Epoch 55,loss:0.6557817886194844\n",
      "Validation Loss: 0.6525955554984865,AUC: 0.6736190476190476,ACC:0.6824761904761905,F1:0.6010142857142855,Precision:0.766616666666667,Recall:0.5030119047619047\n",
      "Epoch 60,loss:0.6551059038620296\n",
      "Validation Loss: 0.6519937756515685,AUC: 0.674052380952381,ACC:0.6826619047619047,F1:0.6010785714285712,Precision:0.7675380952380954,Recall:0.50265\n",
      "Epoch 65,loss:0.6545027499123821\n",
      "Validation Loss: 0.6514595732802436,AUC: 0.6743833333333333,ACC:0.6834023809523808,F1:0.6014214285714284,Precision:0.7697738095238096,Recall:0.502402380952381\n",
      "Epoch 70,loss:0.6539790813378462\n",
      "Validation Loss: 0.6510019245601836,AUC: 0.6748809523809525,ACC:0.6839619047619047,F1:0.598795238095238,Precision:0.7748095238095237,Recall:0.49672380952380973\n",
      "Epoch 75,loss:0.6535076358186918\n",
      "Validation Loss: 0.6505445837974548,AUC: 0.6753809523809523,ACC:0.6845190476190475,F1:0.5996428571428571,Precision:0.775797619047619,Recall:0.49752142857142867\n",
      "Epoch 80,loss:0.6530894594868337\n",
      "Validation Loss: 0.6501529741854895,AUC: 0.6757142857142856,ACC:0.6843357142857142,F1:0.6001619047619049,Precision:0.7756523809523809,Recall:0.49945238095238104\n",
      "Epoch 85,loss:0.6526944045945415\n",
      "Validation Loss: 0.6498028522446042,AUC: 0.6764738095238094,ACC:0.6843380952380952,F1:0.6010261904761907,Precision:0.7741714285714284,Recall:0.5008142857142858\n",
      "Epoch 90,loss:0.6523409584375817\n",
      "Validation Loss: 0.6495275554202852,AUC: 0.6766999999999999,ACC:0.6852714285714286,F1:0.6007738095238098,Precision:0.7798261904761903,Recall:0.49918333333333337\n",
      "Epoch 95,loss:0.652031410866835\n",
      "Validation Loss: 0.6492613156636556,AUC: 0.6773047619047617,ACC:0.6856404761904761,F1:0.603692857142857,Precision:0.774495238095238,Recall:0.5043809523809524\n",
      "Epoch 100,loss:0.6517320045336025\n",
      "Validation Loss: 0.649033899818148,AUC: 0.6778190476190477,ACC:0.6856428571428571,F1:0.6027785714285715,Precision:0.7766761904761904,Recall:0.502047619047619\n",
      "Epoch 105,loss:0.6514477584305711\n",
      "Validation Loss: 0.648822967495237,AUC: 0.6783190476190474,ACC:0.6852666666666666,F1:0.6028119047619047,Precision:0.7760357142857143,Recall:0.5015142857142857\n",
      "Epoch 110,loss:0.6511696947841193\n",
      "Validation Loss: 0.6487347923573994,AUC: 0.6783785714285715,ACC:0.686197619047619,F1:0.6030952380952381,Precision:0.7771500000000001,Recall:0.49968571428571434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115,loss:0.6509169396453016\n",
      "Validation Loss: 0.6484702825546265,AUC: 0.6784190476190475,ACC:0.6867547619047618,F1:0.6024285714285713,Precision:0.7826309523809523,Recall:0.49848095238095247\n",
      "Epoch 120,loss:0.6506849245762262\n",
      "Validation Loss: 0.6483431188833146,AUC: 0.6786476190476188,ACC:0.6865642857142855,F1:0.6049357142857142,Precision:0.7758333333333334,Recall:0.5038857142857143\n",
      "Epoch 125,loss:0.6504388010407997\n",
      "Validation Loss: 0.6483130298909687,AUC: 0.6787809523809526,ACC:0.6867523809523808,F1:0.6022738095238096,Precision:0.778557142857143,Recall:0.4977142857142857\n",
      "Epoch 130,loss:0.6501483710732047\n",
      "Validation Loss: 0.6481907353514716,AUC: 0.6792523809523809,ACC:0.6876833333333332,F1:0.6046833333333334,Precision:0.7762142857142857,Recall:0.5011476190476192\n",
      "Epoch 135,loss:0.6499518193597869\n",
      "Validation Loss: 0.6480912622951326,AUC: 0.6792595238095235,ACC:0.6884285714285714,F1:0.6042190476190478,Precision:0.779347619047619,Recall:0.4990166666666668\n",
      "Epoch 140,loss:0.6497202346644063\n",
      "Validation Loss: 0.6479539743491581,AUC: 0.6791857142857143,ACC:0.6882404761904761,F1:0.6044309523809526,Precision:0.7788833333333333,Recall:0.49990952380952375\n",
      "Epoch 145,loss:0.6494413970962284\n",
      "Validation Loss: 0.6478251431669507,AUC: 0.6794404761904761,ACC:0.6876857142857143,F1:0.6055738095238096,Precision:0.7749166666666667,Recall:0.5028142857142857\n",
      "Epoch 150,loss:0.649168074131012\n",
      "Validation Loss: 0.6477279379254296,AUC: 0.6792404761904762,ACC:0.6891738095238095,F1:0.6061880952380955,Precision:0.7787928571428571,Recall:0.5016214285714286\n",
      "Epoch 155,loss:0.6488559846802959\n",
      "Validation Loss: 0.6475914603187924,AUC: 0.6795095238095238,ACC:0.689545238095238,F1:0.6066738095238096,Precision:0.7790857142857144,Recall:0.502295238095238\n",
      "Epoch 160,loss:0.6485389949768547\n",
      "Validation Loss: 0.6474323244321913,AUC: 0.6801428571428572,ACC:0.6891738095238094,F1:0.6042809523809526,Precision:0.7824190476190477,Recall:0.4983571428571429\n",
      "Epoch 165,loss:0.6482283388535808\n",
      "Validation Loss: 0.6472368439038595,AUC: 0.6802380952380953,ACC:0.6891738095238094,F1:0.6061190476190478,Precision:0.7788142857142857,Recall:0.5010547619047618\n",
      "Epoch 170,loss:0.6479150084998664\n",
      "Validation Loss: 0.6470318081833067,AUC: 0.6805095238095237,ACC:0.6902880952380951,F1:0.6073190476190476,Precision:0.7836904761904762,Recall:0.5028738095238096\n",
      "Epoch 175,loss:0.6476369349975285\n",
      "Validation Loss: 0.6468193162055242,AUC: 0.680595238095238,ACC:0.689547619047619,F1:0.6072666666666666,Precision:0.7807928571428572,Recall:0.5027880952380952\n",
      "Epoch 180,loss:0.6473716145425331\n",
      "Validation Loss: 0.6466444730758667,AUC: 0.6809714285714283,ACC:0.6897309523809523,F1:0.6066261904761904,Precision:0.7832833333333336,Recall:0.5020238095238094\n",
      "Epoch 185,loss:0.6471205330270482\n",
      "Validation Loss: 0.6464775020167941,AUC: 0.6815357142857144,ACC:0.6901023809523809,F1:0.605459523809524,Precision:0.7863071428571429,Recall:0.49974999999999997\n",
      "Epoch 190,loss:0.646882361783756\n",
      "Validation Loss: 0.6463268995285034,AUC: 0.681995238095238,ACC:0.6906619047619047,F1:0.6058261904761905,Precision:0.7873285714285714,Recall:0.4992095238095239\n",
      "Epoch 195,loss:0.6466595159740899\n",
      "Validation Loss: 0.6462060738177526,AUC: 0.6818523809523811,ACC:0.6902928571428572,F1:0.6049666666666667,Precision:0.7908047619047619,Recall:0.49861190476190476\n",
      "Epoch 200,loss:0.646454446897732\n",
      "Validation Loss: 0.6460781977290199,AUC: 0.6819571428571429,ACC:0.6904785714285714,F1:0.6060190476190476,Precision:0.7884333333333334,Recall:0.5000857142857144\n",
      "Epoch 205,loss:0.6462532436753822\n",
      "Validation Loss: 0.6459889000370389,AUC: 0.6821595238095237,ACC:0.6902952380952381,F1:0.6071047619047618,Precision:0.7862357142857144,Recall:0.5024880952380952\n",
      "Epoch 210,loss:0.6460463188764617\n",
      "Validation Loss: 0.6458927378768012,AUC: 0.6828452380952382,ACC:0.6904809523809524,F1:0.6071619047619047,Precision:0.7875500000000002,Recall:0.5029071428571428\n",
      "Epoch 215,loss:0.6458545575930378\n",
      "Validation Loss: 0.645750166404815,AUC: 0.6831952380952382,ACC:0.6902952380952381,F1:0.6075404761904762,Precision:0.7868809523809523,Recall:0.5040071428571429\n",
      "Epoch 220,loss:0.6456691275431415\n",
      "Validation Loss: 0.6455288926760355,AUC: 0.6834309523809525,ACC:0.690852380952381,F1:0.6077880952380953,Precision:0.7881047619047619,Recall:0.5034595238095237\n",
      "Epoch 225,loss:0.6454987892015712\n",
      "Validation Loss: 0.6454435899144128,AUC: 0.6831285714285714,ACC:0.6914119047619047,F1:0.6081119047619048,Precision:0.7878238095238097,Recall:0.5024261904761905\n",
      "Epoch 230,loss:0.6453169349610336\n",
      "Validation Loss: 0.6453386218774886,AUC: 0.6827738095238095,ACC:0.6917833333333333,F1:0.6075285714285714,Precision:0.7907761904761905,Recall:0.5005642857142857\n",
      "Epoch 235,loss:0.6451176860201078\n",
      "Validation Loss: 0.6452456556615376,AUC: 0.6828619047619048,ACC:0.6917857142857142,F1:0.6084999999999999,Precision:0.7886857142857143,Recall:0.5028\n",
      "Epoch 240,loss:0.6449778694806136\n",
      "Validation Loss: 0.6451724129063743,AUC: 0.6832642857142858,ACC:0.6921595238095237,F1:0.6080261904761904,Precision:0.7904857142857143,Recall:0.5017452380952381\n",
      "Epoch 245,loss:0.644773261753593\n",
      "Validation Loss: 0.6450733102503277,AUC: 0.6834071428571429,ACC:0.6919738095238095,F1:0.6088738095238094,Precision:0.7881190476190476,Recall:0.5034095238095239\n",
      "Epoch 250,loss:0.6446382323587974\n",
      "Validation Loss: 0.6450603831382025,AUC: 0.6836880952380954,ACC:0.6916,F1:0.606497619047619,Precision:0.7912785714285714,Recall:0.5000619047619048\n",
      "Epoch 255,loss:0.6444296944798447\n",
      "Validation Loss: 0.6449589502243769,AUC: 0.6838285714285715,ACC:0.6912238095238094,F1:0.6059642857142857,Precision:0.7905857142857144,Recall:0.49904761904761896\n",
      "Epoch 260,loss:0.6442277159277848\n",
      "Validation Loss: 0.6448793993109748,AUC: 0.6836595238095237,ACC:0.6912261904761904,F1:0.6075976190476191,Precision:0.7889190476190476,Recall:0.5030023809523809\n",
      "Epoch 265,loss:0.6440448559175326\n",
      "Validation Loss: 0.6448516008399782,AUC: 0.6843452380952378,ACC:0.6925261904761904,F1:0.6094500000000002,Precision:0.788754761904762,Recall:0.5046333333333334\n",
      "Epoch 270,loss:0.6438627163256248\n",
      "Validation Loss: 0.6448057563531966,AUC: 0.68465,ACC:0.6925285714285714,F1:0.6098428571428572,Precision:0.7883119047619047,Recall:0.5055595238095238\n",
      "Epoch 275,loss:0.6436960650241281\n",
      "Validation Loss: 0.6447267418815976,AUC: 0.6847976190476192,ACC:0.6929000000000001,F1:0.6102309523809525,Precision:0.7892238095238097,Recall:0.5063190476190476\n",
      "Epoch 280,loss:0.6435185539440846\n",
      "Validation Loss: 0.644626817532948,AUC: 0.6852500000000001,ACC:0.6925285714285715,F1:0.6110357142857143,Precision:0.7867619047619047,Recall:0.5089309523809522\n",
      "Epoch 285,loss:0.6433116774859391\n",
      "Validation Loss: 0.6445557262216296,AUC: 0.6854642857142856,ACC:0.693642857142857,F1:0.6132833333333334,Precision:0.7872666666666664,Recall:0.5117238095238095\n",
      "Epoch 290,loss:0.6431050117560259\n",
      "Validation Loss: 0.644444553625016,AUC: 0.6858642857142856,ACC:0.6941999999999999,F1:0.6128071428571429,Precision:0.7893380952380953,Recall:0.5107976190476189\n",
      "Epoch 295,loss:0.642882424546039\n",
      "Validation Loss: 0.6443644307908558,AUC: 0.6865285714285716,ACC:0.6942023809523808,F1:0.6149976190476191,Precision:0.7860047619047619,Recall:0.5156642857142855\n",
      "Epoch 300,loss:0.6426828142226212\n",
      "Validation Loss: 0.6442919969558716,AUC: 0.6868428571428572,ACC:0.6943880952380953,F1:0.6148190476190477,Precision:0.7855738095238096,Recall:0.5153476190476189\n",
      "Epoch 305,loss:0.6424610628856449\n",
      "Validation Loss: 0.6442539918990362,AUC: 0.6869952380952379,ACC:0.6945690476190476,F1:0.6190642857142856,Precision:0.7762571428571428,Recall:0.5220928571428571\n",
      "Epoch 310,loss:0.6422407598946038\n",
      "Validation Loss: 0.6441769628297715,AUC: 0.687152380952381,ACC:0.6956857142857142,F1:0.6170833333333332,Precision:0.7818166666666667,Recall:0.517295238095238\n",
      "Epoch 315,loss:0.6420390587153397\n",
      "Validation Loss: 0.6440772371632713,AUC: 0.6873333333333332,ACC:0.6956833333333333,F1:0.6192761904761905,Precision:0.7772238095238095,Recall:0.5215071428571428\n",
      "Epoch 320,loss:0.6418832310541408\n",
      "Validation Loss: 0.6439779883339292,AUC: 0.6876142857142858,ACC:0.6971738095238095,F1:0.6204547619047619,Precision:0.7804357142857143,Recall:0.5219309523809523\n",
      "Epoch 325,loss:0.641626446265874\n",
      "Validation Loss: 0.6438610426017216,AUC: 0.6880642857142857,ACC:0.6956857142857141,F1:0.6221476190476191,Precision:0.7762190476190478,Recall:0.5264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330,loss:0.6414057213490404\n",
      "Validation Loss: 0.6437571133886065,AUC: 0.6878047619047619,ACC:0.697542857142857,F1:0.6243595238095241,Precision:0.7777238095238097,Recall:0.5290619047619047\n",
      "Epoch 335,loss:0.6410575147688858\n",
      "Validation Loss: 0.6439149535837627,AUC: 0.6876928571428572,ACC:0.6967976190476189,F1:0.6261380952380954,Precision:0.7713095238095239,Recall:0.5359095238095237\n",
      "早停策略触发，停止训练在第 334 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 10:04:38.343414 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 10:04:38.356564 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 10:04:38.369068 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 10:04:38.381737 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 10:04:38.394392 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 10:04:38.407407 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 10:04:38.420338 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 10:04:38.432990 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 10:04:38.445899 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 10:04:38.458985 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 10:04:38.471603 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 10:04:38.485146 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 10:04:38.497787 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 10:04:38.510372 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 10:04:38.522965 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 10:04:38.535508 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 10:04:38.548809 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 10:04:38.561519 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 10:04:38.574109 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 10:04:38.586663 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 10:04:38.599181 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 10:04:38.611765 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 10:04:38.624329 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 10:04:38.636853 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 10:04:38.649379 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 10:04:38.662424 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 10:04:38.675067 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 10:04:38.687730 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 10:04:38.700243 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 10:04:38.712816 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 10:04:38.725354 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 10:04:38.737825 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 10:04:38.751982 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 10:04:38.764687 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 10:04:38.777639 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 10:04:38.790157 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 10:04:38.802754 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 10:04:38.815676 -------------\n",
      "||--测试：---------- 38 个batch运行时间： 2024-03-19 10:04:38.828628 -------------\n",
      "||--测试：---------- 39 个batch运行时间： 2024-03-19 10:04:38.841155 -------------\n",
      "||--测试：---------- 40 个batch运行时间： 2024-03-19 10:04:38.854642 -------------\n",
      "||--测试：---------- 41 个batch运行时间： 2024-03-19 10:04:38.867203 -------------\n",
      "||--测试：---------- 42 个batch运行时间： 2024-03-19 10:04:38.880200 -------------\n",
      "Test Loss: 0.6429910773322696,AUC: 0.7008095238095239,ACC:0.7090809523809525,F1:0.6408976190476191,Precision:0.7718047619047619,Recall:0.5565761904761904\n",
      "i=:5\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6848895376122842\n",
      "Validation Loss: 0.6842701662154425,AUC: 0.6145476190476189,ACC:0.6162595238095238,F1:0.5832142857142858,Precision:0.6134761904761903,Recall:0.5792499999999999\n",
      "Epoch 10,loss:0.6781360521091251\n",
      "Validation Loss: 0.6758475800355276,AUC: 0.6412833333333334,ACC:0.6473190476190477,F1:0.5808452380952379,Precision:0.6822238095238097,Recall:0.5194166666666669\n",
      "Epoch 15,loss:0.6728465585258063\n",
      "Validation Loss: 0.6696381299268632,AUC: 0.6525047619047621,ACC:0.6616380952380952,F1:0.5778309523809523,Precision:0.7242738095238097,Recall:0.4877976190476191\n",
      "Epoch 20,loss:0.6689522782648643\n",
      "Validation Loss: 0.665231127114523,AUC: 0.6595738095238095,ACC:0.6660999999999999,F1:0.5858571428571429,Precision:0.7292095238095239,Recall:0.49931666666666674\n",
      "Epoch 25,loss:0.6660033929066396\n",
      "Validation Loss: 0.6619862275464194,AUC: 0.6637071428571427,ACC:0.6700119047619045,F1:0.5847309523809525,Precision:0.7444928571428574,Recall:0.4938309523809525\n",
      "Epoch 30,loss:0.663706165599072\n",
      "Validation Loss: 0.6595502226125627,AUC: 0.6666452380952382,ACC:0.6711238095238095,F1:0.5806738095238094,Precision:0.7548428571428573,Recall:0.48254761904761895\n",
      "Epoch 35,loss:0.6618537358411654\n",
      "Validation Loss: 0.65771841719037,AUC: 0.6694428571428572,ACC:0.6727976190476189,F1:0.5837523809523809,Precision:0.7574309523809524,Recall:0.4861047619047618\n",
      "Epoch 40,loss:0.6603197333380932\n",
      "Validation Loss: 0.6564892388525463,AUC: 0.6711833333333332,ACC:0.6750285714285714,F1:0.5864761904761905,Precision:0.7627690476190475,Recall:0.4879261904761905\n",
      "Epoch 45,loss:0.6590686975501654\n",
      "Validation Loss: 0.6554947467077346,AUC: 0.671697619047619,ACC:0.6776333333333332,F1:0.5889785714285715,Precision:0.7695738095238094,Recall:0.48793571428571425\n",
      "Epoch 50,loss:0.6580538848253685\n",
      "Validation Loss: 0.6546056384132022,AUC: 0.6718380952380953,ACC:0.6798714285714285,F1:0.5948476190476191,Precision:0.7678499999999999,Recall:0.4950595238095237\n",
      "Epoch 55,loss:0.6570582023755772\n",
      "Validation Loss: 0.6537388194174993,AUC: 0.672997619047619,ACC:0.6822904761904761,F1:0.5952,Precision:0.7754476190476192,Recall:0.49315476190476176\n",
      "Epoch 60,loss:0.6562667010337349\n",
      "Validation Loss: 0.652982554265431,AUC: 0.672954761904762,ACC:0.682842857142857,F1:0.5890642857142858,Precision:0.7837857142857142,Recall:0.48087619047619046\n",
      "Epoch 65,loss:0.6556078913643604\n",
      "Validation Loss: 0.6523742079734802,AUC: 0.673909523809524,ACC:0.6822833333333331,F1:0.5898000000000001,Precision:0.7808857142857144,Recall:0.4824404761904762\n",
      "Epoch 70,loss:0.6549436464084415\n",
      "Validation Loss: 0.6518711845080057,AUC: 0.6733857142857145,ACC:0.6813547619047617,F1:0.5919952380952382,Precision:0.7742166666666668,Recall:0.4869666666666665\n",
      "Epoch 75,loss:0.6543437223734818\n",
      "Validation Loss: 0.6511988781747364,AUC: 0.6741904761904761,ACC:0.6813547619047617,F1:0.5930095238095239,Precision:0.7739595238095239,Recall:0.48927857142857145\n",
      "Epoch 80,loss:0.653815656196414\n",
      "Validation Loss: 0.6509377573217664,AUC: 0.674395238095238,ACC:0.68285,F1:0.5957619047619049,Precision:0.7753119047619049,Recall:0.4927714285714286\n",
      "Epoch 85,loss:0.6533077382665919\n",
      "Validation Loss: 0.6504970164526076,AUC: 0.6743976190476191,ACC:0.6826666666666666,F1:0.5944071428571429,Precision:0.7756380952380952,Recall:0.4892642857142857\n",
      "Epoch 90,loss:0.6528026391202071\n",
      "Validation Loss: 0.6497807644662403,AUC: 0.6752047619047619,ACC:0.6824738095238094,F1:0.6000595238095238,Precision:0.768459523809524,Recall:0.5008214285714285\n",
      "Epoch 95,loss:0.6524024389860198\n",
      "Validation Loss: 0.649427185455958,AUC: 0.675345238095238,ACC:0.6826595238095238,F1:0.6026761904761905,Precision:0.7660690476190478,Recall:0.50645\n",
      "Epoch 100,loss:0.6520104530289417\n",
      "Validation Loss: 0.6490817822161175,AUC: 0.6758666666666665,ACC:0.6833999999999999,F1:0.5982571428571427,Precision:0.7741690476190479,Recall:0.49590952380952386\n",
      "Epoch 105,loss:0.6515970868388499\n",
      "Validation Loss: 0.6487015386422476,AUC: 0.6760785714285714,ACC:0.6839571428571427,F1:0.5949166666666665,Precision:0.7825095238095239,Recall:0.4894071428571428\n",
      "Epoch 110,loss:0.6512659731812365\n",
      "Validation Loss: 0.648472805817922,AUC: 0.6761404761904761,ACC:0.6839571428571427,F1:0.5950714285714286,Precision:0.7828666666666665,Recall:0.4896642857142857\n",
      "Epoch 115,loss:0.6509341682036092\n",
      "Validation Loss: 0.6481689243089586,AUC: 0.6764357142857141,ACC:0.6841428571428569,F1:0.594845238095238,Precision:0.7827738095238095,Recall:0.4881166666666667\n",
      "Epoch 120,loss:0.6506783793291707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6480024755001068,AUC: 0.6764047619047618,ACC:0.6847023809523809,F1:0.5978738095238095,Precision:0.7801261904761906,Recall:0.4938714285714286\n",
      "Epoch 125,loss:0.6503637273480573\n",
      "Validation Loss: 0.6477386695998055,AUC: 0.6765785714285715,ACC:0.6845142857142855,F1:0.597545238095238,Precision:0.7810333333333335,Recall:0.49360714285714286\n",
      "Epoch 130,loss:0.6501067829883005\n",
      "Validation Loss: 0.6475919584433237,AUC: 0.6760357142857142,ACC:0.6850738095238095,F1:0.5976285714285713,Precision:0.7814380952380953,Recall:0.4926190476190476\n",
      "Epoch 135,loss:0.6498207881694703\n",
      "Validation Loss: 0.6474282628013974,AUC: 0.6756261904761903,ACC:0.6852595238095237,F1:0.5970857142857141,Precision:0.7832333333333333,Recall:0.49107142857142855\n",
      "Epoch 140,loss:0.6496084557743523\n",
      "Validation Loss: 0.64739857117335,AUC: 0.6751261904761904,ACC:0.6858190476190476,F1:0.5968190476190477,Precision:0.78625,Recall:0.4901095238095238\n",
      "Epoch 145,loss:0.6494277410619841\n",
      "Validation Loss: 0.6472661764848799,AUC: 0.6746571428571428,ACC:0.685447619047619,F1:0.5958642857142857,Precision:0.7870690476190474,Recall:0.4878761904761903\n",
      "Epoch 150,loss:0.649189388658118\n",
      "Validation Loss: 0.6469904993261609,AUC: 0.6743642857142857,ACC:0.686190476190476,F1:0.5967738095238095,Precision:0.7880928571428572,Recall:0.48886666666666656\n",
      "Epoch 155,loss:0.6489870815765201\n",
      "Validation Loss: 0.6469092652911231,AUC: 0.6742095238095237,ACC:0.6856333333333333,F1:0.5947857142857143,Precision:0.7892690476190476,Recall:0.48566904761904744\n",
      "Epoch 160,loss:0.6487521468185065\n",
      "Validation Loss: 0.6467869182427725,AUC: 0.6738595238095239,ACC:0.68545,F1:0.5947904761904761,Precision:0.7885357142857143,Recall:0.48633333333333323\n",
      "Epoch 165,loss:0.648573366206462\n",
      "Validation Loss: 0.6466173288368043,AUC: 0.6734523809523812,ACC:0.68545,F1:0.5942761904761904,Precision:0.7878809523809522,Recall:0.48396190476190465\n",
      "Epoch 170,loss:0.6483736699960363\n",
      "Validation Loss: 0.646459060055869,AUC: 0.6730642857142857,ACC:0.6854452380952379,F1:0.5929904761904762,Precision:0.7906738095238094,Recall:0.48158571428571423\n",
      "Epoch 175,loss:0.6481953038005378\n",
      "Validation Loss: 0.64654369865145,AUC: 0.6735023809523809,ACC:0.6845142857142855,F1:0.59915,Precision:0.7803476190476192,Recall:0.49810714285714297\n",
      "早停策略触发，停止训练在第 174 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 10:30:51.971699 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 10:30:51.985416 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 10:30:51.998150 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 10:30:52.011821 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 10:30:52.024494 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 10:30:52.037208 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 10:30:52.050003 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 10:30:52.063058 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 10:30:52.075755 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 10:30:52.088442 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 10:30:52.101194 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 10:30:52.114027 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 10:30:52.127267 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 10:30:52.139971 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 10:30:52.152651 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 10:30:52.165810 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 10:30:52.179440 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 10:30:52.192270 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 10:30:52.205024 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 10:30:52.217756 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 10:30:52.230454 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 10:30:52.243217 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 10:30:52.256844 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 10:30:52.270468 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 10:30:52.284387 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 10:30:52.302874 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 10:30:52.319874 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 10:30:52.334559 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 10:30:52.349646 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 10:30:52.364018 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 10:30:52.383823 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 10:30:52.398776 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 10:30:52.412430 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 10:30:52.426321 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 10:30:52.440502 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 10:30:52.454427 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 10:30:52.468035 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 10:30:52.482448 -------------\n",
      "||--测试：---------- 38 个batch运行时间： 2024-03-19 10:30:52.496028 -------------\n",
      "||--测试：---------- 39 个batch运行时间： 2024-03-19 10:30:52.509867 -------------\n",
      "||--测试：---------- 40 个batch运行时间： 2024-03-19 10:30:52.524454 -------------\n",
      "||--测试：---------- 41 个batch运行时间： 2024-03-19 10:30:52.537946 -------------\n",
      "||--测试：---------- 42 个batch运行时间： 2024-03-19 10:30:52.551319 -------------\n",
      "Test Loss: 0.6493555293196723,AUC: 0.6803714285714287,ACC:0.6914023809523808,F1:0.5999047619047619,Precision:0.7770357142857143,Recall:0.49689285714285714\n",
      "结果已输出\n",
      "||--------当前时间窗 1101_1130 结束时间： 2024-03-19 10:30:52.569303 -------------\n",
      "i=:1\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6833481568051135\n",
      "Validation Loss: 0.6797309560435159,AUC: 0.6146404761904761,ACC:0.6218380952380952,F1:0.5592547619047619,Precision:0.6525166666666665,Recall:0.5199404761904761\n",
      "Epoch 10,loss:0.6818119090373121\n",
      "Validation Loss: 0.6782402566501072,AUC: 0.6179499999999999,ACC:0.6199785714285714,F1:0.5479523809523809,Precision:0.6594071428571427,Recall:0.5036142857142858\n",
      "Epoch 15,loss:0.6805820971962036\n",
      "Validation Loss: 0.6770179995468685,AUC: 0.6197857142857144,ACC:0.6220285714285714,F1:0.5329452380952381,Precision:0.6820023809523809,Recall:0.4788595238095238\n",
      "Epoch 20,loss:0.679425670875339\n",
      "Validation Loss: 0.6762147701921917,AUC: 0.6206214285714288,ACC:0.623697619047619,F1:0.542354761904762,Precision:0.674852380952381,Recall:0.491445238095238\n",
      "Epoch 25,loss:0.6782942808519198\n",
      "Validation Loss: 0.6750509455090478,AUC: 0.6221714285714286,ACC:0.6251880952380953,F1:0.5413547619047618,Precision:0.6832809523809524,Recall:0.48901666666666666\n",
      "Epoch 30,loss:0.6771575808525085\n",
      "Validation Loss: 0.6738743072464353,AUC: 0.623697619047619,ACC:0.6300214285714285,F1:0.5364642857142856,Precision:0.6939738095238096,Recall:0.4732547619047618\n",
      "Epoch 35,loss:0.6760409619864516\n",
      "Validation Loss: 0.6727564036846161,AUC: 0.6248380952380954,ACC:0.6320738095238096,F1:0.5436023809523809,Precision:0.6885071428571428,Recall:0.4777214285714284\n",
      "Epoch 40,loss:0.6749195203067749\n",
      "Validation Loss: 0.6715890126568931,AUC: 0.6258809523809523,ACC:0.631697619047619,F1:0.5424428571428572,Precision:0.6923047619047618,Recall:0.47908095238095233\n",
      "Epoch 45,loss:0.6738147496238468\n",
      "Validation Loss: 0.6704709246045067,AUC: 0.6275809523809524,ACC:0.6331833333333333,F1:0.5323333333333333,Precision:0.7051142857142856,Recall:0.4585809523809524\n",
      "Epoch 50,loss:0.6726987113164166\n",
      "Validation Loss: 0.669476819889886,AUC: 0.6294261904761902,ACC:0.636904761904762,F1:0.5419285714285714,Precision:0.7031999999999999,Recall:0.46709285714285703\n",
      "Epoch 55,loss:0.6715909604012497\n",
      "Validation Loss: 0.6685957071327028,AUC: 0.6306976190476191,ACC:0.6378309523809522,F1:0.5416047619047618,Precision:0.7085142857142858,Recall:0.4626904761904762\n",
      "Epoch 60,loss:0.670558336682207\n",
      "Validation Loss: 0.6678255753857749,AUC: 0.6325214285714287,ACC:0.639690476190476,F1:0.5510119047619049,Precision:0.7066976190476192,Recall:0.4754785714285713\n",
      "Epoch 65,loss:0.669612434905345\n",
      "Validation Loss: 0.667135979448046,AUC: 0.6331595238095239,ACC:0.6428499999999998,F1:0.5541309523809524,Precision:0.7068095238095237,Recall:0.4755523809523809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70,loss:0.6687234011222059\n",
      "Validation Loss: 0.6664773566382272,AUC: 0.6344547619047619,ACC:0.6430380952380952,F1:0.5465785714285715,Precision:0.716147619047619,Recall:0.45749285714285715\n",
      "Epoch 75,loss:0.6678140022623258\n",
      "Validation Loss: 0.6655127973783583,AUC: 0.6370190476190478,ACC:0.6469380952380951,F1:0.5591952380952381,Precision:0.7133380952380952,Recall:0.4751690476190477\n",
      "Epoch 80,loss:0.6664081258097971\n",
      "Validation Loss: 0.6641996346768879,AUC: 0.6396857142857143,ACC:0.6478690476190475,F1:0.5597,Precision:0.7217309523809524,Recall:0.4736071428571429\n",
      "Epoch 85,loss:0.6649922493874557\n",
      "Validation Loss: 0.6629024602117992,AUC: 0.6435999999999998,ACC:0.6523380952380953,F1:0.5646071428571429,Precision:0.7245666666666667,Recall:0.48023333333333323\n",
      "Epoch 90,loss:0.6639633685585082\n",
      "Validation Loss: 0.6621419021061489,AUC: 0.6461690476190475,ACC:0.6523380952380952,F1:0.5629595238095237,Precision:0.7286785714285713,Recall:0.4737571428571429\n",
      "Epoch 95,loss:0.6631427543369803\n",
      "Validation Loss: 0.6615066939876193,AUC: 0.6475809523809525,ACC:0.6528999999999999,F1:0.5724333333333335,Precision:0.7212142857142858,Recall:0.4948833333333334\n",
      "Epoch 100,loss:0.662372866014796\n",
      "Validation Loss: 0.6608749642258599,AUC: 0.6499380952380952,ACC:0.6525238095238094,F1:0.5666142857142858,Precision:0.7252904761904764,Recall:0.4817\n",
      "Epoch 105,loss:0.6616790674802825\n",
      "Validation Loss: 0.6603271947020576,AUC: 0.6511023809523808,ACC:0.653452380952381,F1:0.5652571428571429,Precision:0.7302071428571429,Recall:0.4740595238095237\n",
      "Epoch 110,loss:0.6610080979940459\n",
      "Validation Loss: 0.6597670685677302,AUC: 0.6526619047619047,ACC:0.6566142857142857,F1:0.5708404761904762,Precision:0.7328357142857145,Recall:0.4845761904761904\n",
      "Epoch 115,loss:0.6603731034308906\n",
      "Validation Loss: 0.6592734101272765,AUC: 0.6533619047619047,ACC:0.6571714285714285,F1:0.5682976190476191,Precision:0.7377261904761907,Recall:0.4789928571428571\n",
      "Epoch 120,loss:0.6597826147642661\n",
      "Validation Loss: 0.6587738635994139,AUC: 0.6541714285714286,ACC:0.6569904761904762,F1:0.5624261904761905,Precision:0.7476119047619048,Recall:0.46884523809523804\n",
      "Epoch 125,loss:0.6592218889964847\n",
      "Validation Loss: 0.6583283884184701,AUC: 0.655202380952381,ACC:0.6571785714285715,F1:0.5617333333333334,Precision:0.7517047619047619,Recall:0.4651666666666666\n",
      "Epoch 130,loss:0.6586898715477291\n",
      "Validation Loss: 0.6579103115059081,AUC: 0.6560833333333334,ACC:0.6594119047619048,F1:0.5640690476190476,Precision:0.7526333333333333,Recall:0.46512380952380944\n",
      "Epoch 135,loss:0.658180312847528\n",
      "Validation Loss: 0.6574781082925343,AUC: 0.6568142857142858,ACC:0.6586714285714286,F1:0.5644619047619047,Precision:0.7524309523809524,Recall:0.4651714285714285\n",
      "Epoch 140,loss:0.6577109915065015\n",
      "Validation Loss: 0.6570747977211362,AUC: 0.657585714285714,ACC:0.6599738095238096,F1:0.563197619047619,Precision:0.7563595238095238,Recall:0.4590380952380953\n",
      "Epoch 145,loss:0.6572567797082616\n",
      "Validation Loss: 0.6566822954586574,AUC: 0.658057142857143,ACC:0.6616500000000001,F1:0.5640261904761906,Precision:0.761102380952381,Recall:0.45895714285714295\n",
      "Epoch 150,loss:0.6568303061282541\n",
      "Validation Loss: 0.6563535559745062,AUC: 0.6589833333333333,ACC:0.6622047619047619,F1:0.5642619047619049,Precision:0.7640190476190478,Recall:0.45879523809523803\n",
      "Epoch 155,loss:0.6563993363868533\n",
      "Validation Loss: 0.6560294599760146,AUC: 0.6597285714285712,ACC:0.6636952380952381,F1:0.5697476190476192,Precision:0.7569738095238097,Recall:0.4664333333333334\n",
      "Epoch 160,loss:0.6560199002581318\n",
      "Validation Loss: 0.6557632684707642,AUC: 0.6601476190476193,ACC:0.6642499999999999,F1:0.5665142857142857,Precision:0.7647261904761904,Recall:0.4615595238095239\n",
      "Epoch 165,loss:0.6556226118343083\n",
      "Validation Loss: 0.6555389350368863,AUC: 0.6605761904761904,ACC:0.6640619047619046,F1:0.5718166666666666,Precision:0.7619642857142859,Recall:0.4718642857142858\n",
      "Epoch 170,loss:0.6552701221676324\n",
      "Validation Loss: 0.6553305628753844,AUC: 0.660292857142857,ACC:0.6644285714285713,F1:0.5663095238095239,Precision:0.7691619047619047,Recall:0.46010714285714305\n",
      "Epoch 175,loss:0.654889570446465\n",
      "Validation Loss: 0.6551446446350643,AUC: 0.6606714285714286,ACC:0.6636833333333332,F1:0.5720214285714286,Precision:0.7594238095238095,Recall:0.4724285714285716\n",
      "Epoch 180,loss:0.6546103367655296\n",
      "Validation Loss: 0.6549728612105051,AUC: 0.6610238095238095,ACC:0.662195238095238,F1:0.5680833333333334,Precision:0.7630809523809525,Recall:0.46816190476190467\n",
      "Epoch 185,loss:0.6542670393553306\n",
      "Validation Loss: 0.6548711402075631,AUC: 0.6616547619047619,ACC:0.663685714285714,F1:0.5716000000000002,Precision:0.7597190476190477,Recall:0.46996666666666653\n",
      "Epoch 190,loss:0.6539618307211268\n",
      "Validation Loss: 0.6548084574086326,AUC: 0.6621785714285713,ACC:0.6642428571428569,F1:0.5664095238095237,Precision:0.7706976190476191,Recall:0.46241428571428567\n",
      "Epoch 195,loss:0.6536824764229181\n",
      "Validation Loss: 0.6547218206382933,AUC: 0.6626357142857143,ACC:0.6634976190476188,F1:0.5680023809523809,Precision:0.7643761904761903,Recall:0.46569523809523805\n",
      "Epoch 200,loss:0.6534006084044148\n",
      "Validation Loss: 0.6546763167494819,AUC: 0.6627333333333332,ACC:0.6636880952380951,F1:0.5677380952380952,Precision:0.7658857142857143,Recall:0.46315952380952363\n",
      "Epoch 205,loss:0.6531058333990142\n",
      "Validation Loss: 0.6546133047058469,AUC: 0.6628166666666667,ACC:0.6633166666666666,F1:0.5703190476190476,Precision:0.7635857142857143,Recall:0.4677095238095238\n",
      "Epoch 210,loss:0.6528392293321805\n",
      "Validation Loss: 0.6545304925668807,AUC: 0.6629904761904761,ACC:0.6612738095238095,F1:0.5744880952380953,Precision:0.7556119047619048,Recall:0.48023333333333323\n",
      "Epoch 215,loss:0.6526046193490816\n",
      "Validation Loss: 0.6544929047425588,AUC: 0.6633761904761906,ACC:0.6618309523809524,F1:0.5755666666666667,Precision:0.7549690476190477,Recall:0.4822523809523809\n",
      "Epoch 220,loss:0.6523669695290993\n",
      "Validation Loss: 0.654425269081479,AUC: 0.6641904761904761,ACC:0.6629452380952381,F1:0.5758309523809524,Precision:0.7541190476190478,Recall:0.4805761904761904\n",
      "Epoch 225,loss:0.6521303325187503\n",
      "Validation Loss: 0.6542597796235766,AUC: 0.6645476190476187,ACC:0.663690476190476,F1:0.5722642857142857,Precision:0.7555404761904765,Recall:0.4730452380952381\n",
      "Epoch 230,loss:0.6520098856114965\n",
      "Validation Loss: 0.6541323931444258,AUC: 0.664645238095238,ACC:0.6635047619047618,F1:0.5714904761904762,Precision:0.7551785714285715,Recall:0.47149047619047607\n",
      "Epoch 235,loss:0.6518408013141062\n",
      "Validation Loss: 0.6539136029425121,AUC: 0.6640809523809524,ACC:0.6623880952380953,F1:0.5685333333333333,Precision:0.7580166666666668,Recall:0.4678499999999999\n",
      "Epoch 240,loss:0.6515882578421766\n",
      "Validation Loss: 0.6539128209863391,AUC: 0.6647642857142857,ACC:0.6633190476190476,F1:0.5684404761904763,Precision:0.7619190476190476,Recall:0.4670499999999998\n",
      "Epoch 245,loss:0.6514305157924262\n",
      "Validation Loss: 0.6539815096628099,AUC: 0.6654690476190476,ACC:0.6640619047619047,F1:0.5733333333333335,Precision:0.7554857142857143,Recall:0.47482619047619035\n",
      "早停策略触发，停止训练在第 244 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 11:11:51.544837 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 11:11:51.558349 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 11:11:51.571016 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 11:11:51.584110 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 11:11:51.596809 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 11:11:51.609538 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 11:11:51.622193 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 11:11:51.635749 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 11:11:51.649377 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 11:11:51.662384 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 11:11:51.675078 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 11:11:51.688200 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 11:11:51.700838 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 11:11:51.713545 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 11:11:51.726223 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 11:11:51.738888 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 11:11:51.753229 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 11:11:51.766072 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 11:11:51.778724 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 11:11:51.791757 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 11:11:51.804408 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 11:11:51.817289 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 11:11:51.830303 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 11:11:51.842939 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 11:11:51.855581 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 11:11:51.869073 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 11:11:51.881874 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 11:11:51.894491 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 11:11:51.907157 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 11:11:51.919748 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 11:11:51.932427 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 11:11:51.945044 -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 11:11:51.958329 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 11:11:51.971976 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 11:11:51.985766 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 11:11:51.998818 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 11:11:52.011410 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 11:11:52.024030 -------------\n",
      "||--测试：---------- 38 个batch运行时间： 2024-03-19 11:11:52.036608 -------------\n",
      "||--测试：---------- 39 个batch运行时间： 2024-03-19 11:11:52.049217 -------------\n",
      "||--测试：---------- 40 个batch运行时间： 2024-03-19 11:11:52.061816 -------------\n",
      "||--测试：---------- 41 个batch运行时间： 2024-03-19 11:11:52.074397 -------------\n",
      "||--测试：---------- 42 个batch运行时间： 2024-03-19 11:11:52.086983 -------------\n",
      "Test Loss: 0.6519246527126857,AUC: 0.6661023809523808,ACC:0.6662904761904762,F1:0.5692523809523811,Precision:0.7777547619047619,Recall:0.4629380952380951\n",
      "i=:2\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6827223437038932\n",
      "Validation Loss: 0.679357233501616,AUC: 0.6160404761904762,ACC:0.6212833333333333,F1:0.5411309523809523,Precision:0.6651642857142858,Recall:0.4880261904761904\n",
      "Epoch 10,loss:0.6813503893341605\n",
      "Validation Loss: 0.6779776953515553,AUC: 0.6180095238095239,ACC:0.620352380952381,F1:0.5332714285714286,Precision:0.6722809523809525,Recall:0.47633571428571414\n",
      "Epoch 15,loss:0.6802597970474423\n",
      "Validation Loss: 0.6768984354677654,AUC: 0.6200285714285715,ACC:0.6216499999999999,F1:0.5335833333333333,Precision:0.6819999999999998,Recall:0.4788785714285713\n",
      "Epoch 20,loss:0.6792631463741693\n",
      "Validation Loss: 0.6759310662746429,AUC: 0.6209809523809524,ACC:0.6212785714285713,F1:0.5303595238095239,Precision:0.6904166666666666,Recall:0.4732785714285714\n",
      "Epoch 25,loss:0.678294815885739\n",
      "Validation Loss: 0.6751215983004797,AUC: 0.6209714285714286,ACC:0.6210952380952379,F1:0.5260285714285714,Precision:0.689947619047619,Recall:0.46671666666666656\n",
      "Epoch 30,loss:0.6773106258685194\n",
      "Validation Loss: 0.6743665777501606,AUC: 0.6214333333333334,ACC:0.6248142857142857,F1:0.517102380952381,Precision:0.7031404761904761,Recall:0.44943095238095243\n",
      "Epoch 35,loss:0.6762795330971245\n",
      "Validation Loss: 0.6731765142508915,AUC: 0.6235928571428572,ACC:0.6261142857142856,F1:0.52305,Precision:0.7026452380952379,Recall:0.4556523809523809\n",
      "Epoch 40,loss:0.6752307161571472\n",
      "Validation Loss: 0.6720740880284991,AUC: 0.6265261904761904,ACC:0.6251809523809525,F1:0.5276095238095238,Precision:0.6903,Recall:0.45888571428571434\n",
      "Epoch 45,loss:0.6742095064929151\n",
      "Validation Loss: 0.6711171936421167,AUC: 0.6274095238095236,ACC:0.6292761904761905,F1:0.5362595238095238,Precision:0.6906428571428573,Recall:0.47251428571428566\n",
      "Epoch 50,loss:0.6732453924464429\n",
      "Validation Loss: 0.6703036569413685,AUC: 0.6295642857142857,ACC:0.632438095238095,F1:0.5477809523809524,Precision:0.6873142857142858,Recall:0.4834595238095239\n",
      "Epoch 55,loss:0.6723425332016832\n",
      "Validation Loss: 0.6696285137108394,AUC: 0.630295238095238,ACC:0.6359714285714284,F1:0.5432928571428571,Precision:0.698692857142857,Recall:0.4718809523809523\n",
      "Epoch 60,loss:0.6714629437041095\n",
      "Validation Loss: 0.668950346254167,AUC: 0.6322238095238094,ACC:0.636340476190476,F1:0.5276619047619049,Precision:0.7194547619047619,Recall:0.43627619047619043\n",
      "Epoch 65,loss:0.6706265520861768\n",
      "Validation Loss: 0.6682220370996566,AUC: 0.6341333333333333,ACC:0.6381999999999999,F1:0.534945238095238,Precision:0.7187380952380951,Recall:0.44881190476190486\n",
      "Epoch 70,loss:0.6697112669156292\n",
      "Validation Loss: 0.6673293369156974,AUC: 0.6351404761904763,ACC:0.6424785714285713,F1:0.5504904761904762,Precision:0.7147285714285714,Recall:0.46639285714285716\n",
      "Epoch 75,loss:0.6686224524430403\n",
      "Validation Loss: 0.6662594477335612,AUC: 0.6361619047619048,ACC:0.6441499999999999,F1:0.5478000000000001,Precision:0.7253904761904761,Recall:0.4593142857142858\n",
      "Epoch 80,loss:0.6676680713187991\n",
      "Validation Loss: 0.6654735420431409,AUC: 0.6373380952380951,ACC:0.6447047619047618,F1:0.5515285714285714,Precision:0.721102380952381,Recall:0.46561904761904765\n",
      "Epoch 85,loss:0.666920680699386\n",
      "Validation Loss: 0.6649166984217507,AUC: 0.6384095238095236,ACC:0.6441499999999999,F1:0.5598857142857143,Precision:0.7105404761904762,Recall:0.48104761904761906\n",
      "Epoch 90,loss:0.6662838374535869\n",
      "Validation Loss: 0.6644853665715172,AUC: 0.6391761904761906,ACC:0.6458261904761904,F1:0.5551,Precision:0.720447619047619,Recall:0.47184523809523826\n",
      "Epoch 95,loss:0.6657182245742618\n",
      "Validation Loss: 0.6641189754009247,AUC: 0.6397499999999999,ACC:0.6467571428571427,F1:0.554852380952381,Precision:0.7251976190476189,Recall:0.4708333333333335\n",
      "Epoch 100,loss:0.6652159235608859\n",
      "Validation Loss: 0.6637836794058481,AUC: 0.6402047619047619,ACC:0.6471309523809523,F1:0.5610666666666667,Precision:0.7204761904761904,Recall:0.4811571428571429\n",
      "Epoch 105,loss:0.6647470283696032\n",
      "Validation Loss: 0.6634652586210341,AUC: 0.6407357142857143,ACC:0.6471285714285714,F1:0.5577095238095239,Precision:0.7228095238095236,Recall:0.4730714285714286\n",
      "Epoch 110,loss:0.6643263739863718\n",
      "Validation Loss: 0.66316290696462,AUC: 0.6410666666666667,ACC:0.6484285714285714,F1:0.563002380952381,Precision:0.7195166666666665,Recall:0.4829357142857142\n",
      "Epoch 115,loss:0.6639398120519683\n",
      "Validation Loss: 0.6628736002104623,AUC: 0.6417595238095237,ACC:0.6474976190476189,F1:0.5556833333333333,Precision:0.7274333333333333,Recall:0.4695619047619048\n",
      "Epoch 120,loss:0.6635744933068283\n",
      "Validation Loss: 0.6626121501127878,AUC: 0.6424119047619049,ACC:0.6474976190476189,F1:0.5552666666666667,Precision:0.7272833333333333,Recall:0.46726190476190477\n",
      "Epoch 125,loss:0.6632246051247664\n",
      "Validation Loss: 0.6624030456656501,AUC: 0.643052380952381,ACC:0.6480547619047619,F1:0.5606809523809524,Precision:0.7219071428571427,Recall:0.47977380952380966\n",
      "Epoch 130,loss:0.6629220571104936\n",
      "Validation Loss: 0.6621728738149008,AUC: 0.6429333333333334,ACC:0.6476833333333333,F1:0.5613976190476191,Precision:0.7191571428571429,Recall:0.4809047619047619\n",
      "Epoch 135,loss:0.6626492644858173\n",
      "Validation Loss: 0.6619523380483899,AUC: 0.6428095238095237,ACC:0.6480523809523808,F1:0.5593738095238094,Precision:0.7216857142857143,Recall:0.4775214285714286\n",
      "Epoch 140,loss:0.6623979013735853\n",
      "Validation Loss: 0.6617794916743324,AUC: 0.6431023809523807,ACC:0.6484261904761903,F1:0.5603190476190475,Precision:0.7218404761904763,Recall:0.48011666666666664\n",
      "Epoch 145,loss:0.6621530342289782\n",
      "Validation Loss: 0.661617880775815,AUC: 0.6435595238095237,ACC:0.647492857142857,F1:0.560142857142857,Precision:0.7187476190476191,Recall:0.480252380952381\n",
      "Epoch 150,loss:0.6619110332699273\n",
      "Validation Loss: 0.6614506727173215,AUC: 0.643940476190476,ACC:0.646938095238095,F1:0.561502380952381,Precision:0.7161738095238095,Recall:0.48122380952380955\n",
      "Epoch 155,loss:0.6616591764247324\n",
      "Validation Loss: 0.6612595546813238,AUC: 0.6445809523809525,ACC:0.6482380952380952,F1:0.5632309523809523,Precision:0.716697619047619,Recall:0.48164761904761894\n",
      "Epoch 160,loss:0.6614030139652762\n",
      "Validation Loss: 0.6610891762233916,AUC: 0.6449952380952381,ACC:0.6484285714285714,F1:0.5569000000000001,Precision:0.7254428571428572,Recall:0.47103333333333336\n",
      "Epoch 165,loss:0.6611486175867516\n",
      "Validation Loss: 0.6609326828093756,AUC: 0.6452690476190477,ACC:0.6497285714285713,F1:0.5567166666666667,Precision:0.7264833333333334,Recall:0.46743333333333337\n",
      "Epoch 170,loss:0.6608991777803016\n",
      "Validation Loss: 0.660831556433723,AUC: 0.6456452380952382,ACC:0.648242857142857,F1:0.5573142857142857,Precision:0.7272190476190478,Recall:0.4699047619047618\n",
      "Epoch 175,loss:0.6606389284133911\n",
      "Validation Loss: 0.6606446731658209,AUC: 0.6465619047619049,ACC:0.6493595238095237,F1:0.5570190476190476,Precision:0.7303500000000002,Recall:0.468692857142857\n",
      "Epoch 180,loss:0.6603497337168596\n",
      "Validation Loss: 0.6605975642090752,AUC: 0.646192857142857,ACC:0.6527047619047617,F1:0.5580928571428572,Precision:0.7366000000000001,Recall:0.4651571428571429\n",
      "Epoch 185,loss:0.660113206059914\n",
      "Validation Loss: 0.6603283002263024,AUC: 0.6471523809523809,ACC:0.6512142857142855,F1:0.5591595238095238,Precision:0.7335428571428574,Recall:0.47119999999999995\n",
      "Epoch 190,loss:0.659786475455667\n",
      "Validation Loss: 0.6601333674930391,AUC: 0.648104761904762,ACC:0.6523428571428571,F1:0.5594928571428571,Precision:0.7350904761904763,Recall:0.4683595238095238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195,loss:0.6594369350455878\n",
      "Validation Loss: 0.6598243372780936,AUC: 0.648011904761905,ACC:0.6534571428571427,F1:0.5631690476190476,Precision:0.734159523809524,Recall:0.4754333333333333\n",
      "Epoch 200,loss:0.6592272355800538\n",
      "Validation Loss: 0.6595785135314578,AUC: 0.648995238095238,ACC:0.6532714285714285,F1:0.5615261904761905,Precision:0.735152380952381,Recall:0.47299285714285705\n",
      "Epoch 205,loss:0.6589580009302755\n",
      "Validation Loss: 0.6594421792597998,AUC: 0.6494166666666668,ACC:0.6545738095238095,F1:0.5622261904761904,Precision:0.7374261904761907,Recall:0.47064285714285703\n",
      "Epoch 210,loss:0.658789548817582\n",
      "Validation Loss: 0.6593378980954488,AUC: 0.6496404761904763,ACC:0.6545738095238095,F1:0.5623142857142858,Precision:0.7368809523809526,Recall:0.4712904761904762\n",
      "Epoch 215,loss:0.6585232798508772\n",
      "Validation Loss: 0.6591195918264843,AUC: 0.6506071428571429,ACC:0.6555023809523811,F1:0.5593119047619048,Precision:0.7441238095238097,Recall:0.46381666666666665\n",
      "Epoch 220,loss:0.6582637110094386\n",
      "Validation Loss: 0.6590141143117633,AUC: 0.6503857142857141,ACC:0.6562523809523811,F1:0.5632166666666667,Precision:0.7435904761904764,Recall:0.4716071428571428\n",
      "Epoch 225,loss:0.6579713478801757\n",
      "Validation Loss: 0.6588338954108102,AUC: 0.6507785714285713,ACC:0.6569976190476191,F1:0.5641952380952381,Precision:0.744607142857143,Recall:0.4738428571428571\n",
      "Epoch 230,loss:0.6577539077893956\n",
      "Validation Loss: 0.6587729524998438,AUC: 0.6517285714285712,ACC:0.6553238095238096,F1:0.5583500000000001,Precision:0.7472023809523812,Recall:0.46221904761904764\n",
      "Epoch 235,loss:0.657567789235453\n",
      "Validation Loss: 0.6585810823099953,AUC: 0.6521880952380952,ACC:0.6562523809523811,F1:0.5602523809523812,Precision:0.7456071428571429,Recall:0.4613142857142858\n",
      "Epoch 240,loss:0.6573111893623833\n",
      "Validation Loss: 0.658528364840008,AUC: 0.6521880952380952,ACC:0.6549452380952381,F1:0.5566714285714285,Precision:0.7467833333333335,Recall:0.45540476190476187\n",
      "Epoch 245,loss:0.6570513365775581\n",
      "Validation Loss: 0.6584060816537767,AUC: 0.6530619047619048,ACC:0.6547571428571428,F1:0.5614476190476191,Precision:0.7379000000000002,Recall:0.4625619047619048\n",
      "Epoch 250,loss:0.6568216939610759\n",
      "Validation Loss: 0.6583612901823861,AUC: 0.6534571428571428,ACC:0.6558785714285713,F1:0.5576833333333335,Precision:0.7485309523809524,Recall:0.45436428571428567\n",
      "Epoch 255,loss:0.6565411133090342\n",
      "Validation Loss: 0.6582915910652706,AUC: 0.6537547619047617,ACC:0.6558761904761903,F1:0.557402380952381,Precision:0.7486690476190475,Recall:0.45338809523809526\n",
      "Epoch 260,loss:0.6562395541686711\n",
      "Validation Loss: 0.6582203266166505,AUC: 0.6539642857142859,ACC:0.6560666666666667,F1:0.5619619047619048,Precision:0.7408333333333332,Recall:0.46167619047619046\n",
      "Epoch 265,loss:0.6560640391402357\n",
      "Validation Loss: 0.6581200531550816,AUC: 0.6545976190476192,ACC:0.6562523809523808,F1:0.5584785714285716,Precision:0.7488047619047619,Recall:0.454995238095238\n",
      "Epoch 270,loss:0.6557979635366304\n",
      "Validation Loss: 0.6580081156321934,AUC: 0.6544857142857142,ACC:0.6553238095238095,F1:0.5568380952380952,Precision:0.7473166666666666,Recall:0.4533380952380952\n",
      "Epoch 275,loss:0.6555779904831113\n",
      "Validation Loss: 0.6578800280888876,AUC: 0.6551333333333336,ACC:0.6562523809523808,F1:0.5584023809523809,Precision:0.7484214285714285,Recall:0.4548119047619047\n",
      "Epoch 280,loss:0.6554168838215625\n",
      "Validation Loss: 0.6577410598595937,AUC: 0.6556761904761907,ACC:0.6568095238095237,F1:0.5587809523809524,Precision:0.7491071428571429,Recall:0.4547619047619048\n",
      "Epoch 285,loss:0.6551937216848839\n",
      "Validation Loss: 0.6576592879635947,AUC: 0.6565595238095236,ACC:0.656997619047619,F1:0.5602857142857144,Precision:0.7485738095238094,Recall:0.4555476190476191\n",
      "Epoch 290,loss:0.6549080314598684\n",
      "Validation Loss: 0.657589031117303,AUC: 0.6568285714285713,ACC:0.658302380952381,F1:0.5615809523809525,Precision:0.7520214285714285,Recall:0.45857380952380933\n",
      "Epoch 295,loss:0.6547613580395856\n",
      "Validation Loss: 0.6574801462037223,AUC: 0.6571785714285714,ACC:0.658302380952381,F1:0.5620928571428572,Precision:0.7489714285714287,Recall:0.46218809523809523\n",
      "Epoch 300,loss:0.6545606091266541\n",
      "Validation Loss: 0.657412839787347,AUC: 0.6574571428571429,ACC:0.6579309523809526,F1:0.5579857142857142,Precision:0.7536142857142858,Recall:0.4503214285714284\n",
      "Epoch 305,loss:0.6542927247332776\n",
      "Validation Loss: 0.6576112267516908,AUC: 0.6591404761904761,ACC:0.656802380952381,F1:0.5667119047619049,Precision:0.7453595238095237,Recall:0.46603095238095227\n",
      "早停策略触发，停止训练在第 304 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 12:02:48.808804 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 12:02:48.822121 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 12:02:48.835179 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 12:02:48.848379 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 12:02:48.862559 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 12:02:48.875503 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 12:02:48.888412 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 12:02:48.901321 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 12:02:48.915512 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 12:02:48.928817 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 12:02:48.942122 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 12:02:48.955582 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 12:02:48.969427 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 12:02:48.982408 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 12:02:48.995528 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 12:02:49.008562 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 12:02:49.023456 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 12:02:49.036864 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 12:02:49.050219 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 12:02:49.063433 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 12:02:49.076354 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 12:02:49.089262 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 12:02:49.103650 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 12:02:49.116619 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 12:02:49.129952 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 12:02:49.143308 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 12:02:49.156809 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 12:02:49.169790 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 12:02:49.182857 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 12:02:49.195519 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 12:02:49.208555 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 12:02:49.222018 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 12:02:49.234901 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 12:02:49.247624 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 12:02:49.260324 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 12:02:49.273060 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 12:02:49.285757 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 12:02:49.299326 -------------\n",
      "||--测试：---------- 38 个batch运行时间： 2024-03-19 12:02:49.312475 -------------\n",
      "||--测试：---------- 39 个batch运行时间： 2024-03-19 12:02:49.325194 -------------\n",
      "||--测试：---------- 40 个batch运行时间： 2024-03-19 12:02:49.338085 -------------\n",
      "||--测试：---------- 41 个batch运行时间： 2024-03-19 12:02:49.350914 -------------\n",
      "||--测试：---------- 42 个batch运行时间： 2024-03-19 12:02:49.363674 -------------\n",
      "Test Loss: 0.6554179645719982,AUC: 0.6621738095238093,ACC:0.6599738095238096,F1:0.5785595238095238,Precision:0.7394761904761904,Recall:0.48760000000000003\n",
      "i=:3\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6823571488613219\n",
      "Validation Loss: 0.6788919255847022,AUC: 0.6179214285714283,ACC:0.6175642857142858,F1:0.5429571428571427,Precision:0.6554976190476189,Recall:0.497640476190476\n",
      "Epoch 10,loss:0.6811061689234156\n",
      "Validation Loss: 0.6776282645407177,AUC: 0.6167238095238093,ACC:0.6192380952380953,F1:0.5379738095238095,Precision:0.6726071428571427,Recall:0.4880380952380952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15,loss:0.6800532876037237\n",
      "Validation Loss: 0.6765953855855125,AUC: 0.6178476190476191,ACC:0.6194261904761906,F1:0.5452333333333333,Precision:0.6686357142857142,Recall:0.5013714285714286\n",
      "Epoch 20,loss:0.6789524982294698\n",
      "Validation Loss: 0.6755516713573819,AUC: 0.6197095238095238,ACC:0.6250000000000001,F1:0.5239000000000001,Precision:0.6991166666666666,Recall:0.46160238095238093\n",
      "Epoch 25,loss:0.6777887020524093\n",
      "Validation Loss: 0.6744205923307509,AUC: 0.6220023809523811,ACC:0.6277857142857143,F1:0.5361809523809524,Precision:0.6945928571428572,Recall:0.4759190476190476\n",
      "Epoch 30,loss:0.6765811091332924\n",
      "Validation Loss: 0.6732406332379296,AUC: 0.6248738095238094,ACC:0.6276023809523809,F1:0.5330357142857144,Precision:0.6937738095238096,Recall:0.4703714285714286\n",
      "Epoch 35,loss:0.6754113135375376\n",
      "Validation Loss: 0.6721394615513938,AUC: 0.6265357142857142,ACC:0.6302023809523808,F1:0.5364047619047619,Precision:0.6953880952380953,Recall:0.4687857142857143\n",
      "Epoch 40,loss:0.6743412975251205\n",
      "Validation Loss: 0.6711681485176086,AUC: 0.6277357142857145,ACC:0.6305738095238093,F1:0.5386952380952381,Precision:0.6950999999999998,Recall:0.47288571428571435\n",
      "Epoch 45,loss:0.6733512915964202\n",
      "Validation Loss: 0.6702896470115298,AUC: 0.6294309523809524,ACC:0.6309476190476191,F1:0.5259833333333334,Precision:0.7137333333333333,Recall:0.45109523809523794\n",
      "Epoch 50,loss:0.6724194105215898\n",
      "Validation Loss: 0.6695561025823865,AUC: 0.631447619047619,ACC:0.6341119047619047,F1:0.54245,Precision:0.6968666666666669,Recall:0.4796333333333334\n",
      "Epoch 55,loss:0.6715361466557961\n",
      "Validation Loss: 0.6689363136177972,AUC: 0.6328476190476191,ACC:0.6367190476190477,F1:0.5339714285714285,Precision:0.7173595238095237,Recall:0.4620309523809525\n",
      "Epoch 60,loss:0.6705918987904946\n",
      "Validation Loss: 0.6681289445786249,AUC: 0.6339690476190477,ACC:0.6369095238095238,F1:0.5369761904761905,Precision:0.7197333333333333,Recall:0.4649119047619048\n",
      "Epoch 65,loss:0.6691046906268503\n",
      "Validation Loss: 0.6666878319921947,AUC: 0.6355142857142858,ACC:0.6396857142857142,F1:0.5550380952380952,Precision:0.7012690476190476,Recall:0.4824833333333335\n",
      "Epoch 70,loss:0.6678441908415846\n",
      "Validation Loss: 0.6657676909651075,AUC: 0.6366880952380952,ACC:0.6409904761904761,F1:0.5521976190476192,Precision:0.7055428571428571,Recall:0.47366190476190484\n",
      "Epoch 75,loss:0.6669542789459229\n",
      "Validation Loss: 0.6651703261193775,AUC: 0.6379547619047619,ACC:0.6424761904761905,F1:0.552857142857143,Precision:0.7079476190476193,Recall:0.47223571428571426\n",
      "Epoch 80,loss:0.6662056798071373\n",
      "Validation Loss: 0.6646230249177842,AUC: 0.6388,ACC:0.6441499999999999,F1:0.5536380952380953,Precision:0.7107571428571431,Recall:0.4748261904761906\n",
      "Epoch 85,loss:0.6656279409025597\n",
      "Validation Loss: 0.6642222461246309,AUC: 0.6397309523809523,ACC:0.645645238095238,F1:0.5616690476190476,Precision:0.7098738095238095,Recall:0.48470714285714295\n",
      "Epoch 90,loss:0.6651394686360997\n",
      "Validation Loss: 0.6638672323453993,AUC: 0.6408404761904762,ACC:0.6458309523809523,F1:0.5609476190476191,Precision:0.7114428571428572,Recall:0.4837880952380954\n",
      "Epoch 95,loss:0.6646190609518937\n",
      "Validation Loss: 0.6634996831417084,AUC: 0.6425142857142856,ACC:0.6447095238095235,F1:0.5580547619047617,Precision:0.7166095238095238,Recall:0.48049761904761906\n",
      "Epoch 100,loss:0.6641749716180516\n",
      "Validation Loss: 0.6631554237433842,AUC: 0.6439547619047618,ACC:0.644345238095238,F1:0.5651952380952382,Precision:0.7083571428571428,Recall:0.49425476190476203\n",
      "Epoch 105,loss:0.6638418619088301\n",
      "Validation Loss: 0.6627684703895024,AUC: 0.6453261904761904,ACC:0.6449023809523811,F1:0.565757142857143,Precision:0.7075666666666667,Recall:0.4952785714285715\n",
      "Epoch 110,loss:0.6634350649015172\n",
      "Validation Loss: 0.662240560565676,AUC: 0.6488190476190475,ACC:0.6475119047619048,F1:0.5675190476190477,Precision:0.7102285714285712,Recall:0.49029285714285703\n",
      "Epoch 115,loss:0.6632798910140991\n",
      "Validation Loss: 0.6622328332492283,AUC: 0.6469880952380954,ACC:0.6493666666666666,F1:0.5661166666666667,Precision:0.7169785714285715,Recall:0.4896238095238097\n",
      "Epoch 120,loss:0.662565948925619\n",
      "Validation Loss: 0.6620845099290212,AUC: 0.6478357142857143,ACC:0.648809523809524,F1:0.5701452380952382,Precision:0.7151357142857144,Recall:0.49728095238095243\n",
      "Epoch 125,loss:0.6621792058306416\n",
      "Validation Loss: 0.6615327639239175,AUC: 0.6487499999999999,ACC:0.6471357142857143,F1:0.5676857142857146,Precision:0.7142595238095238,Recall:0.4908142857142857\n",
      "Epoch 130,loss:0.6618303853695787\n",
      "Validation Loss: 0.6617441191559746,AUC: 0.6479380952380953,ACC:0.6463857142857142,F1:0.5619238095238095,Precision:0.7193333333333334,Recall:0.48097380952380947\n",
      "早停策略触发，停止训练在第 129 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 12:25:14.837681 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 12:25:14.851510 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 12:25:14.864561 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 12:25:14.877663 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 12:25:14.890752 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 12:25:14.903930 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 12:25:14.916965 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 12:25:14.930080 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 12:25:14.943785 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 12:25:14.956772 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 12:25:14.969852 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 12:25:14.982916 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 12:25:14.996022 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 12:25:15.009048 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 12:25:15.022077 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 12:25:15.035183 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 12:25:15.048935 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 12:25:15.062068 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 12:25:15.075451 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 12:25:15.088463 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 12:25:15.101551 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 12:25:15.115716 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 12:25:15.128747 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 12:25:15.141762 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 12:25:15.154846 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 12:25:15.167824 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 12:25:15.180761 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 12:25:15.193728 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 12:25:15.206834 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 12:25:15.219849 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 12:25:15.232858 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 12:25:15.245904 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 12:25:15.259783 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 12:25:15.272942 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 12:25:15.286026 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 12:25:15.299070 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 12:25:15.312110 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 12:25:15.325596 -------------\n",
      "||--测试：---------- 38 个batch运行时间： 2024-03-19 12:25:15.339759 -------------\n",
      "||--测试：---------- 39 个batch运行时间： 2024-03-19 12:25:15.352746 -------------\n",
      "||--测试：---------- 40 个batch运行时间： 2024-03-19 12:25:15.365775 -------------\n",
      "||--测试：---------- 41 个batch运行时间： 2024-03-19 12:25:15.378871 -------------\n",
      "||--测试：---------- 42 个batch运行时间： 2024-03-19 12:25:15.391923 -------------\n",
      "Test Loss: 0.6616782687959217,AUC: 0.6446666666666667,ACC:0.6486190476190474,F1:0.558945238095238,Precision:0.7334428571428572,Recall:0.47058333333333335\n",
      "i=:4\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6820579316672377\n",
      "Validation Loss: 0.6784174953188215,AUC: 0.6193214285714286,ACC:0.6197928571428571,F1:0.5370547619047619,Precision:0.6655928571428571,Recall:0.48428095238095237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10,loss:0.6808226981500941\n",
      "Validation Loss: 0.6771229363623119,AUC: 0.6185595238095237,ACC:0.6214666666666666,F1:0.5416642857142856,Precision:0.6745952380952381,Recall:0.4954071428571428\n",
      "Epoch 15,loss:0.6798096698100172\n",
      "Validation Loss: 0.6761142313480377,AUC: 0.6193000000000001,ACC:0.6209095238095238,F1:0.5405261904761903,Precision:0.6775857142857143,Recall:0.49288809523809524\n",
      "Epoch 20,loss:0.6788248546480193\n",
      "Validation Loss: 0.6750817242122832,AUC: 0.6199904761904761,ACC:0.6235047619047617,F1:0.5312404761904761,Precision:0.6897500000000003,Recall:0.47439523809523804\n",
      "Epoch 25,loss:0.6777337047997423\n",
      "Validation Loss: 0.6741205822853815,AUC: 0.6223880952380952,ACC:0.623692857142857,F1:0.5195857142857142,Precision:0.7016166666666666,Recall:0.45187142857142865\n",
      "Epoch 30,loss:0.6765804858658258\n",
      "Validation Loss: 0.6728719785099938,AUC: 0.6236547619047619,ACC:0.6244357142857142,F1:0.53335,Precision:0.6893166666666666,Recall:0.4722738095238096\n",
      "Epoch 35,loss:0.6754170947187529\n",
      "Validation Loss: 0.6718301120258513,AUC: 0.6255904761904761,ACC:0.6296523809523809,F1:0.5169619047619047,Precision:0.7134761904761904,Recall:0.4412357142857144\n",
      "Epoch 40,loss:0.6741953046303096\n",
      "Validation Loss: 0.6707096511409396,AUC: 0.6268500000000001,ACC:0.6331833333333333,F1:0.5278214285714287,Precision:0.7098523809523809,Recall:0.448902380952381\n",
      "Epoch 45,loss:0.6730521405775716\n",
      "Validation Loss: 0.6696824289503551,AUC: 0.6283833333333333,ACC:0.6356023809523809,F1:0.5293666666666665,Precision:0.7266476190476192,Recall:0.4526119047619048\n",
      "Epoch 50,loss:0.6720204921219293\n",
      "Validation Loss: 0.6689998890672412,AUC: 0.6290309523809524,ACC:0.6359738095238094,F1:0.5395833333333333,Precision:0.7142833333333334,Recall:0.4644595238095238\n",
      "Epoch 55,loss:0.6710809309651532\n",
      "Validation Loss: 0.6684262951215109,AUC: 0.6308357142857142,ACC:0.63895,F1:0.5419928571428573,Precision:0.7139428571428571,Recall:0.4583428571428572\n",
      "Epoch 60,loss:0.6701311788221044\n",
      "Validation Loss: 0.6679647536504836,AUC: 0.6311809523809526,ACC:0.6400619047619047,F1:0.5435000000000001,Precision:0.7155452380952381,Recall:0.4574119047619048\n",
      "Epoch 65,loss:0.669350935248878\n",
      "Validation Loss: 0.6672794492471785,AUC: 0.6326238095238095,ACC:0.640809523809524,F1:0.5412976190476192,Precision:0.7184785714285715,Recall:0.4522357142857143\n",
      "Epoch 70,loss:0.6686164872852836\n",
      "Validation Loss: 0.6668809453646342,AUC: 0.6327571428571428,ACC:0.6404333333333335,F1:0.5415380952380954,Precision:0.7190023809523811,Recall:0.4534690476190476\n",
      "Epoch 75,loss:0.6679614955984702\n",
      "Validation Loss: 0.6665764820008051,AUC: 0.6332690476190478,ACC:0.6419261904761905,F1:0.5495976190476191,Precision:0.7120309523809525,Recall:0.46818095238095236\n",
      "Epoch 80,loss:0.6673575254875844\n",
      "Validation Loss: 0.666257917881012,AUC: 0.6336142857142859,ACC:0.6432238095238094,F1:0.5506333333333333,Precision:0.712997619047619,Recall:0.4665309523809523\n",
      "Epoch 85,loss:0.6667815451546917\n",
      "Validation Loss: 0.6659056643644968,AUC: 0.6345952380952382,ACC:0.6445238095238095,F1:0.5535523809523811,Precision:0.7117071428571428,Recall:0.46797380952380957\n",
      "Epoch 90,loss:0.6662130825162873\n",
      "Validation Loss: 0.6655099704152062,AUC: 0.6361357142857141,ACC:0.6460095238095238,F1:0.5587857142857142,Precision:0.7095476190476189,Recall:0.473845238095238\n",
      "Epoch 95,loss:0.6654608803471243\n",
      "Validation Loss: 0.6652910922254834,AUC: 0.6378261904761906,ACC:0.6465761904761906,F1:0.557054761904762,Precision:0.7180261904761904,Recall:0.47054999999999997\n",
      "Epoch 100,loss:0.6644007831107913\n",
      "Validation Loss: 0.6638648566745576,AUC: 0.640954761904762,ACC:0.6480595238095239,F1:0.5538238095238096,Precision:0.7223142857142856,Recall:0.4643404761904764\n",
      "Epoch 105,loss:0.6635592246618797\n",
      "Validation Loss: 0.6632148921489716,AUC: 0.6432333333333334,ACC:0.6497380952380953,F1:0.5468999999999999,Precision:0.7370619047619046,Recall:0.45210952380952385\n",
      "Epoch 110,loss:0.6628527594363596\n",
      "Validation Loss: 0.6627144075575329,AUC: 0.6447690476190479,ACC:0.6469500000000001,F1:0.5441357142857142,Precision:0.7432666666666667,Recall:0.45027619047619055\n",
      "Epoch 115,loss:0.6623067039204394\n",
      "Validation Loss: 0.6624320433253333,AUC: 0.6453642857142857,ACC:0.6519738095238098,F1:0.562157142857143,Precision:0.7306333333333332,Recall:0.47847619047619067\n",
      "Epoch 120,loss:0.6618360313843554\n",
      "Validation Loss: 0.6621541168008532,AUC: 0.6460476190476191,ACC:0.650852380952381,F1:0.5711666666666667,Precision:0.719602380952381,Recall:0.49305000000000004\n",
      "Epoch 125,loss:0.6614190687344769\n",
      "Validation Loss: 0.6619097774937039,AUC: 0.6467523809523811,ACC:0.6502952380952381,F1:0.569966666666667,Precision:0.7204476190476191,Recall:0.4930071428571428\n",
      "Epoch 130,loss:0.6610261305110661\n",
      "Validation Loss: 0.6616437761556535,AUC: 0.647647619047619,ACC:0.6525261904761905,F1:0.5656880952380954,Precision:0.7298261904761905,Recall:0.48445000000000005\n",
      "Epoch 135,loss:0.6606465479520363\n",
      "Validation Loss: 0.6613424789337885,AUC: 0.648504761904762,ACC:0.6519714285714285,F1:0.565404761904762,Precision:0.7292309523809525,Recall:0.48205238095238084\n",
      "Epoch 140,loss:0.6603069770054555\n",
      "Validation Loss: 0.6611736360050383,AUC: 0.6490714285714286,ACC:0.6549523809523811,F1:0.5744571428571429,Precision:0.7247047619047617,Recall:0.4996619047619047\n",
      "Epoch 145,loss:0.6599385452082777\n",
      "Validation Loss: 0.6609131736414773,AUC: 0.649197619047619,ACC:0.6525309523809524,F1:0.5666285714285715,Precision:0.7314690476190476,Recall:0.485347619047619\n",
      "Epoch 150,loss:0.6596738921375725\n",
      "Validation Loss: 0.6608197532948994,AUC: 0.6493500000000001,ACC:0.6497404761904763,F1:0.5608833333333334,Precision:0.7291119047619047,Recall:0.47507857142857146\n",
      "Epoch 155,loss:0.6593525954118864\n",
      "Validation Loss: 0.6605698466300964,AUC: 0.6492857142857142,ACC:0.6504880952380954,F1:0.5616404761904762,Precision:0.728047619047619,Recall:0.47456666666666675\n",
      "Epoch 160,loss:0.659159524703589\n",
      "Validation Loss: 0.6603276303836277,AUC: 0.649669047619048,ACC:0.6514190476190478,F1:0.5561333333333331,Precision:0.7354904761904763,Recall:0.4636595238095239\n",
      "Epoch 165,loss:0.6589051593007065\n",
      "Validation Loss: 0.6601510459468478,AUC: 0.6502166666666664,ACC:0.6514166666666668,F1:0.557297619047619,Precision:0.7344952380952381,Recall:0.4666523809523811\n",
      "Epoch 170,loss:0.6586399176928002\n",
      "Validation Loss: 0.65994045989854,AUC: 0.6499595238095237,ACC:0.6514166666666668,F1:0.5620095238095238,Precision:0.7308333333333332,Recall:0.474607142857143\n",
      "Epoch 175,loss:0.6584081499595341\n",
      "Validation Loss: 0.6598338711829412,AUC: 0.6501880952380953,ACC:0.6506738095238097,F1:0.562554761904762,Precision:0.7298142857142857,Recall:0.4744238095238096\n",
      "Epoch 180,loss:0.658164100853477\n",
      "Validation Loss: 0.6597145199775696,AUC: 0.6508071428571429,ACC:0.6517904761904764,F1:0.5558119047619048,Precision:0.7412238095238095,Recall:0.4623333333333333\n",
      "Epoch 185,loss:0.657941662889766\n",
      "Validation Loss: 0.6595758639630818,AUC: 0.6518476190476191,ACC:0.6512285714285715,F1:0.5562261904761906,Precision:0.7399547619047618,Recall:0.46394285714285716\n",
      "Epoch 190,loss:0.6577144321494215\n",
      "Validation Loss: 0.6594819100130171,AUC: 0.6515642857142856,ACC:0.652902380952381,F1:0.5584547619047621,Precision:0.7417380952380952,Recall:0.4666023809523808\n",
      "Epoch 195,loss:0.6575096132248406\n",
      "Validation Loss: 0.6593646052337828,AUC: 0.651840476190476,ACC:0.6543880952380953,F1:0.5643166666666667,Precision:0.738347619047619,Recall:0.4777833333333333\n",
      "Epoch 200,loss:0.6573027963713398\n",
      "Validation Loss: 0.6592647135257721,AUC: 0.6521357142857143,ACC:0.6530904761904763,F1:0.5554619047619048,Precision:0.743747619047619,Recall:0.45832142857142866\n",
      "Epoch 205,loss:0.6570485004289882\n",
      "Validation Loss: 0.6592133470943996,AUC: 0.6521880952380952,ACC:0.6536452380952381,F1:0.5608666666666666,Precision:0.7382904761904762,Recall:0.46870238095238104\n",
      "Epoch 210,loss:0.6568312532319798\n",
      "Validation Loss: 0.6590986294405801,AUC: 0.6514738095238095,ACC:0.653457142857143,F1:0.5582880952380952,Precision:0.7425952380952382,Recall:0.46135952380952394\n",
      "Epoch 215,loss:0.6566506713394105\n",
      "Validation Loss: 0.6590280107089451,AUC: 0.6513261904761906,ACC:0.652157142857143,F1:0.5596714285714287,Precision:0.7385095238095238,Recall:0.4690047619047621\n",
      "Epoch 220,loss:0.6567838384410528\n",
      "Validation Loss: 0.6589695740313757,AUC: 0.652754761904762,ACC:0.6549452380952382,F1:0.559009523809524,Precision:0.7436952380952382,Recall:0.4639166666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225,loss:0.6565665935906838\n",
      "Validation Loss: 0.6587511329423814,AUC: 0.6520880952380952,ACC:0.6527166666666667,F1:0.5627452380952382,Precision:0.7358095238095238,Recall:0.47389285714285717\n",
      "Epoch 230,loss:0.656977345624308\n",
      "Validation Loss: 0.6586693681421734,AUC: 0.6530976190476191,ACC:0.6532738095238096,F1:0.5583428571428573,Precision:0.7384904761904761,Recall:0.46459047619047633\n",
      "Epoch 235,loss:0.6560234342973064\n",
      "Validation Loss: 0.6585825795219058,AUC: 0.6528190476190477,ACC:0.6491785714285714,F1:0.5598666666666667,Precision:0.7331095238095239,Recall:0.4722809523809525\n",
      "Epoch 240,loss:0.6561667872226145\n",
      "Validation Loss: 0.6585765906742641,AUC: 0.6533571428571426,ACC:0.6495571428571429,F1:0.5540285714285716,Precision:0.7410547619047618,Recall:0.4604476190476191\n",
      "Epoch 245,loss:0.6556849033813777\n",
      "Validation Loss: 0.6582689441385723,AUC: 0.655004761904762,ACC:0.6504857142857143,F1:0.5524380952380954,Precision:0.7461976190476192,Recall:0.46030238095238085\n",
      "Epoch 250,loss:0.6553103637507581\n",
      "Validation Loss: 0.6579535007476807,AUC: 0.6556166666666666,ACC:0.6514142857142857,F1:0.5568880952380952,Precision:0.7453119047619047,Recall:0.4649\n",
      "Epoch 255,loss:0.6551619003138204\n",
      "Validation Loss: 0.6575060032662892,AUC: 0.6572642857142859,ACC:0.6519690476190475,F1:0.5567547619047618,Precision:0.7524309523809524,Recall:0.4600142857142857\n",
      "Epoch 260,loss:0.6547393798828125\n",
      "Validation Loss: 0.6573066484360468,AUC: 0.6575880952380955,ACC:0.6530857142857142,F1:0.5555809523809524,Precision:0.7558380952380952,Recall:0.45704523809523806\n",
      "Epoch 265,loss:0.6545027686854986\n",
      "Validation Loss: 0.6570864915847778,AUC: 0.6576023809523809,ACC:0.6532714285714284,F1:0.5575142857142859,Precision:0.7561714285714286,Recall:0.45893809523809526\n",
      "Epoch 270,loss:0.6540996826539828\n",
      "Validation Loss: 0.6569091450600397,AUC: 0.6584571428571429,ACC:0.65365,F1:0.5576357142857142,Precision:0.7568190476190476,Recall:0.45875952380952373\n",
      "Epoch 275,loss:0.6537895329355254\n",
      "Validation Loss: 0.6567419824146089,AUC: 0.6582690476190475,ACC:0.6560690476190476,F1:0.5587023809523809,Precision:0.7570738095238095,Recall:0.4547190476190477\n",
      "Epoch 280,loss:0.6536702438602298\n",
      "Validation Loss: 0.6565301276388622,AUC: 0.6588666666666665,ACC:0.6568095238095237,F1:0.5595452380952382,Precision:0.7564309523809521,Recall:0.4538309523809523\n",
      "Epoch 285,loss:0.6533481286266657\n",
      "Validation Loss: 0.6563418195361183,AUC: 0.6592619047619047,ACC:0.6551333333333333,F1:0.5604666666666669,Precision:0.7535499999999998,Recall:0.4597690476190476\n",
      "Epoch 290,loss:0.6531443605272789\n",
      "Validation Loss: 0.6562136482624781,AUC: 0.6591357142857142,ACC:0.6558761904761904,F1:0.5606690476190478,Precision:0.751597619047619,Recall:0.45897380952380945\n",
      "Epoch 295,loss:0.6530777708751949\n",
      "Validation Loss: 0.6560866492135184,AUC: 0.6589285714285714,ACC:0.6553166666666665,F1:0.5614261904761905,Precision:0.7525285714285713,Recall:0.46194285714285727\n",
      "Epoch 300,loss:0.6525822845030957\n",
      "Validation Loss: 0.6558914127803984,AUC: 0.6587095238095235,ACC:0.6551285714285713,F1:0.5661142857142858,Precision:0.7475690476190474,Recall:0.47219285714285725\n",
      "Epoch 305,loss:0.652265685280477\n",
      "Validation Loss: 0.655714342991511,AUC: 0.6576952380952381,ACC:0.6555047619047618,F1:0.5623952380952381,Precision:0.7517999999999998,Recall:0.4640809523809524\n",
      "Epoch 310,loss:0.6520049618923758\n",
      "Validation Loss: 0.6556275657245091,AUC: 0.6586857142857143,ACC:0.6566166666666665,F1:0.5653976190476189,Precision:0.7526785714285713,Recall:0.4673404761904762\n",
      "Epoch 315,loss:0.6524198252385057\n",
      "Validation Loss: 0.6552917971497491,AUC: 0.6610976190476189,ACC:0.6605285714285715,F1:0.5668142857142858,Precision:0.7580404761904759,Recall:0.4631857142857143\n",
      "Epoch 320,loss:0.6517000630145936\n",
      "Validation Loss: 0.6552689997922807,AUC: 0.6598119047619045,ACC:0.6601571428571429,F1:0.5675285714285716,Precision:0.7540619047619047,Recall:0.4658857142857142\n",
      "Epoch 325,loss:0.651480422245236\n",
      "Validation Loss: 0.6550541874908266,AUC: 0.6606261904761906,ACC:0.6605238095238095,F1:0.5678047619047619,Precision:0.7556309523809522,Recall:0.46510952380952386\n",
      "Epoch 330,loss:0.6514397319846266\n",
      "Validation Loss: 0.6550423006216685,AUC: 0.6611785714285714,ACC:0.6599690476190476,F1:0.5679428571428573,Precision:0.7519785714285715,Recall:0.4660619047619048\n",
      "Epoch 335,loss:0.6510300171656871\n",
      "Validation Loss: 0.6548309553237188,AUC: 0.6612857142857143,ACC:0.6616404761904762,F1:0.570657142857143,Precision:0.7534214285714285,Recall:0.4675119047619047\n",
      "Epoch 340,loss:0.6508312544484777\n",
      "Validation Loss: 0.6546543836593628,AUC: 0.6617142857142857,ACC:0.6620119047619046,F1:0.5718976190476193,Precision:0.7531238095238094,Recall:0.4707\n",
      "Epoch 345,loss:0.6506100442465834\n",
      "Validation Loss: 0.6545821683747428,AUC: 0.6619833333333335,ACC:0.6614523809523808,F1:0.5730476190476191,Precision:0.7527190476190476,Recall:0.4745857142857143\n",
      "Epoch 350,loss:0.6505095278184245\n",
      "Validation Loss: 0.6545469292572567,AUC: 0.6617595238095239,ACC:0.6607095238095237,F1:0.5714928571428574,Precision:0.7513404761904762,Recall:0.47230952380952373\n",
      "Epoch 355,loss:0.650411435468929\n",
      "Validation Loss: 0.6544587441853115,AUC: 0.6621880952380954,ACC:0.6618285714285713,F1:0.5680380952380952,Precision:0.759911904761905,Recall:0.4648357142857142\n",
      "Epoch 360,loss:0.6502798485943652\n",
      "Validation Loss: 0.6543885114647093,AUC: 0.6624238095238095,ACC:0.6621999999999998,F1:0.5688738095238094,Precision:0.7590404761904763,Recall:0.46591666666666665\n",
      "Epoch 365,loss:0.6501616061203123\n",
      "Validation Loss: 0.6541687505585807,AUC: 0.6628261904761902,ACC:0.662197619047619,F1:0.5684619047619048,Precision:0.7615119047619048,Recall:0.46421904761904753\n",
      "Epoch 370,loss:0.650111309656008\n",
      "Validation Loss: 0.654003749291102,AUC: 0.6630976190476191,ACC:0.6625714285714286,F1:0.5704642857142858,Precision:0.7586785714285715,Recall:0.46596666666666664\n",
      "Epoch 375,loss:0.6497753262519836\n",
      "Validation Loss: 0.6540474806513105,AUC: 0.6622285714285714,ACC:0.6618309523809524,F1:0.5665214285714285,Precision:0.7643476190476189,Recall:0.4607785714285713\n",
      "早停策略触发，停止训练在第 374 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 13:28:05.236669 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 13:28:05.250117 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 13:28:05.262929 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 13:28:05.275972 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 13:28:05.288771 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 13:28:05.301650 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 13:28:05.314474 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 13:28:05.327296 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 13:28:05.340475 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 13:28:05.353438 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 13:28:05.366258 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 13:28:05.379077 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 13:28:05.391871 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 13:28:05.404690 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 13:28:05.417473 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 13:28:05.430359 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 13:28:05.444379 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 13:28:05.457740 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 13:28:05.470570 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 13:28:05.483334 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 13:28:05.496421 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 13:28:05.510089 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 13:28:05.523042 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 13:28:05.535838 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 13:28:05.548776 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 13:28:05.561647 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 13:28:05.574672 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 13:28:05.587790 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 13:28:05.600601 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 13:28:05.613426 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 13:28:05.626721 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 13:28:05.639484 -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 13:28:05.652623 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 13:28:05.665754 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 13:28:05.678808 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 13:28:05.691634 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 13:28:05.705654 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 13:28:05.718467 -------------\n",
      "||--测试：---------- 38 个batch运行时间： 2024-03-19 13:28:05.731790 -------------\n",
      "||--测试：---------- 39 个batch运行时间： 2024-03-19 13:28:05.744706 -------------\n",
      "||--测试：---------- 40 个batch运行时间： 2024-03-19 13:28:05.757959 -------------\n",
      "||--测试：---------- 41 个batch运行时间： 2024-03-19 13:28:05.770843 -------------\n",
      "||--测试：---------- 42 个batch运行时间： 2024-03-19 13:28:05.783785 -------------\n",
      "Test Loss: 0.6513244396164304,AUC: 0.6650785714285714,ACC:0.6657285714285713,F1:0.5678642857142857,Precision:0.779709523809524,Recall:0.4557999999999998\n",
      "i=:5\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.683188153064157\n",
      "Validation Loss: 0.6795945564905802,AUC: 0.6171523809523809,ACC:0.6212809523809524,F1:0.5387238095238095,Precision:0.6708452380952382,Recall:0.48464285714285704\n",
      "Epoch 10,loss:0.6815950969072777\n",
      "Validation Loss: 0.6779070368834904,AUC: 0.617954761904762,ACC:0.6210976190476192,F1:0.5375928571428571,Precision:0.6721571428571431,Recall:0.48465476190476187\n",
      "Epoch 15,loss:0.6803167274617773\n",
      "Validation Loss: 0.676558568364098,AUC: 0.6196380952380952,ACC:0.6246309523809523,F1:0.5239690476190477,Precision:0.703507142857143,Recall:0.4639309523809524\n",
      "Epoch 20,loss:0.6791009175495839\n",
      "Validation Loss: 0.6753148252055758,AUC: 0.6205499999999998,ACC:0.6227690476190475,F1:0.5229119047619049,Precision:0.6999714285714286,Recall:0.4661333333333332\n",
      "Epoch 25,loss:0.6778639733322024\n",
      "Validation Loss: 0.6741295612993694,AUC: 0.6212476190476189,ACC:0.623697619047619,F1:0.5267357142857142,Precision:0.6978880952380953,Recall:0.46652142857142853\n",
      "Epoch 30,loss:0.6765935618107713\n",
      "Validation Loss: 0.672979413043885,AUC: 0.6224571428571427,ACC:0.6262976190476189,F1:0.5334166666666665,Precision:0.6995642857142859,Recall:0.47766428571428565\n",
      "Epoch 35,loss:0.6753818496005741\n",
      "Validation Loss: 0.67182533513932,AUC: 0.6241047619047618,ACC:0.6300142857142856,F1:0.5342595238095239,Precision:0.7039857142857145,Recall:0.47403571428571434\n",
      "Epoch 40,loss:0.6743208963101305\n",
      "Validation Loss: 0.6708053591705504,AUC: 0.6251738095238094,ACC:0.629645238095238,F1:0.5279785714285715,Precision:0.71195,Recall:0.45912857142857144\n",
      "Epoch 45,loss:0.6732066395714527\n",
      "Validation Loss: 0.6698335451739175,AUC: 0.6274357142857143,ACC:0.6339214285714284,F1:0.531802380952381,Precision:0.715907142857143,Recall:0.46107619047619053\n",
      "Epoch 50,loss:0.6721439150374705\n",
      "Validation Loss: 0.6689637331735521,AUC: 0.6297428571428574,ACC:0.6354071428571427,F1:0.5361523809523809,Precision:0.7130833333333333,Recall:0.4620309523809524\n",
      "Epoch 55,loss:0.6711051454694252\n",
      "Validation Loss: 0.6681929812544868,AUC: 0.6317142857142858,ACC:0.6382047619047617,F1:0.5386857142857142,Precision:0.7167999999999999,Recall:0.46257380952380944\n",
      "Epoch 60,loss:0.6699348735058401\n",
      "Validation Loss: 0.667582168465569,AUC: 0.6323142857142857,ACC:0.6411857142857141,F1:0.5503809523809523,Precision:0.7090285714285715,Recall:0.47799047619047613\n",
      "Epoch 65,loss:0.6688480072134123\n",
      "Validation Loss: 0.667196573246093,AUC: 0.6344880952380952,ACC:0.6404428571428572,F1:0.5427928571428572,Precision:0.719797619047619,Recall:0.4598095238095238\n",
      "Epoch 70,loss:0.668077938199982\n",
      "Validation Loss: 0.6661118311541421,AUC: 0.6362833333333334,ACC:0.6430428571428571,F1:0.5422452380952381,Precision:0.728454761904762,Recall:0.44873095238095245\n",
      "Epoch 75,loss:0.6671013921264588\n",
      "Validation Loss: 0.6657791648592267,AUC: 0.6369095238095239,ACC:0.6452761904761903,F1:0.5552738095238093,Precision:0.7175404761904763,Recall:0.4680999999999999\n",
      "Epoch 80,loss:0.6662545091523899\n",
      "Validation Loss: 0.6662818903014773,AUC: 0.6367380952380951,ACC:0.6469547619047619,F1:0.5525214285714286,Precision:0.7222166666666665,Recall:0.46242619047619044\n",
      "早停策略触发，停止训练在第 79 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 13:42:29.458514 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 13:42:29.472452 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 13:42:29.485774 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 13:42:29.499928 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 13:42:29.512979 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 13:42:29.526102 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 13:42:29.539232 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 13:42:29.552345 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 13:42:29.565496 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 13:42:29.578568 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 13:42:29.591665 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 13:42:29.605045 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 13:42:29.618270 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 13:42:29.631393 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 13:42:29.644500 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 13:42:29.658055 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 13:42:29.671884 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 13:42:29.685338 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 13:42:29.698586 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 13:42:29.711722 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 13:42:29.725092 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 13:42:29.738061 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 13:42:29.750913 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 13:42:29.763643 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 13:42:29.777555 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 13:42:29.790338 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 13:42:29.803147 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 13:42:29.815887 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 13:42:29.829157 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 13:42:29.842332 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 13:42:29.855249 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 13:42:29.868203 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 13:42:29.881537 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 13:42:29.894387 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 13:42:29.907263 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 13:42:29.920046 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 13:42:29.933429 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 13:42:29.946359 -------------\n",
      "||--测试：---------- 38 个batch运行时间： 2024-03-19 13:42:29.959189 -------------\n",
      "||--测试：---------- 39 个batch运行时间： 2024-03-19 13:42:29.971988 -------------\n",
      "||--测试：---------- 40 个batch运行时间： 2024-03-19 13:42:29.984858 -------------\n",
      "||--测试：---------- 41 个batch运行时间： 2024-03-19 13:42:29.997982 -------------\n",
      "||--测试：---------- 42 个batch运行时间： 2024-03-19 13:42:30.010875 -------------\n",
      "Test Loss: 0.6658242798986889,AUC: 0.6373,ACC:0.6419190476190476,F1:0.5566785714285716,Precision:0.7131547619047619,Recall:0.47738809523809533\n",
      "结果已输出\n",
      "||--------当前时间窗 1115_1215 结束时间： 2024-03-19 13:42:30.026365 -------------\n",
      "i=:1\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6910604249059626\n",
      "Validation Loss: 0.6890712944236962,AUC: 0.5667108108108105,ACC:0.6114864864864865,F1:0.4547378378378379,Precision:0.6389621621621621,Recall:0.3831108108108109\n",
      "Epoch 10,loss:0.6895693872882201\n",
      "Validation Loss: 0.6879649178401844,AUC: 0.5717621621621621,ACC:0.6135999999999999,F1:0.46337297297297286,Precision:0.6286702702702703,Recall:0.3856351351351351\n",
      "Epoch 15,loss:0.6882432092607549\n",
      "Validation Loss: 0.6870252409496823,AUC: 0.573691891891892,ACC:0.6131729729729728,F1:0.4606432432432433,Precision:0.6402324324324324,Recall:0.3861351351351352\n",
      "Epoch 20,loss:0.6870726331145363\n",
      "Validation Loss: 0.6862771188890612,AUC: 0.5743945945945945,ACC:0.6197243243243246,F1:0.4392513513513513,Precision:0.6690297297297297,Recall:0.3556216216216217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25,loss:0.6860046128256131\n",
      "Validation Loss: 0.6857110600213747,AUC: 0.574691891891892,ACC:0.6190891891891892,F1:0.4508702702702703,Precision:0.6507378378378379,Recall:0.37202702702702695\n",
      "Epoch 30,loss:0.6850095734132075\n",
      "Validation Loss: 0.6852737665176392,AUC: 0.5754216216216217,ACC:0.6184594594594597,F1:0.4530486486486487,Precision:0.6527567567567568,Recall:0.37562702702702694\n",
      "Epoch 35,loss:0.6840741613269907\n",
      "Validation Loss: 0.6848936805853972,AUC: 0.5754783783783783,ACC:0.6188810810810811,F1:0.44908918918918916,Precision:0.6514540540540541,Recall:0.36993783783783774\n",
      "Epoch 40,loss:0.6832235924965513\n",
      "Validation Loss: 0.6845671502319542,AUC: 0.5760000000000002,ACC:0.6216243243243244,F1:0.4481216216216217,Precision:0.6653810810810811,Recall:0.3606783783783784\n",
      "Epoch 45,loss:0.6824332850169291\n",
      "Validation Loss: 0.6842595854321042,AUC: 0.5772945945945946,ACC:0.6184594594594596,F1:0.4600891891891892,Precision:0.6528621621621622,Recall:0.38055945945945946\n",
      "Epoch 50,loss:0.6817154478182835\n",
      "Validation Loss: 0.683985714976852,AUC: 0.577445945945946,ACC:0.6180405405405406,F1:0.4646135135135135,Precision:0.6452810810810811,Recall:0.3848432432432433\n",
      "Epoch 55,loss:0.6810676682311877\n",
      "Validation Loss: 0.683744187290604,AUC: 0.5780432432432431,ACC:0.6180378378378379,F1:0.4638513513513513,Precision:0.6433054054054055,Recall:0.3831567567567568\n",
      "Epoch 60,loss:0.680476127472599\n",
      "Validation Loss: 0.683509886264801,AUC: 0.5790297297297297,ACC:0.6220432432432433,F1:0.45449189189189193,Precision:0.6599756756756756,Recall:0.3699108108108109\n",
      "Epoch 65,loss:0.6799397294500232\n",
      "Validation Loss: 0.6833007496756476,AUC: 0.5801999999999999,ACC:0.622464864864865,F1:0.4524216216216216,Precision:0.6660864864864866,Recall:0.36617837837837847\n",
      "Epoch 70,loss:0.6794523623137347\n",
      "Validation Loss: 0.6831089596490603,AUC: 0.5813675675675676,ACC:0.622672972972973,F1:0.44813513513513503,Precision:0.6699756756756757,Recall:0.35874864864864875\n",
      "Epoch 75,loss:0.6790086864370161\n",
      "Validation Loss: 0.6829247909623224,AUC: 0.5812243243243245,ACC:0.6230972972972973,F1:0.4505999999999999,Precision:0.6706189189189189,Recall:0.36146486486486484\n",
      "Epoch 80,loss:0.67860835104917\n",
      "Validation Loss: 0.6827386907629065,AUC: 0.5816216216216216,ACC:0.6237351351351352,F1:0.4514432432432432,Precision:0.671889189189189,Recall:0.3617972972972973\n",
      "Epoch 85,loss:0.6782239279915802\n",
      "Validation Loss: 0.68256756421682,AUC: 0.5828540540540541,ACC:0.6224702702702704,F1:0.46368108108108114,Precision:0.6531783783783783,Recall:0.380827027027027\n",
      "Epoch 90,loss:0.6778677817994514\n",
      "Validation Loss: 0.6824007904207384,AUC: 0.5835432432432432,ACC:0.6245783783783784,F1:0.4585918918918918,Precision:0.6668918918918919,Recall:0.3682756756756757\n",
      "Epoch 95,loss:0.6775395274162292\n",
      "Validation Loss: 0.6822729497342497,AUC: 0.5837945945945946,ACC:0.6252135135135136,F1:0.4590270270270271,Precision:0.6683810810810811,Recall:0.3695972972972973\n",
      "Epoch 100,loss:0.6772384986413263\n",
      "Validation Loss: 0.6821522696598156,AUC: 0.5849108108108109,ACC:0.6252162162162161,F1:0.46381351351351346,Precision:0.6635405405405406,Recall:0.3756216216216216\n",
      "Epoch 105,loss:0.6769417735327662\n",
      "Validation Loss: 0.682041272923753,AUC: 0.5848378378378378,ACC:0.6252135135135135,F1:0.4639918918918919,Precision:0.6619918918918918,Recall:0.37572432432432434\n",
      "Epoch 110,loss:0.6766634620396437\n",
      "Validation Loss: 0.6819526569263356,AUC: 0.5852351351351349,ACC:0.6260594594594596,F1:0.460218918918919,Precision:0.6696297297297297,Recall:0.37063513513513513\n",
      "Epoch 115,loss:0.6763911943520065\n",
      "Validation Loss: 0.6818431180876654,AUC: 0.5856243243243242,ACC:0.6256378378378378,F1:0.4602432432432432,Precision:0.6671054054054054,Recall:0.36968108108108105\n",
      "Epoch 120,loss:0.6761452270820077\n",
      "Validation Loss: 0.6817280779013762,AUC: 0.5864405405405405,ACC:0.6277459459459459,F1:0.4569297297297298,Precision:0.6701216216216217,Recall:0.3615135135135135\n",
      "Epoch 125,loss:0.6759022774949538\n",
      "Validation Loss: 0.6816251986735576,AUC: 0.5869972972972972,ACC:0.6283783783783784,F1:0.4542405405405405,Precision:0.6740675675675675,Recall:0.35758108108108105\n",
      "Epoch 130,loss:0.6756753246341132\n",
      "Validation Loss: 0.6814914539053634,AUC: 0.5877432432432432,ACC:0.6279567567567567,F1:0.45587567567567555,Precision:0.6715513513513514,Recall:0.3595432432432432\n",
      "Epoch 135,loss:0.6754535921907003\n",
      "Validation Loss: 0.6813880462904234,AUC: 0.5878648648648651,ACC:0.6279567567567568,F1:0.45699459459459446,Precision:0.6693405405405406,Recall:0.3606\n",
      "Epoch 140,loss:0.675249975866976\n",
      "Validation Loss: 0.6812735506006189,AUC: 0.5883918918918919,ACC:0.6281675675675675,F1:0.45693513513513495,Precision:0.6718324324324325,Recall:0.36068108108108105\n",
      "Epoch 145,loss:0.6750373624067391\n",
      "Validation Loss: 0.6811684063962988,AUC: 0.5874324324324325,ACC:0.6283783783783784,F1:0.4564675675675675,Precision:0.6746621621621621,Recall:0.3596837837837838\n",
      "Epoch 150,loss:0.6748571221807361\n",
      "Validation Loss: 0.6810838080741264,AUC: 0.5870756756756758,ACC:0.6290108108108108,F1:0.46037297297297297,Precision:0.6716648648648647,Recall:0.36504054054054064\n",
      "Epoch 155,loss:0.6746906653969689\n",
      "Validation Loss: 0.6810086272858284,AUC: 0.587791891891892,ACC:0.6294297297297297,F1:0.45738378378378375,Precision:0.6808162162162161,Recall:0.36340540540540545\n",
      "Epoch 160,loss:0.6745213159417685\n",
      "Validation Loss: 0.6809439546353108,AUC: 0.5878783783783783,ACC:0.6309081081081079,F1:0.45924864864864856,Precision:0.6792594594594593,Recall:0.36500270270270274\n",
      "Epoch 165,loss:0.6743592261213117\n",
      "Validation Loss: 0.6808861671267329,AUC: 0.5888513513513514,ACC:0.6306972972972972,F1:0.4588054054054054,Precision:0.6783594594594594,Recall:0.3645540540540541\n",
      "Epoch 170,loss:0.6742069831991617\n",
      "Validation Loss: 0.6808272986798674,AUC: 0.5891837837837838,ACC:0.6311189189189188,F1:0.45672972972972964,Precision:0.684391891891892,Recall:0.3614432432432433\n",
      "Epoch 175,loss:0.6740387794190803\n",
      "Validation Loss: 0.6808025724179035,AUC: 0.5893783783783783,ACC:0.6313324324324323,F1:0.4539837837837838,Precision:0.6825135135135134,Recall:0.35573243243243247\n",
      "Epoch 180,loss:0.6738988219109256\n",
      "Validation Loss: 0.680761461322372,AUC: 0.588716216216216,ACC:0.6323891891891891,F1:0.45493243243243253,Precision:0.6856,Recall:0.35665135135135134\n",
      "Epoch 185,loss:0.6737579650583521\n",
      "Validation Loss: 0.6807012686858306,AUC: 0.5893594594594593,ACC:0.6330216216216215,F1:0.4545945945945946,Precision:0.6888864864864865,Recall:0.3557864864864865\n",
      "Epoch 190,loss:0.673630838373066\n",
      "Validation Loss: 0.6806535688606469,AUC: 0.5891297297297298,ACC:0.6334459459459458,F1:0.4561540540540542,Precision:0.6890270270270271,Recall:0.35795675675675676\n",
      "Epoch 195,loss:0.6735051105507707\n",
      "Validation Loss: 0.6806110965239035,AUC: 0.5892783783783784,ACC:0.6330216216216216,F1:0.454727027027027,Precision:0.6903243243243247,Recall:0.35768648648648654\n",
      "Epoch 200,loss:0.6733735029676319\n",
      "Validation Loss: 0.6805666250151556,AUC: 0.5891432432432432,ACC:0.6332351351351351,F1:0.4529243243243244,Precision:0.6920945945945949,Recall:0.3533864864864865\n",
      "Epoch 205,loss:0.6732511087856462\n",
      "Validation Loss: 0.680524864712277,AUC: 0.589272972972973,ACC:0.6323891891891892,F1:0.4557297297297298,Precision:0.6856054054054058,Recall:0.36038108108108113\n",
      "Epoch 210,loss:0.6731294425187913\n",
      "Validation Loss: 0.6804625923569138,AUC: 0.5893378378378378,ACC:0.6326054054054052,F1:0.4588702702702704,Precision:0.6860432432432436,Recall:0.36191351351351353\n",
      "Epoch 215,loss:0.6730071190184197\n",
      "Validation Loss: 0.6803962169466792,AUC: 0.5897216216216217,ACC:0.6332378378378377,F1:0.4590243243243245,Precision:0.6888243243243243,Recall:0.3601945945945946\n",
      "Epoch 220,loss:0.6728826260144731\n",
      "Validation Loss: 0.6803651049330428,AUC: 0.5898675675675674,ACC:0.6325999999999999,F1:0.46259729729729737,Precision:0.6819027027027029,Recall:0.3651567567567568\n",
      "Epoch 225,loss:0.6727632885485624\n",
      "Validation Loss: 0.6803121067382194,AUC: 0.5903216216216217,ACC:0.6332324324324323,F1:0.4578351351351352,Precision:0.6867243243243245,Recall:0.3595054054054055\n",
      "Epoch 230,loss:0.6726350589136106\n",
      "Validation Loss: 0.6802585431047388,AUC: 0.5911135135135134,ACC:0.6338648648648648,F1:0.45926486486486495,Precision:0.6873135135135137,Recall:0.3612\n",
      "Epoch 235,loss:0.6725056028999059\n",
      "Validation Loss: 0.6802131775263194,AUC: 0.5914270270270272,ACC:0.6332351351351351,F1:0.4606621621621622,Precision:0.6845810810810814,Recall:0.3633432432432433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240,loss:0.6723723775517624\n",
      "Validation Loss: 0.680178123551446,AUC: 0.5912702702702702,ACC:0.6328108108108107,F1:0.4624594594594596,Precision:0.6800783783783787,Recall:0.36624054054054056\n",
      "Epoch 245,loss:0.672253958419361\n",
      "Validation Loss: 0.6801346137716964,AUC: 0.5910891891891893,ACC:0.6321783783783783,F1:0.4644054054054055,Precision:0.6774243243243244,Recall:0.3708432432432433\n",
      "Epoch 250,loss:0.6721361057948222\n",
      "Validation Loss: 0.6800862148001388,AUC: 0.5915972972972973,ACC:0.6332324324324323,F1:0.45622702702702717,Precision:0.6849459459459459,Recall:0.35982972972972976\n",
      "Epoch 255,loss:0.6720151526738057\n",
      "Validation Loss: 0.6800474927232072,AUC: 0.5908918918918918,ACC:0.633654054054054,F1:0.4571837837837838,Precision:0.6864000000000001,Recall:0.36054324324324327\n",
      "Epoch 260,loss:0.6719047564320859\n",
      "Validation Loss: 0.6799983333896946,AUC: 0.5911297297297295,ACC:0.6330216216216216,F1:0.4530783783783784,Precision:0.6892081081081082,Recall:0.356045945945946\n",
      "Epoch 265,loss:0.6717948903024724\n",
      "Validation Loss: 0.6799574687674239,AUC: 0.5916567567567566,ACC:0.6325972972972973,F1:0.4609702702702703,Precision:0.6818081081081081,Recall:0.3639054054054055\n",
      "Epoch 270,loss:0.6716726680772495\n",
      "Validation Loss: 0.6799127201776247,AUC: 0.5911432432432431,ACC:0.6330216216216216,F1:0.45948918918918924,Precision:0.6839486486486487,Recall:0.3614594594594595\n",
      "Epoch 275,loss:0.671575235582031\n",
      "Validation Loss: 0.6798891247929754,AUC: 0.5910648648648649,ACC:0.6330216216216216,F1:0.4600810810810811,Precision:0.6833135135135135,Recall:0.3624540540540541\n",
      "Epoch 280,loss:0.6714612082042525\n",
      "Validation Loss: 0.6798626168354137,AUC: 0.5910216216216218,ACC:0.6326027027027027,F1:0.4601864864864865,Precision:0.6813459459459461,Recall:0.36352702702702705\n",
      "Epoch 285,loss:0.6713510931065653\n",
      "Validation Loss: 0.679822069567603,AUC: 0.5906864864864866,ACC:0.6332351351351351,F1:0.4593729729729731,Precision:0.6846756756756759,Recall:0.36142702702702706\n",
      "Epoch 290,loss:0.6712399104000193\n",
      "Validation Loss: 0.6797960513346905,AUC: 0.5909243243243245,ACC:0.6328135135135134,F1:0.46147027027027027,Precision:0.6795729729729733,Recall:0.3624648648648649\n",
      "Epoch 295,loss:0.6711392750782249\n",
      "Validation Loss: 0.6797786226143708,AUC: 0.5916864864864865,ACC:0.6334459459459458,F1:0.4630621621621622,Precision:0.6820810810810815,Recall:0.36357297297297303\n",
      "Epoch 300,loss:0.6710335010975863\n",
      "Validation Loss: 0.679770645257589,AUC: 0.5924378378378378,ACC:0.6326027027027027,F1:0.4616675675675676,Precision:0.6778081081081082,Recall:0.36125675675675684\n",
      "Epoch 305,loss:0.670932834127308\n",
      "Validation Loss: 0.6797471884134654,AUC: 0.5927891891891891,ACC:0.6328135135135134,F1:0.460145945945946,Precision:0.6796000000000001,Recall:0.3588918918918919\n",
      "Epoch 310,loss:0.6708299311916385\n",
      "Validation Loss: 0.679733973902625,AUC: 0.5928378378378379,ACC:0.6328135135135134,F1:0.460564864864865,Precision:0.681721621621622,Recall:0.3594405405405406\n",
      "Epoch 315,loss:0.6707380783241407\n",
      "Validation Loss: 0.6797110744424768,AUC: 0.593291891891892,ACC:0.6323918918918917,F1:0.4610324324324325,Precision:0.6800729729729733,Recall:0.35991621621621617\n",
      "Epoch 320,loss:0.6706405529933693\n",
      "Validation Loss: 0.6796810175921466,AUC: 0.5935351351351352,ACC:0.6319702702702702,F1:0.4660702702702703,Precision:0.6731297297297298,Recall:0.3685243243243244\n",
      "Epoch 325,loss:0.6705454772552558\n",
      "Validation Loss: 0.6796555825181909,AUC: 0.5944189189189187,ACC:0.6311270270270269,F1:0.4683378378378378,Precision:0.6670648648648649,Recall:0.3733324324324325\n",
      "Epoch 330,loss:0.6704557448361828\n",
      "Validation Loss: 0.6796390220925614,AUC: 0.5945621621621623,ACC:0.6319702702702702,F1:0.4680567567567568,Precision:0.6704405405405406,Recall:0.3719351351351352\n",
      "Epoch 335,loss:0.670371164790297\n",
      "Validation Loss: 0.6796136466232506,AUC: 0.5935243243243242,ACC:0.632181081081081,F1:0.4681864864864864,Precision:0.6704216216216218,Recall:0.3718810810810812\n",
      "Epoch 340,loss:0.6702798251557139\n",
      "Validation Loss: 0.6795822945800988,AUC: 0.5936027027027028,ACC:0.6323918918918918,F1:0.4680513513513513,Precision:0.6710864864864865,Recall:0.3717864864864865\n",
      "Epoch 345,loss:0.6701942413254122\n",
      "Validation Loss: 0.6795377795760696,AUC: 0.5939540540540541,ACC:0.6321810810810811,F1:0.4639972972972974,Precision:0.675618918918919,Recall:0.36738108108108114\n",
      "Epoch 350,loss:0.6701070128288944\n",
      "Validation Loss: 0.6794982600856472,AUC: 0.5947513513513514,ACC:0.6317567567567568,F1:0.466781081081081,Precision:0.6717405405405406,Recall:0.370154054054054\n",
      "Epoch 355,loss:0.6700245980667857\n",
      "Validation Loss: 0.6794552529180372,AUC: 0.5951027027027026,ACC:0.6321783783783783,F1:0.4651216216216217,Precision:0.6764513513513513,Recall:0.36817567567567566\n",
      "Epoch 360,loss:0.6699458751003299\n",
      "Validation Loss: 0.6794391387217754,AUC: 0.5954945945945946,ACC:0.6325999999999999,F1:0.46842972972972985,Precision:0.6725621621621622,Recall:0.3718270270270271\n",
      "Epoch 365,loss:0.6698624111909782\n",
      "Validation Loss: 0.6794078688363772,AUC: 0.5954918918918919,ACC:0.6321783783783783,F1:0.46443783783783793,Precision:0.675318918918919,Recall:0.36749189189189185\n",
      "Epoch 370,loss:0.6697885262227692\n",
      "Validation Loss: 0.6793703211320413,AUC: 0.595862162162162,ACC:0.6319675675675676,F1:0.4660243243243244,Precision:0.6728648648648651,Recall:0.36968108108108105\n",
      "Epoch 375,loss:0.669709204572492\n",
      "Validation Loss: 0.6793412082904094,AUC: 0.595416216216216,ACC:0.6321783783783783,F1:0.46640270270270273,Precision:0.6728810810810811,Recall:0.369927027027027\n",
      "Epoch 380,loss:0.6696421235008577\n",
      "Validation Loss: 0.6793168928172137,AUC: 0.5953675675675677,ACC:0.6330216216216216,F1:0.4674945945945947,Precision:0.6755540540540541,Recall:0.3708594594594595\n",
      "Epoch 385,loss:0.6695619821548462\n",
      "Validation Loss: 0.6793129508559769,AUC: 0.5951432432432433,ACC:0.6330216216216216,F1:0.4673783783783785,Precision:0.6778594594594596,Recall:0.3704594594594594\n",
      "Epoch 390,loss:0.6694844322921956\n",
      "Validation Loss: 0.6792908745843012,AUC: 0.5955756756756759,ACC:0.6330216216216216,F1:0.46582432432432436,Precision:0.6786729729729731,Recall:0.3681405405405406\n",
      "Epoch 395,loss:0.6694561090089578\n",
      "Validation Loss: 0.6792619502222216,AUC: 0.5962756756756755,ACC:0.6347135135135133,F1:0.46423243243243245,Precision:0.6849702702702704,Recall:0.36437027027027025\n",
      "Epoch 400,loss:0.6694118127358698\n",
      "Validation Loss: 0.6792598366737366,AUC: 0.5957324324324325,ACC:0.6345027027027026,F1:0.4641027027027027,Precision:0.6844486486486487,Recall:0.3644945945945946\n",
      "Epoch 405,loss:0.6693802549775723\n",
      "Validation Loss: 0.6792644600610476,AUC: 0.5954621621621621,ACC:0.6349243243243242,F1:0.46372972972972976,Precision:0.6884702702702705,Recall:0.364345945945946\n",
      "早停策略触发，停止训练在第 404 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 14:43:23.327107 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 14:43:23.340718 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 14:43:23.353910 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 14:43:23.366667 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 14:43:23.379424 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 14:43:23.392190 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 14:43:23.404966 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 14:43:23.417707 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 14:43:23.430432 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 14:43:23.443211 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 14:43:23.455911 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 14:43:23.468655 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 14:43:23.481392 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 14:43:23.494090 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 14:43:23.506840 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 14:43:23.519616 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 14:43:23.532928 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 14:43:23.545959 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 14:43:23.558754 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 14:43:23.571429 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 14:43:23.584186 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 14:43:23.596911 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 14:43:23.609632 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 14:43:23.622368 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 14:43:23.635082 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 14:43:23.648144 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 14:43:23.661309 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 14:43:23.674135 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 14:43:23.686900 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 14:43:23.699617 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 14:43:23.712413 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 14:43:23.725146 -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 14:43:23.738699 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 14:43:23.751714 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 14:43:23.764437 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 14:43:23.777154 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 14:43:23.789862 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 14:43:23.802582 -------------\n",
      "Test Loss: 0.6766532450108915,AUC: 0.5855108108108108,ACC:0.6271108108108108,F1:0.4317621621621622,Precision:0.6992810810810811,Recall:0.3251270270270271\n",
      "i=:2\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6914047319277198\n",
      "Validation Loss: 0.6899535092147621,AUC: 0.5657945945945947,ACC:0.6078945945945947,F1:0.44189459459459474,Precision:0.6188783783783783,Recall:0.3718378378378378\n",
      "Epoch 10,loss:0.6905111343459746\n",
      "Validation Loss: 0.6890725122915732,AUC: 0.5684756756756757,ACC:0.6102216216216215,F1:0.4357432432432432,Precision:0.6463324324324324,Recall:0.364354054054054\n",
      "Epoch 15,loss:0.6893723011016846\n",
      "Validation Loss: 0.688125001417624,AUC: 0.5699891891891891,ACC:0.6110702702702703,F1:0.44792702702702714,Precision:0.6352648648648649,Recall:0.37633783783783786\n",
      "Epoch 20,loss:0.6880488015909111\n",
      "Validation Loss: 0.6871612990224684,AUC: 0.571935135135135,ACC:0.6146567567567568,F1:0.4502648648648649,Precision:0.6477297297297298,Recall:0.3795945945945946\n",
      "Epoch 25,loss:0.6868762627112127\n",
      "Validation Loss: 0.6863534031687556,AUC: 0.5728270270270271,ACC:0.6182405405405406,F1:0.4496270270270271,Precision:0.6610405405405405,Recall:0.3746891891891892\n",
      "Epoch 30,loss:0.6858026353658828\n",
      "Validation Loss: 0.6856538460061357,AUC: 0.5732027027027027,ACC:0.6148648648648649,F1:0.4468108108108108,Precision:0.657691891891892,Recall:0.37511081081081077\n",
      "Epoch 35,loss:0.6847613833646858\n",
      "Validation Loss: 0.685025379464433,AUC: 0.5762216216216217,ACC:0.6155027027027028,F1:0.4578810810810811,Precision:0.640091891891892,Recall:0.3810135135135136\n",
      "Epoch 40,loss:0.6837514227470466\n",
      "Validation Loss: 0.6844642178432362,AUC: 0.5793243243243243,ACC:0.6163513513513516,F1:0.4582297297297297,Precision:0.6434081081081082,Recall:0.37819459459459465\n",
      "Epoch 45,loss:0.6828121516556866\n",
      "Validation Loss: 0.6839467222626144,AUC: 0.5789675675675675,ACC:0.6176216216216217,F1:0.4508945945945946,Precision:0.6532432432432432,Recall:0.3685054054054054\n",
      "Epoch 50,loss:0.6819469606981868\n",
      "Validation Loss: 0.683509760611766,AUC: 0.5798783783783782,ACC:0.6161378378378379,F1:0.4604891891891891,Precision:0.6436567567567567,Recall:0.3820486486486486\n",
      "Epoch 55,loss:0.6811831050214514\n",
      "Validation Loss: 0.6831353387317142,AUC: 0.5805432432432432,ACC:0.6186648648648649,F1:0.45818648648648636,Precision:0.6450000000000001,Recall:0.3788891891891891\n",
      "Epoch 60,loss:0.6804916589660982\n",
      "Validation Loss: 0.6828012208680849,AUC: 0.5812189189189192,ACC:0.6212027027027027,F1:0.4578756756756756,Precision:0.651927027027027,Recall:0.3728918918918919\n",
      "Epoch 65,loss:0.6798548144576824\n",
      "Validation Loss: 0.6825485551679457,AUC: 0.5814702702702701,ACC:0.6218324324324325,F1:0.4585567567567567,Precision:0.6593,Recall:0.373181081081081\n",
      "Epoch 70,loss:0.6792794181182321\n",
      "Validation Loss: 0.6823222846598238,AUC: 0.5819783783783781,ACC:0.6222486486486486,F1:0.45374054054054064,Precision:0.6656324324324325,Recall:0.36442702702702695\n",
      "Epoch 75,loss:0.6787451611155957\n",
      "Validation Loss: 0.6821109845831588,AUC: 0.5823810810810813,ACC:0.622464864864865,F1:0.4537162162162163,Precision:0.6622189189189189,Recall:0.3644864864864865\n",
      "Epoch 80,loss:0.6782689632567684\n",
      "Validation Loss: 0.681900096906198,AUC: 0.5832432432432434,ACC:0.622672972972973,F1:0.45345675675675673,Precision:0.6649243243243245,Recall:0.3648243243243243\n",
      "Epoch 85,loss:0.677841850086651\n",
      "Validation Loss: 0.6817009755083032,AUC: 0.583910810810811,ACC:0.6264702702702702,F1:0.44888108108108105,Precision:0.6675324324324325,Recall:0.35383513513513504\n",
      "Epoch 90,loss:0.6774490607523285\n",
      "Validation Loss: 0.6815356096705875,AUC: 0.5839270270270269,ACC:0.6266837837837838,F1:0.44792432432432433,Precision:0.6677054054054056,Recall:0.3521027027027026\n",
      "Epoch 95,loss:0.6771070471907084\n",
      "Validation Loss: 0.6813847760896425,AUC: 0.5829108108108108,ACC:0.6266837837837836,F1:0.4483351351351351,Precision:0.6671459459459459,Recall:0.35202702702702715\n",
      "Epoch 100,loss:0.676784413578236\n",
      "Validation Loss: 0.6812512487978548,AUC: 0.582372972972973,ACC:0.627108108108108,F1:0.45208108108108097,Precision:0.666302702702703,Recall:0.3553108108108108\n",
      "Epoch 105,loss:0.676489433356091\n",
      "Validation Loss: 0.681074670843176,AUC: 0.5823243243243243,ACC:0.6281648648648647,F1:0.45315945945945946,Precision:0.6682837837837841,Recall:0.3554972972972973\n",
      "Epoch 110,loss:0.6762201495930157\n",
      "Validation Loss: 0.6809364863344141,AUC: 0.5825513513513513,ACC:0.6287999999999998,F1:0.45464594594594604,Precision:0.6687891891891893,Recall:0.3573972972972973\n",
      "Epoch 115,loss:0.675968891223975\n",
      "Validation Loss: 0.680798272828798,AUC: 0.5823567567567568,ACC:0.6294324324324323,F1:0.45250270270270276,Precision:0.6748081081081081,Recall:0.354445945945946\n",
      "Epoch 120,loss:0.6757352974562518\n",
      "Validation Loss: 0.680684829080427,AUC: 0.5824324324324325,ACC:0.6292189189189188,F1:0.45618108108108124,Precision:0.6685054054054054,Recall:0.35847297297297304\n",
      "Epoch 125,loss:0.6755153389103645\n",
      "Validation Loss: 0.6805831322798858,AUC: 0.5825675675675674,ACC:0.6292189189189188,F1:0.45618108108108124,Precision:0.6685054054054054,Recall:0.35847297297297304\n",
      "Epoch 130,loss:0.6753095768194283\n",
      "Validation Loss: 0.6804988835309003,AUC: 0.5823972972972973,ACC:0.627954054054054,F1:0.4598459459459459,Precision:0.6645324324324324,Recall:0.36323243243243253\n",
      "Epoch 135,loss:0.6751087091665352\n",
      "Validation Loss: 0.6803920269012451,AUC: 0.5828621621621624,ACC:0.6279540540540539,F1:0.46134054054054047,Precision:0.6635486486486486,Recall:0.3655135135135136\n",
      "Epoch 140,loss:0.6749204840280313\n",
      "Validation Loss: 0.6803160696416288,AUC: 0.5830378378378377,ACC:0.6283756756756755,F1:0.4608756756756757,Precision:0.6659567567567567,Recall:0.3645216216216217\n",
      "Epoch 145,loss:0.6747431723417434\n",
      "Validation Loss: 0.680241225539027,AUC: 0.5831378378378378,ACC:0.6283756756756755,F1:0.46102162162162164,Precision:0.6659513513513513,Recall:0.36479189189189204\n",
      "Epoch 150,loss:0.6745714756239832\n",
      "Validation Loss: 0.6801716830279376,AUC: 0.5839567567567568,ACC:0.6279540540540539,F1:0.4602810810810812,Precision:0.6654648648648648,Recall:0.3639648648648649\n",
      "Epoch 155,loss:0.6744078360827623\n",
      "Validation Loss: 0.6801053301708119,AUC: 0.5844567567567569,ACC:0.6281648648648647,F1:0.46114324324324324,Precision:0.6634972972972971,Recall:0.36481081081081085\n",
      "Epoch 160,loss:0.6742441369368967\n",
      "Validation Loss: 0.6800407155140026,AUC: 0.5846405405405404,ACC:0.6273216216216215,F1:0.46023783783783795,Precision:0.6624891891891891,Recall:0.3638027027027027\n",
      "Epoch 165,loss:0.6740911228466878\n",
      "Validation Loss: 0.6799882747031547,AUC: 0.5843054054054054,ACC:0.6283756756756755,F1:0.4585837837837838,Precision:0.6671729729729731,Recall:0.36076756756756767\n",
      "Epoch 170,loss:0.6739412852093182\n",
      "Validation Loss: 0.6799497652698208,AUC: 0.5853621621621621,ACC:0.6283783783783783,F1:0.4568405405405405,Precision:0.670783783783784,Recall:0.35866216216216223\n",
      "Epoch 175,loss:0.6737873649175188\n",
      "Validation Loss: 0.6798950884793256,AUC: 0.5851189189189189,ACC:0.6292216216216215,F1:0.45581351351351346,Precision:0.6759513513513514,Recall:0.35716216216216223\n",
      "Epoch 180,loss:0.6736402495772438\n",
      "Validation Loss: 0.679846330268963,AUC: 0.5853675675675676,ACC:0.6288,F1:0.4548783783783784,Precision:0.6758081081081081,Recall:0.35618378378378385\n",
      "Epoch 185,loss:0.6734916773517575\n",
      "Validation Loss: 0.6797863889384914,AUC: 0.585472972972973,ACC:0.6288027027027027,F1:0.4581999999999999,Precision:0.6701108108108109,Recall:0.3598378378378379\n",
      "Epoch 190,loss:0.6733406233576547\n",
      "Validation Loss: 0.6797463072312845,AUC: 0.5858270270270272,ACC:0.6288027027027027,F1:0.457862162162162,Precision:0.6701972972972974,Recall:0.35937837837837844\n",
      "Epoch 195,loss:0.6731908595667476\n",
      "Validation Loss: 0.6796918849687319,AUC: 0.5857756756756757,ACC:0.6296459459459459,F1:0.45288378378378374,Precision:0.6777243243243244,Recall:0.35388918918918916\n",
      "Epoch 200,loss:0.6730346321004682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6796662291964969,AUC: 0.5860216216216215,ACC:0.6298567567567567,F1:0.45418918918918916,Precision:0.6767243243243244,Recall:0.3557486486486487\n",
      "Epoch 205,loss:0.6728964025995373\n",
      "Validation Loss: 0.6796216578096956,AUC: 0.5857351351351351,ACC:0.6292243243243243,F1:0.4569702702702703,Precision:0.6713243243243244,Recall:0.359727027027027\n",
      "Epoch 210,loss:0.6727485071241328\n",
      "Validation Loss: 0.6795906440631764,AUC: 0.5852729729729729,ACC:0.6298567567567568,F1:0.45362702702702706,Precision:0.6771297297297298,Recall:0.35329729729729736\n",
      "Epoch 215,loss:0.6725988240368599\n",
      "Validation Loss: 0.6795437690374013,AUC: 0.5854918918918918,ACC:0.6294351351351352,F1:0.45367297297297293,Precision:0.6751945945945946,Recall:0.353318918918919\n",
      "Epoch 220,loss:0.6724535300668362\n",
      "Validation Loss: 0.6794999177391464,AUC: 0.5852783783783783,ACC:0.6292243243243244,F1:0.45187297297297296,Precision:0.6781540540540543,Recall:0.3518135135135135\n",
      "Epoch 225,loss:0.6723161081297208\n",
      "Validation Loss: 0.6794326949763942,AUC: 0.5857054054054053,ACC:0.6292243243243244,F1:0.4526405405405406,Precision:0.6776351351351354,Recall:0.3527837837837838\n",
      "Epoch 230,loss:0.6721723986937936\n",
      "Validation Loss: 0.6793790459632874,AUC: 0.585354054054054,ACC:0.6296459459459459,F1:0.45245405405405414,Precision:0.6795027027027029,Recall:0.35174864864864863\n",
      "Epoch 235,loss:0.6720383515400169\n",
      "Validation Loss: 0.6793499878934912,AUC: 0.5853513513513514,ACC:0.6298540540540539,F1:0.44803513513513515,Precision:0.6820000000000002,Recall:0.34641351351351357\n",
      "Epoch 240,loss:0.6719065709451658\n",
      "Validation Loss: 0.6793239358309153,AUC: 0.5853378378378379,ACC:0.6294324324324324,F1:0.45079459459459464,Precision:0.679372972972973,Recall:0.3493864864864865\n",
      "Epoch 245,loss:0.6717725586047215\n",
      "Validation Loss: 0.6792839846095523,AUC: 0.585537837837838,ACC:0.630281081081081,F1:0.45227027027027034,Precision:0.6816135135135137,Recall:0.3508594594594595\n",
      "Epoch 250,loss:0.671642577226183\n",
      "Validation Loss: 0.6792562072341507,AUC: 0.5860243243243244,ACC:0.631127027027027,F1:0.45383783783783777,Precision:0.6840162162162163,Recall:0.35291891891891897\n",
      "Epoch 255,loss:0.6715116448107019\n",
      "Validation Loss: 0.6792389847136833,AUC: 0.5861621621621622,ACC:0.6302837837837838,F1:0.458045945945946,Precision:0.674537837837838,Recall:0.35874054054054066\n",
      "Epoch 260,loss:0.6713802086568512\n",
      "Validation Loss: 0.6792004736694129,AUC: 0.5866135135135137,ACC:0.6309162162162162,F1:0.4595135135135135,Precision:0.6758945945945948,Recall:0.36029189189189187\n",
      "Epoch 265,loss:0.6712573502971008\n",
      "Validation Loss: 0.6791780075511417,AUC: 0.5865297297297297,ACC:0.6309162162162163,F1:0.45722972972972975,Precision:0.6802378378378381,Recall:0.3573891891891892\n",
      "Epoch 270,loss:0.6711321884551934\n",
      "Validation Loss: 0.6791480602444829,AUC: 0.5865405405405407,ACC:0.6309162162162163,F1:0.4525648648648648,Precision:0.6839189189189189,Recall:0.3519432432432432\n",
      "Epoch 275,loss:0.6710035827307574\n",
      "Validation Loss: 0.6790831443425771,AUC: 0.5864945945945946,ACC:0.6315486486486487,F1:0.44384864864864865,Precision:0.6915891891891892,Recall:0.3403378378378378\n",
      "Epoch 280,loss:0.670881848419662\n",
      "Validation Loss: 0.6790514475590473,AUC: 0.5867810810810812,ACC:0.6319729729729731,F1:0.44706486486486474,Precision:0.6905405405405406,Recall:0.3428459459459459\n",
      "Epoch 285,loss:0.670763584364832\n",
      "Validation Loss: 0.6790130299490851,AUC: 0.5866837837837838,ACC:0.6326081081081081,F1:0.4486432432432432,Precision:0.690127027027027,Recall:0.3451837837837838\n",
      "Epoch 290,loss:0.670647045679852\n",
      "Validation Loss: 0.6789595420296127,AUC: 0.5870108108108109,ACC:0.6326081081081081,F1:0.44785135135135135,Precision:0.6921702702702703,Recall:0.3433864864864864\n",
      "Epoch 295,loss:0.6705341391858801\n",
      "Validation Loss: 0.6789095643404368,AUC: 0.5864756756756757,ACC:0.632818918918919,F1:0.44961351351351353,Precision:0.6921567567567568,Recall:0.34644864864864866\n",
      "Epoch 300,loss:0.6704181321954306\n",
      "Validation Loss: 0.6788677041595047,AUC: 0.5865432432432433,ACC:0.6323945945945947,F1:0.4501837837837838,Precision:0.6891837837837839,Recall:0.3476108108108109\n",
      "Epoch 305,loss:0.6703152630181439\n",
      "Validation Loss: 0.6788194743362633,AUC: 0.586110810810811,ACC:0.6328135135135136,F1:0.4447351351351353,Precision:0.6932540540540542,Recall:0.34038108108108106\n",
      "Epoch 310,loss:0.6701962837075766\n",
      "Validation Loss: 0.6787787530873273,AUC: 0.586891891891892,ACC:0.6332351351351352,F1:0.4471513513513514,Precision:0.6925837837837838,Recall:0.3421162162162162\n",
      "Epoch 315,loss:0.6700901689782607\n",
      "Validation Loss: 0.6787473204973582,AUC: 0.5873567567567568,ACC:0.633445945945946,F1:0.4497540540540542,Precision:0.6898513513513514,Recall:0.3451216216216217\n",
      "Epoch 320,loss:0.6699680912811145\n",
      "Validation Loss: 0.6787012767147373,AUC: 0.5877216216216217,ACC:0.6336567567567567,F1:0.4459675675675675,Precision:0.6941594594594596,Recall:0.34032162162162166\n",
      "Epoch 325,loss:0.6698562761323642\n",
      "Validation Loss: 0.678658351704881,AUC: 0.5877675675675677,ACC:0.6336567567567567,F1:0.44595135135135144,Precision:0.695545945945946,Recall:0.34022432432432437\n",
      "Epoch 330,loss:0.6697464769920417\n",
      "Validation Loss: 0.6786164254755587,AUC: 0.5876270270270272,ACC:0.6342864864864864,F1:0.4449027027027028,Precision:0.6985000000000001,Recall:0.33786216216216225\n",
      "Epoch 335,loss:0.6696326231534502\n",
      "Validation Loss: 0.6785665025582185,AUC: 0.5878783783783783,ACC:0.6344972972972972,F1:0.44215675675675686,Precision:0.702810810810811,Recall:0.3345702702702703\n",
      "Epoch 340,loss:0.6695054695669529\n",
      "Validation Loss: 0.6785219521135897,AUC: 0.5873486486486487,ACC:0.6336540540540541,F1:0.4501837837837838,Precision:0.6931540540540541,Recall:0.3446297297297297\n",
      "Epoch 345,loss:0.6693752708688246\n",
      "Validation Loss: 0.6784791414802139,AUC: 0.5868135135135137,ACC:0.6345027027027029,F1:0.44991081081081086,Precision:0.7012432432432432,Recall:0.3444999999999999\n",
      "Epoch 350,loss:0.6692237563892803\n",
      "Validation Loss: 0.6784319748749604,AUC: 0.5869216216216216,ACC:0.6345027027027029,F1:0.44909729729729736,Precision:0.7052054054054053,Recall:0.34526486486486485\n",
      "Epoch 355,loss:0.6690914952649479\n",
      "Validation Loss: 0.6784121925766403,AUC: 0.5872945945945947,ACC:0.6342918918918921,F1:0.4516027027027027,Precision:0.7009432432432433,Recall:0.34926486486486485\n",
      "Epoch 360,loss:0.668946994616922\n",
      "Validation Loss: 0.6783655269725902,AUC: 0.5864648648648648,ACC:0.6334486486486487,F1:0.4542162162162162,Precision:0.6869783783783785,Recall:0.35254324324324315\n",
      "Epoch 365,loss:0.6688022386711255\n",
      "Validation Loss: 0.678333659429808,AUC: 0.5866513513513514,ACC:0.6326054054054054,F1:0.4576081081081082,Precision:0.6834243243243247,Recall:0.3584027027027027\n",
      "Epoch 370,loss:0.6686673486127263\n",
      "Validation Loss: 0.6782844453244596,AUC: 0.5871324324324324,ACC:0.6323918918918919,F1:0.46131351351351363,Precision:0.684791891891892,Recall:0.36602702702702694\n",
      "Epoch 375,loss:0.6685456860381945\n",
      "Validation Loss: 0.678235775715596,AUC: 0.5864081081081083,ACC:0.6319702702702703,F1:0.46677027027027035,Precision:0.6782540540540541,Recall:0.37312972972972963\n",
      "Epoch 380,loss:0.6684302735117684\n",
      "Validation Loss: 0.6781656597111676,AUC: 0.5863,ACC:0.6347135135135137,F1:0.46156756756756767,Precision:0.6922702702702704,Recall:0.3640648648648648\n",
      "Epoch 385,loss:0.6683112757395854\n",
      "Validation Loss: 0.6780942968420081,AUC: 0.586527027027027,ACC:0.6336540540540542,F1:0.46220270270270286,Precision:0.6908756756756756,Recall:0.36578378378378373\n",
      "Epoch 390,loss:0.6681879743010597\n",
      "Validation Loss: 0.6780494387085373,AUC: 0.5866675675675677,ACC:0.6340810810810812,F1:0.45973513513513536,Precision:0.6927324324324323,Recall:0.36256756756756753\n",
      "Epoch 395,loss:0.668080853677429\n",
      "Validation Loss: 0.6779915706531422,AUC: 0.5868081081081079,ACC:0.6330270270270271,F1:0.46046216216216224,Precision:0.6823432432432431,Recall:0.3624054054054054\n",
      "Epoch 400,loss:0.6679694874096761\n",
      "Validation Loss: 0.6779658230575355,AUC: 0.5863540540540538,ACC:0.6309135135135134,F1:0.4665162162162162,Precision:0.672572972972973,Recall:0.37298378378378383\n",
      "Epoch 405,loss:0.6678736610750181\n",
      "Validation Loss: 0.6779942866918203,AUC: 0.586681081081081,ACC:0.6304864864864864,F1:0.4693324324324324,Precision:0.6720783783783784,Recall:0.3806108108108108\n",
      "早停策略触发，停止训练在第 404 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 15:43:21.864613 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 15:43:21.878987 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 15:43:21.892056 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 15:43:21.905175 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 15:43:21.918273 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 15:43:21.931552 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 15:43:21.944656 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 15:43:21.958408 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 15:43:21.972214 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 15:43:21.985358 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 15:43:21.998467 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 15:43:22.012580 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 15:43:22.025804 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 15:43:22.039012 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 15:43:22.052130 -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 15:43:22.065986 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 15:43:22.079074 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 15:43:22.092144 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 15:43:22.105255 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 15:43:22.118347 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 15:43:22.131438 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 15:43:22.144462 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 15:43:22.157524 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 15:43:22.170553 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 15:43:22.183584 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 15:43:22.196511 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 15:43:22.209552 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 15:43:22.222542 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 15:43:22.235705 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 15:43:22.249216 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 15:43:22.262229 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 15:43:22.275643 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 15:43:22.289077 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 15:43:22.302311 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 15:43:22.315311 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 15:43:22.328412 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 15:43:22.343562 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 15:43:22.357529 -------------\n",
      "Test Loss: 0.676965510522997,AUC: 0.5805594594594596,ACC:0.6304864864864864,F1:0.4311756756756756,Precision:0.7137135135135135,Recall:0.3234054054054054\n",
      "i=:3\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6916487032333306\n",
      "Validation Loss: 0.6896329119398787,AUC: 0.565091891891892,ACC:0.6055729729729729,F1:0.45568108108108113,Precision:0.6226945945945946,Recall:0.3959999999999999\n",
      "Epoch 10,loss:0.6906765541144176\n",
      "Validation Loss: 0.6888821092811791,AUC: 0.5669972972972973,ACC:0.6066351351351351,F1:0.4399594594594594,Precision:0.6341405405405405,Recall:0.3703108108108108\n",
      "Epoch 15,loss:0.6897390701074516\n",
      "Validation Loss: 0.688203742375245,AUC: 0.5691891891891893,ACC:0.6083216216216215,F1:0.44222432432432435,Precision:0.6299054054054056,Recall:0.3716810810810811\n",
      "Epoch 20,loss:0.6887226706057523\n",
      "Validation Loss: 0.6874390969405303,AUC: 0.5707432432432431,ACC:0.6110675675675676,F1:0.44582432432432423,Precision:0.6287297297297297,Recall:0.36766486486486494\n",
      "Epoch 25,loss:0.6876122946232821\n",
      "Validation Loss: 0.6866532870241113,AUC: 0.572535135135135,ACC:0.6135972972972973,F1:0.4553027027027026,Precision:0.6415621621621621,Recall:0.3817135135135135\n",
      "Epoch 30,loss:0.6863983157461724\n",
      "Validation Loss: 0.6858119271896981,AUC: 0.5730108108108107,ACC:0.6167702702702703,F1:0.4611378378378378,Precision:0.638772972972973,Recall:0.3861945945945946\n",
      "Epoch 35,loss:0.6852508334986931\n",
      "Validation Loss: 0.6850852193059148,AUC: 0.5744162162162163,ACC:0.6176162162162164,F1:0.46696486486486494,Precision:0.6365108108108106,Recall:0.39076486486486484\n",
      "Epoch 40,loss:0.6842181413574556\n",
      "Validation Loss: 0.6844618223808907,AUC: 0.5749189189189187,ACC:0.6150837837837838,F1:0.4671972972972972,Precision:0.6401135135135135,Recall:0.39417567567567563\n",
      "Epoch 45,loss:0.6832690972142514\n",
      "Validation Loss: 0.683963600042704,AUC: 0.5763216216216217,ACC:0.615291891891892,F1:0.4675405405405405,Precision:0.6401702702702705,Recall:0.3928054054054054\n",
      "Epoch 50,loss:0.6823944507446964\n",
      "Validation Loss: 0.6835273617022747,AUC: 0.5771216216216216,ACC:0.6220432432432432,F1:0.4538243243243243,Precision:0.6585540540540542,Recall:0.3657054054054054\n",
      "Epoch 55,loss:0.6815985678571516\n",
      "Validation Loss: 0.6831449254139049,AUC: 0.5789756756756755,ACC:0.6237324324324324,F1:0.4523648648648649,Precision:0.6653270270270272,Recall:0.3605972972972973\n",
      "Epoch 60,loss:0.6808776702501077\n",
      "Validation Loss: 0.6828341065226374,AUC: 0.5800108108108109,ACC:0.6249999999999999,F1:0.4551567567567568,Precision:0.6657837837837839,Recall:0.36513783783783776\n",
      "Epoch 65,loss:0.6802430706741536\n",
      "Validation Loss: 0.6825654651667621,AUC: 0.581083783783784,ACC:0.6235243243243243,F1:0.46010540540540534,Precision:0.6581135135135135,Recall:0.3708297297297298\n",
      "Epoch 70,loss:0.6796890982484396\n",
      "Validation Loss: 0.6823338544046557,AUC: 0.5816864864864864,ACC:0.624154054054054,F1:0.4580216216216217,Precision:0.6632675675675674,Recall:0.3683594594594594\n",
      "Epoch 75,loss:0.6791943069052907\n",
      "Validation Loss: 0.6821309392516678,AUC: 0.5829216216216218,ACC:0.6247891891891891,F1:0.4569972972972974,Precision:0.6621351351351351,Recall:0.3651432432432432\n",
      "Epoch 80,loss:0.678746422835156\n",
      "Validation Loss: 0.6819682524010942,AUC: 0.5823702702702702,ACC:0.6247891891891891,F1:0.45570270270270274,Precision:0.6674297297297297,Recall:0.36363243243243243\n",
      "Epoch 85,loss:0.6783441104720124\n",
      "Validation Loss: 0.6818147076142801,AUC: 0.5827135135135134,ACC:0.6254189189189189,F1:0.44847297297297295,Precision:0.6702702702702703,Recall:0.3548\n",
      "Epoch 90,loss:0.6779718552015525\n",
      "Validation Loss: 0.6816776829796869,AUC: 0.5835432432432431,ACC:0.6249972972972972,F1:0.44600540540540534,Precision:0.6734486486486487,Recall:0.35236486486486496\n",
      "Epoch 95,loss:0.6776368385922592\n",
      "Validation Loss: 0.6815642859484699,AUC: 0.5833108108108108,ACC:0.6254189189189188,F1:0.4466594594594595,Precision:0.6745081081081081,Recall:0.35295675675675686\n",
      "Epoch 100,loss:0.6773140071767622\n",
      "Validation Loss: 0.6814607736226674,AUC: 0.5827000000000001,ACC:0.6258432432432433,F1:0.4469432432432434,Precision:0.6778513513513513,Recall:0.35292432432432447\n",
      "Epoch 105,loss:0.6769999835343488\n",
      "Validation Loss: 0.6813486975592535,AUC: 0.5825513513513515,ACC:0.6258432432432433,F1:0.444118918918919,Precision:0.6798000000000001,Recall:0.34914324324324336\n",
      "Epoch 110,loss:0.6767205522123692\n",
      "Validation Loss: 0.681254958784258,AUC: 0.5819081081081083,ACC:0.6271081081081081,F1:0.4467486486486487,Precision:0.6740621621621623,Recall:0.3499702702702704\n",
      "Epoch 115,loss:0.6764589616682677\n",
      "Validation Loss: 0.6811648236738669,AUC: 0.5821837837837838,ACC:0.6271081081081081,F1:0.45077297297297286,Precision:0.66542972972973,Recall:0.35569189189189193\n",
      "Epoch 120,loss:0.6762089708210093\n",
      "Validation Loss: 0.6810714280283129,AUC: 0.5817027027027025,ACC:0.6268972972972972,F1:0.4510864864864864,Precision:0.6677621621621623,Recall:0.3558108108108109\n",
      "Epoch 125,loss:0.675967455437753\n",
      "Validation Loss: 0.6810117267273568,AUC: 0.5820756756756755,ACC:0.627108108108108,F1:0.4496972972972972,Precision:0.6709000000000002,Recall:0.35401081081081087\n",
      "Epoch 130,loss:0.675736863001258\n",
      "Validation Loss: 0.6809396196056057,AUC: 0.5828324324324324,ACC:0.627108108108108,F1:0.4508648648648648,Precision:0.6697675675675676,Recall:0.35555675675675685\n",
      "Epoch 135,loss:0.6755122494908561\n",
      "Validation Loss: 0.6808736614278845,AUC: 0.583554054054054,ACC:0.6258432432432433,F1:0.4523405405405405,Precision:0.6676918918918918,Recall:0.35905405405405405\n",
      "Epoch 140,loss:0.6752987904886228\n",
      "Validation Loss: 0.6808165521235079,AUC: 0.583772972972973,ACC:0.6266864864864865,F1:0.4489594594594594,Precision:0.6727621621621622,Recall:0.35294594594594597\n",
      "Epoch 145,loss:0.6750974655151367\n",
      "Validation Loss: 0.6807608539993698,AUC: 0.5832837837837839,ACC:0.6264810810810811,F1:0.450654054054054,Precision:0.6716567567567567,Recall:0.3544918918918919\n",
      "Epoch 150,loss:0.674905362909874\n",
      "Validation Loss: 0.680690665502806,AUC: 0.5834621621621621,ACC:0.6269027027027028,F1:0.4536837837837838,Precision:0.6693891891891893,Recall:0.35883243243243246\n",
      "Epoch 155,loss:0.674719029295761\n",
      "Validation Loss: 0.6806346097507993,AUC: 0.5832405405405405,ACC:0.6271135135135136,F1:0.4527891891891892,Precision:0.6725000000000002,Recall:0.35773243243243247\n",
      "Epoch 160,loss:0.674538970521066\n",
      "Validation Loss: 0.6805700176470989,AUC: 0.5832324324324324,ACC:0.6277459459459461,F1:0.45338648648648644,Precision:0.6714027027027027,Recall:0.35760270270270267\n",
      "Epoch 165,loss:0.6743632755448333\n",
      "Validation Loss: 0.6804974224116351,AUC: 0.5832513513513515,ACC:0.6283783783783784,F1:0.4520702702702702,Precision:0.6736756756756758,Recall:0.3559054054054054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170,loss:0.6741833449464983\n",
      "Validation Loss: 0.6804291654277492,AUC: 0.583527027027027,ACC:0.6300675675675675,F1:0.4510945945945946,Precision:0.6773351351351352,Recall:0.35286486486486485\n",
      "Epoch 175,loss:0.6740181277283525\n",
      "Validation Loss: 0.6803789106575219,AUC: 0.5838432432432431,ACC:0.6307027027027027,F1:0.4524135135135135,Precision:0.6786675675675677,Recall:0.3541324324324323\n",
      "Epoch 180,loss:0.6738522126611355\n",
      "Validation Loss: 0.6803173036188692,AUC: 0.5835648648648647,ACC:0.6311243243243243,F1:0.454864864864865,Precision:0.6755324324324326,Recall:0.3574675675675675\n",
      "Epoch 185,loss:0.6736944207047995\n",
      "Validation Loss: 0.6802547735136908,AUC: 0.5835621621621618,ACC:0.6315486486486487,F1:0.4519054054054054,Precision:0.6812594594594595,Recall:0.35145405405405394\n",
      "Epoch 190,loss:0.6735429837640408\n",
      "Validation Loss: 0.6801994732908301,AUC: 0.5838621621621621,ACC:0.6306999999999999,F1:0.4546567567567568,Precision:0.6772459459459459,Recall:0.3554405405405406\n",
      "Epoch 195,loss:0.6733963948435489\n",
      "Validation Loss: 0.6801405549049377,AUC: 0.5834864864864866,ACC:0.6313351351351351,F1:0.4538054054054054,Precision:0.6781189189189188,Recall:0.35444324324324317\n",
      "Epoch 200,loss:0.6732519516902687\n",
      "Validation Loss: 0.6800818749376245,AUC: 0.5832351351351351,ACC:0.6309135135135135,F1:0.4545,Precision:0.6761945945945943,Recall:0.3560594594594595\n",
      "Epoch 205,loss:0.6731042192045567\n",
      "Validation Loss: 0.6800190033139409,AUC: 0.5834567567567567,ACC:0.6309135135135134,F1:0.4565378378378379,Precision:0.6730378378378377,Recall:0.35810810810810806\n",
      "Epoch 210,loss:0.6729602940314638\n",
      "Validation Loss: 0.6799718141555786,AUC: 0.5837108108108109,ACC:0.6309135135135134,F1:0.45583243243243243,Precision:0.6761729729729729,Recall:0.35889999999999994\n",
      "Epoch 215,loss:0.6728235778555406\n",
      "Validation Loss: 0.6799282302727571,AUC: 0.5837189189189188,ACC:0.6300702702702703,F1:0.45684864864864877,Precision:0.6755594594594594,Recall:0.36101351351351346\n",
      "Epoch 220,loss:0.6726921095257312\n",
      "Validation Loss: 0.6798786585395401,AUC: 0.5841243243243243,ACC:0.6298594594594594,F1:0.45603513513513516,Precision:0.6752540540540539,Recall:0.3604351351351352\n",
      "Epoch 225,loss:0.6725657387117369\n",
      "Validation Loss: 0.679827868938446,AUC: 0.5844918918918918,ACC:0.6309135135135134,F1:0.4510594594594595,Precision:0.6872675675675674,Recall:0.35486216216216226\n",
      "Epoch 230,loss:0.6724402598575153\n",
      "Validation Loss: 0.6797982405971836,AUC: 0.5849243243243243,ACC:0.6313378378378378,F1:0.44868108108108123,Precision:0.6913918918918917,Recall:0.3518108108108109\n",
      "Epoch 235,loss:0.6723268475152749\n",
      "Validation Loss: 0.6797607106131476,AUC: 0.5859027027027027,ACC:0.6309135135135134,F1:0.4515783783783786,Precision:0.6879567567567566,Recall:0.3551702702702703\n",
      "Epoch 240,loss:0.6722083234154017\n",
      "Validation Loss: 0.6796927258775041,AUC: 0.5857810810810811,ACC:0.6311297297297298,F1:0.4511081081081082,Precision:0.6886864864864864,Recall:0.35407567567567577\n",
      "Epoch 245,loss:0.67208299278158\n",
      "Validation Loss: 0.6796456220987681,AUC: 0.5858756756756758,ACC:0.6321864864864868,F1:0.4500567567567569,Precision:0.6920324324324324,Recall:0.35114054054054056\n",
      "Epoch 250,loss:0.6719527967208254\n",
      "Validation Loss: 0.6796024602812689,AUC: 0.5859918918918919,ACC:0.6319702702702703,F1:0.450237837837838,Precision:0.6898783783783783,Recall:0.35132432432432437\n",
      "Epoch 255,loss:0.6718353196582963\n",
      "Validation Loss: 0.6795588006844392,AUC: 0.5863837837837839,ACC:0.6319702702702703,F1:0.44992972972972983,Precision:0.6901837837837836,Recall:0.35090270270270274\n",
      "Epoch 260,loss:0.6717148882097903\n",
      "Validation Loss: 0.6795344739346891,AUC: 0.5866432432432434,ACC:0.6317594594594597,F1:0.45037297297297313,Precision:0.6892243243243241,Recall:0.3518756756756757\n",
      "Epoch 265,loss:0.671592583698509\n",
      "Validation Loss: 0.6794808410309456,AUC: 0.5870513513513514,ACC:0.6321810810810813,F1:0.45512162162162173,Precision:0.6872297297297296,Recall:0.35755675675675674\n",
      "Epoch 270,loss:0.6714549069910978\n",
      "Validation Loss: 0.6794552062008832,AUC: 0.5869594594594594,ACC:0.6336621621621623,F1:0.45407027027027025,Precision:0.6918972972972971,Recall:0.3552135135135135\n",
      "Epoch 275,loss:0.6713266430702884\n",
      "Validation Loss: 0.6794168336971386,AUC: 0.5870243243243243,ACC:0.6336621621621623,F1:0.45287027027027027,Precision:0.692735135135135,Recall:0.3533648648648649\n",
      "Epoch 280,loss:0.6711872763338342\n",
      "Validation Loss: 0.6793824933670662,AUC: 0.5869135135135135,ACC:0.6338756756756758,F1:0.45406486486486497,Precision:0.6923621621621618,Recall:0.35506216216216213\n",
      "Epoch 285,loss:0.6710666338954352\n",
      "Validation Loss: 0.6793255048829157,AUC: 0.5871162162162161,ACC:0.6334513513513514,F1:0.4532648648648649,Precision:0.6913459459459457,Recall:0.3542054054054054\n",
      "Epoch 290,loss:0.6709501352985349\n",
      "Validation Loss: 0.6792883470251754,AUC: 0.587272972972973,ACC:0.6336621621621623,F1:0.4534243243243243,Precision:0.6924108108108105,Recall:0.3542054054054054\n",
      "Epoch 295,loss:0.6708290608583298\n",
      "Validation Loss: 0.6792515629046673,AUC: 0.5865972972972974,ACC:0.6332405405405407,F1:0.4520783783783783,Precision:0.6928027027027025,Recall:0.35195945945945944\n",
      "Epoch 300,loss:0.6707144553682446\n",
      "Validation Loss: 0.6792440398319347,AUC: 0.5865621621621624,ACC:0.6328189189189191,F1:0.45322432432432425,Precision:0.6913243243243241,Recall:0.35361891891891895\n",
      "Epoch 305,loss:0.670594500229422\n",
      "Validation Loss: 0.6792397482975109,AUC: 0.5868324324324324,ACC:0.6330297297297298,F1:0.4545972972972972,Precision:0.6924108108108107,Recall:0.3554540540540541\n",
      "Epoch 310,loss:0.6704756406556188\n",
      "Validation Loss: 0.6792113555444254,AUC: 0.586810810810811,ACC:0.6334513513513516,F1:0.45294054054054045,Precision:0.6955540540540539,Recall:0.35267567567567565\n",
      "Epoch 315,loss:0.6703538388277577\n",
      "Validation Loss: 0.67921692938418,AUC: 0.5868567567567569,ACC:0.6338729729729732,F1:0.45294054054054045,Precision:0.6979513513513512,Recall:0.3521945945945946\n",
      "早停策略触发，停止训练在第 314 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 16:29:30.135725 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 16:29:30.149266 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 16:29:30.162059 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 16:29:30.174864 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 16:29:30.187662 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 16:29:30.200777 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 16:29:30.213616 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 16:29:30.226789 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 16:29:30.239519 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 16:29:30.252316 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 16:29:30.265069 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 16:29:30.278114 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 16:29:30.290881 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 16:29:30.304566 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 16:29:30.317333 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 16:29:30.330134 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 16:29:30.343468 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 16:29:30.356733 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 16:29:30.369535 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 16:29:30.382562 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 16:29:30.395346 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 16:29:30.408158 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 16:29:30.421689 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 16:29:30.434441 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 16:29:30.447189 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 16:29:30.459920 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 16:29:30.472663 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 16:29:30.485464 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 16:29:30.498711 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 16:29:30.511486 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 16:29:30.524302 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 16:29:30.537143 -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 16:29:30.550522 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 16:29:30.563340 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 16:29:30.576081 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 16:29:30.588865 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 16:29:30.602070 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 16:29:30.614944 -------------\n",
      "Test Loss: 0.6768894421087729,AUC: 0.5816405405405407,ACC:0.6256270270270269,F1:0.4375702702702703,Precision:0.6924648648648649,Recall:0.33202972972972983\n",
      "i=:4\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6914448020732509\n",
      "Validation Loss: 0.6898158595368669,AUC: 0.5648297297297297,ACC:0.6068351351351351,F1:0.44407567567567574,Precision:0.6394945945945947,Recall:0.3774108108108108\n",
      "Epoch 10,loss:0.6902601265274317\n",
      "Validation Loss: 0.6885621467152158,AUC: 0.5667243243243245,ACC:0.6100081081081081,F1:0.45033783783783776,Precision:0.6282378378378378,Recall:0.3825837837837838\n",
      "Epoch 15,loss:0.6889797211748309\n",
      "Validation Loss: 0.6874492184535878,AUC: 0.570808108108108,ACC:0.6144432432432432,F1:0.4517189189189189,Precision:0.6493459459459461,Recall:0.37505945945945945\n",
      "Epoch 20,loss:0.6877099660645544\n",
      "Validation Loss: 0.6864314095394032,AUC: 0.5732054054054055,ACC:0.6176081081081082,F1:0.44267027027027034,Precision:0.6617864864864866,Recall:0.3612324324324324\n",
      "Epoch 25,loss:0.686461631175691\n",
      "Validation Loss: 0.6855963049708186,AUC: 0.5744594594594595,ACC:0.6182432432432432,F1:0.45412972972972976,Precision:0.6534864864864869,Recall:0.3724567567567567\n",
      "Epoch 30,loss:0.6852883026663181\n",
      "Validation Loss: 0.6849037698797278,AUC: 0.5761837837837838,ACC:0.6199351351351352,F1:0.45770540540540544,Precision:0.6538027027027028,Recall:0.37705405405405407\n",
      "Epoch 35,loss:0.6841878590330613\n",
      "Validation Loss: 0.6843314605790216,AUC: 0.5772486486486486,ACC:0.6205702702702703,F1:0.4514972972972972,Precision:0.6686675675675675,Recall:0.363445945945946\n",
      "Epoch 40,loss:0.6831610529823641\n",
      "Validation Loss: 0.6838308701644072,AUC: 0.5782297297297296,ACC:0.6197324324324325,F1:0.4569891891891892,Precision:0.6533216216216217,Recall:0.37273783783783787\n",
      "Epoch 45,loss:0.6822549853704672\n",
      "Validation Loss: 0.6834085599796192,AUC: 0.5778324324324325,ACC:0.6201486486486487,F1:0.4611594594594595,Precision:0.6513810810810812,Recall:0.3785243243243243\n",
      "Epoch 50,loss:0.6814257702996246\n",
      "Validation Loss: 0.6830320503260638,AUC: 0.5779675675675676,ACC:0.6209918918918919,F1:0.4627432432432433,Precision:0.6546216216216215,Recall:0.3775108108108108\n",
      "Epoch 55,loss:0.6807147549316946\n",
      "Validation Loss: 0.682694939342705,AUC: 0.5793459459459459,ACC:0.625,F1:0.4536108108108108,Precision:0.6622729729729729,Recall:0.3618351351351351\n",
      "Epoch 60,loss:0.6800776999608605\n",
      "Validation Loss: 0.6824226427722622,AUC: 0.5797594594594596,ACC:0.6252135135135135,F1:0.4594945945945945,Precision:0.6586270270270269,Recall:0.36964324324324327\n",
      "Epoch 65,loss:0.6795201264651476\n",
      "Validation Loss: 0.6821217134192183,AUC: 0.5798756756756756,ACC:0.6250000000000001,F1:0.46296756756756746,Precision:0.6577243243243243,Recall:0.3747270270270271\n",
      "Epoch 70,loss:0.6790213700944343\n",
      "Validation Loss: 0.6818689897253707,AUC: 0.5808216216216218,ACC:0.6273216216216216,F1:0.4544918918918919,Precision:0.6696405405405403,Recall:0.36065405405405415\n",
      "Epoch 75,loss:0.6785799280732079\n",
      "Validation Loss: 0.6816117860175468,AUC: 0.5824675675675677,ACC:0.6254216216216216,F1:0.45388648648648644,Precision:0.6750432432432432,Recall:0.36260000000000003\n",
      "Epoch 80,loss:0.6781867236162709\n",
      "Validation Loss: 0.6813389965005823,AUC: 0.5830108108108107,ACC:0.6271108108108109,F1:0.4505378378378379,Precision:0.6783108108108108,Recall:0.353927027027027\n",
      "Epoch 85,loss:0.677816444266159\n",
      "Validation Loss: 0.6810804943780642,AUC: 0.5832567567567566,ACC:0.6262621621621622,F1:0.4553027027027027,Precision:0.6754918918918918,Recall:0.3598135135135135\n",
      "Epoch 90,loss:0.6774768069782088\n",
      "Validation Loss: 0.6808667811187538,AUC: 0.5844864864864867,ACC:0.6258459459459459,F1:0.4609054054054054,Precision:0.6678054054054053,Recall:0.370427027027027\n",
      "Epoch 95,loss:0.6771678291590868\n",
      "Validation Loss: 0.680685230203577,AUC: 0.5850297297297297,ACC:0.6271135135135135,F1:0.45680270270270257,Precision:0.6737324324324325,Recall:0.36459729729729723\n",
      "Epoch 100,loss:0.6768830545180666\n",
      "Validation Loss: 0.6805011082339931,AUC: 0.5863054054054054,ACC:0.6262675675675676,F1:0.45771351351351347,Precision:0.6732594594594594,Recall:0.36579729729729726\n",
      "Epoch 105,loss:0.6766092703405735\n",
      "Validation Loss: 0.6803308725357056,AUC: 0.5876756756756756,ACC:0.627535135135135,F1:0.45538108108108116,Precision:0.6718756756756757,Recall:0.3599189189189189\n",
      "Epoch 110,loss:0.6763579908725434\n",
      "Validation Loss: 0.6801913670591406,AUC: 0.5872999999999999,ACC:0.6266918918918919,F1:0.4530216216216216,Precision:0.6716621621621622,Recall:0.3587189189189188\n",
      "Epoch 115,loss:0.6761250137227827\n",
      "Validation Loss: 0.6800558228750486,AUC: 0.5870486486486485,ACC:0.6262702702702702,F1:0.45941891891891884,Precision:0.6655405405405407,Recall:0.36620810810810805\n",
      "Epoch 120,loss:0.6758959836664453\n",
      "Validation Loss: 0.6799161450282948,AUC: 0.5876324324324326,ACC:0.6268999999999999,F1:0.4511027027027027,Precision:0.671272972972973,Recall:0.35588378378378377\n",
      "Epoch 125,loss:0.6756798619717623\n",
      "Validation Loss: 0.679807862719974,AUC: 0.5874621621621622,ACC:0.6277459459459459,F1:0.44819729729729735,Precision:0.6801405405405406,Recall:0.3538378378378379\n",
      "Epoch 130,loss:0.675483343348039\n",
      "Validation Loss: 0.6796812978950707,AUC: 0.5869891891891892,ACC:0.6273216216216216,F1:0.4477270270270271,Precision:0.6801918918918919,Recall:0.35273243243243246\n",
      "Epoch 135,loss:0.6752881344440764\n",
      "Validation Loss: 0.6795751178586805,AUC: 0.5873189189189187,ACC:0.627745945945946,F1:0.44818918918918926,Precision:0.6820351351351353,Recall:0.3524864864864865\n",
      "Epoch 140,loss:0.6751096417418624\n",
      "Validation Loss: 0.679478957846358,AUC: 0.5871648648648649,ACC:0.6266864864864865,F1:0.45209189189189186,Precision:0.6740054054054053,Recall:0.35905945945945955\n",
      "Epoch 145,loss:0.6749357148609331\n",
      "Validation Loss: 0.6793709171784891,AUC: 0.5871891891891892,ACC:0.6273189189189189,F1:0.45254594594594594,Precision:0.6767918918918919,Recall:0.35854324324324327\n",
      "Epoch 150,loss:0.6747647539704247\n",
      "Validation Loss: 0.6792685969455822,AUC: 0.5873864864864865,ACC:0.6279513513513513,F1:0.44950810810810815,Precision:0.6842756756756756,Recall:0.3522513513513513\n",
      "Epoch 155,loss:0.6746099443562263\n",
      "Validation Loss: 0.6791835040659517,AUC: 0.5880027027027027,ACC:0.6275324324324324,F1:0.44915405405405406,Precision:0.685654054054054,Recall:0.3523594594594595\n",
      "Epoch 160,loss:0.6744621496284957\n",
      "Validation Loss: 0.679112033264057,AUC: 0.5877162162162161,ACC:0.629854054054054,F1:0.4439297297297297,Precision:0.6960405405405405,Recall:0.3442297297297297\n",
      "Epoch 165,loss:0.6743171362750298\n",
      "Validation Loss: 0.6790602883777103,AUC: 0.5874297297297297,ACC:0.6283756756756756,F1:0.44832432432432434,Precision:0.6896837837837837,Recall:0.35210270270270283\n",
      "Epoch 170,loss:0.6741805815063746\n",
      "Validation Loss: 0.6790014988667256,AUC: 0.5874270270270271,ACC:0.6283756756756756,F1:0.4493648648648649,Precision:0.687327027027027,Recall:0.3541702702702702\n",
      "Epoch 175,loss:0.6740500431145187\n",
      "Validation Loss: 0.6789287232063912,AUC: 0.5875378378378376,ACC:0.6287972972972973,F1:0.4494864864864865,Precision:0.6878513513513513,Recall:0.3536918918918919\n",
      "Epoch 180,loss:0.673923826850621\n",
      "Validation Loss: 0.6788685386245316,AUC: 0.5870108108108107,ACC:0.6281648648648649,F1:0.4519594594594595,Precision:0.6840297297297296,Recall:0.35850000000000004\n",
      "Epoch 185,loss:0.6737979223242904\n",
      "Validation Loss: 0.6787928020631945,AUC: 0.5862756756756756,ACC:0.6288,F1:0.4517135135135134,Precision:0.6874432432432431,Recall:0.3576216216216216\n",
      "Epoch 190,loss:0.6736817449595021\n",
      "Validation Loss: 0.6787260964110091,AUC: 0.5863567567567569,ACC:0.6311216216216216,F1:0.451854054054054,Precision:0.6868918918918918,Recall:0.3537\n",
      "Epoch 195,loss:0.6735685905524059\n",
      "Validation Loss: 0.6786573529243469,AUC: 0.5870702702702705,ACC:0.6307,F1:0.4502594594594595,Precision:0.6894216216216216,Recall:0.3523594594594594\n",
      "Epoch 200,loss:0.6734485267537885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6785887882516191,AUC: 0.5866783783783784,ACC:0.6313351351351352,F1:0.45119189189189185,Precision:0.6923918918918919,Recall:0.35346216216216214\n",
      "Epoch 205,loss:0.6733333969538191\n",
      "Validation Loss: 0.6785289532429463,AUC: 0.5870702702702704,ACC:0.6309135135135134,F1:0.45433783783783777,Precision:0.6885783783783784,Recall:0.3571351351351351\n",
      "Epoch 210,loss:0.6732230487123\n",
      "Validation Loss: 0.6784593865678117,AUC: 0.5874864864864865,ACC:0.6309108108108108,F1:0.4512891891891892,Precision:0.6894702702702702,Recall:0.3541675675675675\n",
      "Epoch 215,loss:0.6731120216108002\n",
      "Validation Loss: 0.678422072449246,AUC: 0.5872081081081081,ACC:0.630908108108108,F1:0.45696216216216223,Precision:0.6833783783783783,Recall:0.3613864864864865\n",
      "Epoch 220,loss:0.6730024962298637\n",
      "Validation Loss: 0.6783630042462736,AUC: 0.5868243243243242,ACC:0.6311216216216217,F1:0.4497621621621621,Precision:0.6872972972972973,Recall:0.3505810810810811\n",
      "Epoch 225,loss:0.6728944335363608\n",
      "Validation Loss: 0.6783057757326074,AUC: 0.5866108108108108,ACC:0.6317540540540539,F1:0.4510216216216216,Precision:0.6894189189189189,Recall:0.3505027027027026\n",
      "Epoch 230,loss:0.672790551080113\n",
      "Validation Loss: 0.6782770237407169,AUC: 0.5867432432432433,ACC:0.6311216216216216,F1:0.45343513513513506,Precision:0.6861945945945946,Recall:0.3540891891891891\n",
      "Epoch 235,loss:0.6726888950947112\n",
      "Validation Loss: 0.6782135737908853,AUC: 0.5871486486486487,ACC:0.630908108108108,F1:0.45463243243243245,Precision:0.6845135135135134,Recall:0.3567918918918919\n",
      "Epoch 240,loss:0.6725847794946316\n",
      "Validation Loss: 0.6781845866022883,AUC: 0.587445945945946,ACC:0.6302756756756756,F1:0.4588027027027027,Precision:0.6795513513513514,Recall:0.36197297297297293\n",
      "Epoch 245,loss:0.6724747456280531\n",
      "Validation Loss: 0.6781567753972234,AUC: 0.5876162162162163,ACC:0.6300675675675675,F1:0.46010270270270265,Precision:0.6772459459459458,Recall:0.36335945945945947\n",
      "Epoch 250,loss:0.6723702154328338\n",
      "Validation Loss: 0.6781254185212625,AUC: 0.587181081081081,ACC:0.6298540540540541,F1:0.45681351351351346,Precision:0.6793675675675674,Recall:0.36001081081081077\n",
      "Epoch 255,loss:0.672267737114324\n",
      "Validation Loss: 0.6781253009229093,AUC: 0.5868351351351352,ACC:0.6290081081081081,F1:0.4545432432432433,Precision:0.6773864864864865,Recall:0.3586135135135135\n",
      "Epoch 260,loss:0.672155325919126\n",
      "Validation Loss: 0.6781217713613767,AUC: 0.586945945945946,ACC:0.6294324324324325,F1:0.4584702702702704,Precision:0.6753108108108109,Recall:0.3624783783783784\n",
      "Epoch 265,loss:0.6720459081430351\n",
      "Validation Loss: 0.6781176135346696,AUC: 0.5868810810810811,ACC:0.6296432432432433,F1:0.45988378378378386,Precision:0.6756324324324324,Recall:0.36437027027027025\n",
      "Epoch 270,loss:0.6719398013258402\n",
      "Validation Loss: 0.6781004925031919,AUC: 0.5871486486486486,ACC:0.629854054054054,F1:0.45933783783783794,Precision:0.6767972972972972,Recall:0.3635864864864865\n",
      "Epoch 275,loss:0.6718323046127251\n",
      "Validation Loss: 0.678098560990514,AUC: 0.5878081081081081,ACC:0.6296432432432433,F1:0.46171891891891903,Precision:0.6751945945945945,Recall:0.3666594594594595\n",
      "Epoch 280,loss:0.6717303442744027\n",
      "Validation Loss: 0.6781010160575042,AUC: 0.587945945945946,ACC:0.6294324324324325,F1:0.45915675675675677,Precision:0.6743378378378377,Recall:0.36351891891891897\n",
      "早停策略触发，停止训练在第 279 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 17:11:42.621797 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 17:11:42.635330 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 17:11:42.648460 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 17:11:42.661654 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 17:11:42.674815 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 17:11:42.688292 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 17:11:42.701419 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 17:11:42.714693 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 17:11:42.727784 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 17:11:42.740685 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 17:11:42.753748 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 17:11:42.766876 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 17:11:42.780025 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 17:11:42.793107 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 17:11:42.806163 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 17:11:42.819230 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 17:11:42.832783 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 17:11:42.846009 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 17:11:42.858983 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 17:11:42.872101 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 17:11:42.885193 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 17:11:42.898275 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 17:11:42.911540 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 17:11:42.924616 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 17:11:42.937653 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 17:11:42.951314 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 17:11:42.964324 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 17:11:42.977748 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 17:11:42.991036 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 17:11:43.004138 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 17:11:43.017146 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 17:11:43.030717 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 17:11:43.043992 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 17:11:43.057579 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 17:11:43.070700 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 17:11:43.084248 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 17:11:43.097447 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 17:11:43.110620 -------------\n",
      "Test Loss: 0.6777922527210133,AUC: 0.576427027027027,ACC:0.6224648648648649,F1:0.4311972972972973,Precision:0.6864540540540541,Recall:0.33196756756756757\n",
      "i=:5\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.690804794298864\n",
      "Validation Loss: 0.6895272135734558,AUC: 0.5662162162162161,ACC:0.605572972972973,F1:0.4476675675675677,Precision:0.6113837837837838,Recall:0.38358108108108113\n",
      "Epoch 10,loss:0.689617038300607\n",
      "Validation Loss: 0.688620514160878,AUC: 0.5687216216216215,ACC:0.6121216216216216,F1:0.44914864864864856,Precision:0.6376486486486487,Recall:0.36905945945945956\n",
      "Epoch 15,loss:0.6884323886010499\n",
      "Validation Loss: 0.6876831409093496,AUC: 0.5701108108108107,ACC:0.6127594594594595,F1:0.45651621621621635,Precision:0.6310513513513515,Recall:0.38160000000000005\n",
      "Epoch 20,loss:0.6872080780763542\n",
      "Validation Loss: 0.6867793943430927,AUC: 0.5714081081081079,ACC:0.6146540540540542,F1:0.446235135135135,Precision:0.6524594594594595,Recall:0.36408108108108106\n",
      "Epoch 25,loss:0.6860424733794896\n",
      "Validation Loss: 0.6859602992599075,AUC: 0.5734243243243242,ACC:0.6146513513513515,F1:0.44995405405405403,Precision:0.6500108108108108,Recall:0.37110000000000004\n",
      "Epoch 30,loss:0.684940298046686\n",
      "Validation Loss: 0.6852784994486216,AUC: 0.5754594594594595,ACC:0.6146486486486484,F1:0.4659567567567568,Precision:0.6344945945945948,Recall:0.3917297297297298\n",
      "Epoch 35,loss:0.6839165302504481\n",
      "Validation Loss: 0.6846933654836707,AUC: 0.5755027027027029,ACC:0.6169729729729729,F1:0.45880810810810807,Precision:0.6549621621621622,Recall:0.3829972972972973\n",
      "Epoch 40,loss:0.6830007365319581\n",
      "Validation Loss: 0.6842406263222566,AUC: 0.5768891891891893,ACC:0.6186648648648647,F1:0.45750270270270277,Precision:0.656954054054054,Recall:0.3756324324324325\n",
      "Epoch 45,loss:0.6821897256690844\n",
      "Validation Loss: 0.6838544558834385,AUC: 0.5777108108108109,ACC:0.6182486486486486,F1:0.45650270270270277,Precision:0.6601756756756758,Recall:0.3765621621621622\n",
      "Epoch 50,loss:0.6814681987846847\n",
      "Validation Loss: 0.6835242735373007,AUC: 0.577945945945946,ACC:0.6186702702702703,F1:0.4639270270270271,Precision:0.6482648648648649,Recall:0.38587027027027027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55,loss:0.6808421305850544\n",
      "Validation Loss: 0.6832771478472529,AUC: 0.5779837837837838,ACC:0.6201486486486487,F1:0.45890000000000003,Precision:0.6502567567567566,Recall:0.3801972972972974\n",
      "Epoch 60,loss:0.6802909579952207\n",
      "Validation Loss: 0.68305383985107,AUC: 0.5786756756756756,ACC:0.6212027027027028,F1:0.4610864864864864,Precision:0.6491162162162163,Recall:0.3813891891891891\n",
      "Epoch 65,loss:0.6798016734882794\n",
      "Validation Loss: 0.6828291851121027,AUC: 0.5789189189189188,ACC:0.6212000000000001,F1:0.4635567567567568,Precision:0.6479243243243243,Recall:0.3842405405405406\n",
      "Epoch 70,loss:0.6793625998286019\n",
      "Validation Loss: 0.6826299638361544,AUC: 0.5807162162162163,ACC:0.6235216216216217,F1:0.45847027027027026,Precision:0.6546243243243244,Recall:0.37415945945945944\n",
      "Epoch 75,loss:0.678971040037881\n",
      "Validation Loss: 0.6824868514731124,AUC: 0.5820351351351353,ACC:0.6239432432432434,F1:0.45914594594594593,Precision:0.6546594594594596,Recall:0.37430810810810805\n",
      "Epoch 80,loss:0.6786205283308451\n",
      "Validation Loss: 0.6823669156512698,AUC: 0.5836054054054055,ACC:0.6239432432432434,F1:0.4553864864864865,Precision:0.6581108108108109,Recall:0.3682027027027027\n",
      "Epoch 85,loss:0.6782983314674512\n",
      "Validation Loss: 0.6822511328233255,AUC: 0.5847054054054053,ACC:0.623945945945946,F1:0.4560081081081081,Precision:0.6585216216216218,Recall:0.3691675675675675\n",
      "Epoch 90,loss:0.677999843538335\n",
      "Validation Loss: 0.6821406966931111,AUC: 0.5852513513513512,ACC:0.6243648648648649,F1:0.4583189189189189,Precision:0.660383783783784,Recall:0.3714594594594594\n",
      "Epoch 95,loss:0.6777109846604609\n",
      "Validation Loss: 0.6820245159638895,AUC: 0.5864162162162161,ACC:0.6230945945945947,F1:0.45885945945945944,Precision:0.6572351351351353,Recall:0.37308378378378376\n",
      "Epoch 100,loss:0.6774424493840311\n",
      "Validation Loss: 0.681908905506134,AUC: 0.5870054054054055,ACC:0.6226729729729731,F1:0.46010000000000006,Precision:0.6546729729729732,Recall:0.3744162162162161\n",
      "Epoch 105,loss:0.6771820482954515\n",
      "Validation Loss: 0.6817808779510292,AUC: 0.587337837837838,ACC:0.6237270270270271,F1:0.4530567567567568,Precision:0.6643324324324327,Recall:0.362327027027027\n",
      "Epoch 110,loss:0.6769305594199526\n",
      "Validation Loss: 0.6816848403698689,AUC: 0.5878972972972976,ACC:0.6233054054054055,F1:0.45287297297297296,Precision:0.6632000000000001,Recall:0.3623513513513513\n",
      "Epoch 115,loss:0.6766942011571564\n",
      "Validation Loss: 0.6815821705637751,AUC: 0.5870864864864863,ACC:0.6230945945945946,F1:0.4515945945945946,Precision:0.6644351351351353,Recall:0.3610135135135136\n",
      "Epoch 120,loss:0.6764655303111119\n",
      "Validation Loss: 0.6814621735263515,AUC: 0.5867756756756757,ACC:0.6218324324324325,F1:0.4494675675675675,Precision:0.6679189189189191,Recall:0.36278918918918923\n",
      "Epoch 125,loss:0.6762365988925495\n",
      "Validation Loss: 0.6813398825155722,AUC: 0.5868756756756759,ACC:0.6245756756756757,F1:0.44948648648648637,Precision:0.6678783783783785,Recall:0.3598756756756757\n",
      "Epoch 130,loss:0.6760235159798006\n",
      "Validation Loss: 0.6812377700934539,AUC: 0.5869783783783784,ACC:0.6233108108108109,F1:0.45377837837837837,Precision:0.6641027027027029,Recall:0.36739729729729725\n",
      "Epoch 135,loss:0.6758169943252496\n",
      "Validation Loss: 0.6811380176930815,AUC: 0.5874054054054054,ACC:0.6262648648648648,F1:0.4511486486486486,Precision:0.6688864864864866,Recall:0.356681081081081\n",
      "Epoch 140,loss:0.6756152362950081\n",
      "Validation Loss: 0.6810433059125334,AUC: 0.5873216216216217,ACC:0.6268972972972973,F1:0.45242972972972967,Precision:0.6698729729729731,Recall:0.3582081081081081\n",
      "Epoch 145,loss:0.6754160238578256\n",
      "Validation Loss: 0.6809856827194626,AUC: 0.5875783783783785,ACC:0.6264756756756756,F1:0.45276216216216214,Precision:0.6685540540540542,Recall:0.35929999999999995\n",
      "Epoch 150,loss:0.6752264615708747\n",
      "Validation Loss: 0.6808933325715967,AUC: 0.587464864864865,ACC:0.6264756756756756,F1:0.44972972972972974,Precision:0.6729810810810811,Recall:0.3549756756756756\n",
      "Epoch 155,loss:0.6750443688536112\n",
      "Validation Loss: 0.6808136508271501,AUC: 0.5869405405405406,ACC:0.6271081081081081,F1:0.4480054054054054,Precision:0.6769135135135134,Recall:0.3516594594594594\n",
      "Epoch 160,loss:0.6748640632207414\n",
      "Validation Loss: 0.6807402726766225,AUC: 0.5866675675675677,ACC:0.6268945945945945,F1:0.4512756756756756,Precision:0.6735297297297296,Recall:0.35515405405405404\n",
      "Epoch 165,loss:0.6746851316595499\n",
      "Validation Loss: 0.6806673778069986,AUC: 0.5857216216216216,ACC:0.6266837837837838,F1:0.4516108108108108,Precision:0.6725351351351351,Recall:0.3560864864864865\n",
      "Epoch 170,loss:0.6745106414356062\n",
      "Validation Loss: 0.6806056048419025,AUC: 0.5853270270270271,ACC:0.6271081081081081,F1:0.4508216216216216,Precision:0.6752810810810811,Recall:0.35485675675675676\n",
      "Epoch 175,loss:0.6743377199215171\n",
      "Validation Loss: 0.6805232859946586,AUC: 0.5854648648648647,ACC:0.6279513513513513,F1:0.4475648648648649,Precision:0.6813459459459459,Recall:0.3494216216216216\n",
      "Epoch 180,loss:0.6741640420086616\n",
      "Validation Loss: 0.6804414649267454,AUC: 0.5858999999999999,ACC:0.6283702702702701,F1:0.4454135135135136,Precision:0.6813972972972971,Recall:0.3472486486486487\n",
      "Epoch 185,loss:0.6739909248014467\n",
      "Validation Loss: 0.6804032680150625,AUC: 0.5860513513513513,ACC:0.6277378378378378,F1:0.4465891891891892,Precision:0.6787243243243243,Recall:0.3499513513513513\n",
      "Epoch 190,loss:0.6738306537138677\n",
      "Validation Loss: 0.6803461844856674,AUC: 0.585864864864865,ACC:0.6273189189189189,F1:0.44915135135135137,Precision:0.6751999999999999,Recall:0.35357837837837836\n",
      "Epoch 195,loss:0.6736717667199869\n",
      "Validation Loss: 0.6803060689487973,AUC: 0.5857216216216217,ACC:0.6279513513513513,F1:0.45216756756756754,Precision:0.6714243243243243,Recall:0.35623783783783786\n",
      "Epoch 200,loss:0.6735230056585464\n",
      "Validation Loss: 0.6802572591884716,AUC: 0.5858216216216217,ACC:0.6273189189189189,F1:0.45393513513513517,Precision:0.6637216216216217,Recall:0.35850810810810807\n",
      "Epoch 205,loss:0.6733695949073386\n",
      "Validation Loss: 0.6802047346089337,AUC: 0.586443243243243,ACC:0.6279513513513513,F1:0.45280000000000004,Precision:0.6687405405405408,Recall:0.3569891891891892\n",
      "Epoch 210,loss:0.6732295656626204\n",
      "Validation Loss: 0.680164014970934,AUC: 0.5858756756756758,ACC:0.628372972972973,F1:0.4530756756756757,Precision:0.6700486486486488,Recall:0.357254054054054\n",
      "Epoch 215,loss:0.6730979913103897\n",
      "Validation Loss: 0.6801242328978874,AUC: 0.5861108108108107,ACC:0.6287945945945945,F1:0.45451621621621624,Precision:0.670564864864865,Recall:0.3582486486486486\n",
      "Epoch 220,loss:0.6729670868510693\n",
      "Validation Loss: 0.680053715770309,AUC: 0.5858567567567567,ACC:0.6290027027027026,F1:0.45610540540540545,Precision:0.6711783783783787,Recall:0.35889459459459455\n",
      "Epoch 225,loss:0.6728496345798526\n",
      "Validation Loss: 0.6799841555389198,AUC: 0.5864189189189188,ACC:0.6285837837837837,F1:0.45762972972972976,Precision:0.6696891891891894,Recall:0.3610027027027027\n",
      "Epoch 230,loss:0.672734495285338\n",
      "Validation Loss: 0.6799089570303221,AUC: 0.5868432432432431,ACC:0.629008108108108,F1:0.45855135135135144,Precision:0.6705081081081083,Recall:0.3619972972972973\n",
      "Epoch 235,loss:0.6726109290544966\n",
      "Validation Loss: 0.6798294863185367,AUC: 0.5868216216216217,ACC:0.6294297297297297,F1:0.45379729729729745,Precision:0.6743324324324327,Recall:0.35410540540540536\n",
      "Epoch 240,loss:0.6724983422102127\n",
      "Validation Loss: 0.6797873265034443,AUC: 0.5875486486486488,ACC:0.6292189189189189,F1:0.4515729729729731,Precision:0.6758216216216218,Recall:0.3519513513513513\n",
      "Epoch 245,loss:0.672384086435875\n",
      "Validation Loss: 0.6797375630688023,AUC: 0.588127027027027,ACC:0.6298540540540541,F1:0.4538783783783784,Precision:0.6754756756756759,Recall:0.35437027027027024\n",
      "Epoch 250,loss:0.6722646397826946\n",
      "Validation Loss: 0.6797038928882496,AUC: 0.5884918918918919,ACC:0.6304918918918919,F1:0.45300810810810804,Precision:0.6787783783783786,Recall:0.3526324324324325\n",
      "Epoch 255,loss:0.6721398028652225\n",
      "Validation Loss: 0.6796524460251266,AUC: 0.5888243243243242,ACC:0.630281081081081,F1:0.4529189189189189,Precision:0.6790567567567569,Recall:0.3534027027027027\n",
      "Epoch 260,loss:0.6720223036487546\n",
      "Validation Loss: 0.6796376076904503,AUC: 0.5887324324324323,ACC:0.6309135135135135,F1:0.4544729729729729,Precision:0.6795054054054056,Recall:0.3550567567567568\n",
      "Epoch 265,loss:0.6719078353020997\n",
      "Validation Loss: 0.6796115427403837,AUC: 0.5887432432432433,ACC:0.6315459459459459,F1:0.45306486486486486,Precision:0.6835405405405407,Recall:0.3520081081081081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270,loss:0.6717986031971147\n",
      "Validation Loss: 0.6796020623799917,AUC: 0.5883756756756757,ACC:0.6311243243243243,F1:0.45391891891891895,Precision:0.679964864864865,Recall:0.3534837837837838\n",
      "Epoch 275,loss:0.671683615815323\n",
      "Validation Loss: 0.6795988823916461,AUC: 0.5886675675675678,ACC:0.6309135135135134,F1:0.45490270270270267,Precision:0.6794297297297299,Recall:0.35469459459459457\n",
      "Epoch 280,loss:0.6715772299639946\n",
      "Validation Loss: 0.6795887061067529,AUC: 0.5887270270270272,ACC:0.6309135135135133,F1:0.4534270270270271,Precision:0.6810189189189192,Recall:0.35238918918918916\n",
      "Epoch 285,loss:0.6714656400469552\n",
      "Validation Loss: 0.6795822800816717,AUC: 0.5888108108108107,ACC:0.6309135135135133,F1:0.4534270270270271,Precision:0.6810189189189192,Recall:0.35238918918918916\n",
      "Epoch 290,loss:0.6713555049052281\n",
      "Validation Loss: 0.6795795914289113,AUC: 0.5889540540540541,ACC:0.6307027027027026,F1:0.45306486486486486,Precision:0.680783783783784,Recall:0.3519405405405405\n",
      "Epoch 295,loss:0.6712584706534327\n",
      "Validation Loss: 0.67956838736663,AUC: 0.5888189189189191,ACC:0.6311243243243242,F1:0.4529216216216216,Precision:0.6838594594594597,Recall:0.35136756756756765\n",
      "Epoch 300,loss:0.6711485000838221\n",
      "Validation Loss: 0.6795664896836152,AUC: 0.5888513513513514,ACC:0.6311243243243243,F1:0.45279729729729734,Precision:0.6828783783783786,Recall:0.3513378378378379\n",
      "Epoch 305,loss:0.6710449683982714\n",
      "Validation Loss: 0.6795661336666828,AUC: 0.5893378378378377,ACC:0.6317567567567567,F1:0.4486243243243243,Precision:0.6887594594594597,Recall:0.3456918918918919\n",
      "Epoch 310,loss:0.670945857478454\n",
      "Validation Loss: 0.6795722101185773,AUC: 0.5899162162162161,ACC:0.6309108108108108,F1:0.4439918918918918,Precision:0.691737837837838,Recall:0.3395486486486486\n",
      "早停策略触发，停止训练在第 309 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 17:43:08.334172 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 17:43:08.348080 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 17:43:08.360933 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 17:43:08.373847 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 17:43:08.386778 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 17:43:08.399684 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 17:43:08.412620 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 17:43:08.425857 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 17:43:08.438771 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 17:43:08.451669 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 17:43:08.464603 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 17:43:08.477672 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 17:43:08.490669 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 17:43:08.503585 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 17:43:08.516412 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 17:43:08.529290 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 17:43:08.543386 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 17:43:08.556395 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 17:43:08.569293 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 17:43:08.582169 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 17:43:08.595059 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 17:43:08.607997 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 17:43:08.621067 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 17:43:08.634041 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 17:43:08.646915 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 17:43:08.659807 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 17:43:08.672664 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 17:43:08.685684 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 17:43:08.698596 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 17:43:08.711633 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 17:43:08.724522 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 17:43:08.737370 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 17:43:08.751044 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 17:43:08.763981 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 17:43:08.776947 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 17:43:08.789904 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 17:43:08.802782 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 17:43:08.815676 -------------\n",
      "Test Loss: 0.6771669436145473,AUC: 0.5814675675675677,ACC:0.6237270270270269,F1:0.42998918918918927,Precision:0.7003405405405406,Recall:0.32715945945945946\n",
      "结果已输出\n",
      "||--------当前时间窗 1201_1231 结束时间： 2024-03-19 17:43:08.831707 -------------\n",
      "i=:1\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6931909011528555\n",
      "Validation Loss: 0.6929857650318662,AUC: 0.5472351351351351,ACC:0.6021972972972973,F1:0.34651081081081064,Precision:0.5757891891891893,Recall:0.2790621621621621\n",
      "Epoch 10,loss:0.6931277545152512\n",
      "Validation Loss: 0.6929731079050012,AUC: 0.5434513513513511,ACC:0.601772972972973,F1:0.3356756756756756,Precision:0.5842216216216218,Recall:0.26522702702702705\n",
      "Epoch 15,loss:0.6930849082702029\n",
      "Validation Loss: 0.692932040304751,AUC: 0.5439810810810811,ACC:0.6002972972972973,F1:0.3424081081081081,Precision:0.5798216216216217,Recall:0.27294054054054057\n",
      "Epoch 20,loss:0.6930280327796936\n",
      "Validation Loss: 0.6928559171186911,AUC: 0.5432162162162161,ACC:0.6017756756756757,F1:0.3420297297297298,Precision:0.5741054054054056,Recall:0.27162702702702707\n",
      "Epoch 25,loss:0.6929365449247107\n",
      "Validation Loss: 0.6927306652069092,AUC: 0.5477162162162164,ACC:0.6000891891891891,F1:0.35251621621621626,Precision:0.5708027027027028,Recall:0.28815675675675684\n",
      "Epoch 30,loss:0.6927915611098298\n",
      "Validation Loss: 0.6925720089190716,AUC: 0.5505135135135136,ACC:0.5939567567567567,F1:0.3748189189189189,Precision:0.5509108108108108,Recall:0.3221486486486486\n",
      "Epoch 35,loss:0.6926025347372072\n",
      "Validation Loss: 0.6923973173708529,AUC: 0.5483405405405406,ACC:0.5952216216216215,F1:0.3964216216216216,Precision:0.5471675675675673,Recall:0.35234864864864857\n",
      "Epoch 40,loss:0.692389002943461\n",
      "Validation Loss: 0.6921988935083956,AUC: 0.5480945945945946,ACC:0.5916378378378376,F1:0.3839567567567567,Precision:0.5590270270270271,Recall:0.3449756756756758\n",
      "Epoch 45,loss:0.6921591948618931\n",
      "Validation Loss: 0.6919710201186102,AUC: 0.5475783783783784,ACC:0.5958621621621621,F1:0.3675648648648648,Precision:0.5892945945945944,Recall:0.32135675675675673\n",
      "Epoch 50,loss:0.6918858996534769\n",
      "Validation Loss: 0.6916709542274475,AUC: 0.5481243243243243,ACC:0.5967054054054054,F1:0.37385135135135134,Precision:0.5845000000000001,Recall:0.3273864864864865\n",
      "Epoch 55,loss:0.6915516605419395\n",
      "Validation Loss: 0.6913285529291308,AUC: 0.5461000000000001,ACC:0.5962756756756756,F1:0.37419459459459464,Precision:0.579872972972973,Recall:0.32930000000000004\n",
      "Epoch 60,loss:0.6911792850072405\n",
      "Validation Loss: 0.6909404606432528,AUC: 0.5496324324324322,ACC:0.5983891891891892,F1:0.38312702702702706,Precision:0.5693594594594596,Recall:0.333427027027027\n",
      "Epoch 65,loss:0.6907938048902866\n",
      "Validation Loss: 0.6905443797240386,AUC: 0.5499891891891892,ACC:0.5998675675675674,F1:0.37963243243243244,Precision:0.5699837837837839,Recall:0.32637297297297285\n",
      "Epoch 70,loss:0.6904424175751948\n",
      "Validation Loss: 0.6901726899920283,AUC: 0.5508027027027028,ACC:0.6000783783783782,F1:0.3827351351351352,Precision:0.5618783783783784,Recall:0.328327027027027\n",
      "Epoch 75,loss:0.690137663246256\n",
      "Validation Loss: 0.6898154181403082,AUC: 0.5515513513513512,ACC:0.5998729729729728,F1:0.3822432432432433,Precision:0.5663621621621623,Recall:0.32885945945945944\n",
      "Epoch 80,loss:0.6898782253265381\n",
      "Validation Loss: 0.6895661112424489,AUC: 0.551818918918919,ACC:0.5992351351351349,F1:0.37131621621621624,Precision:0.5779189189189189,Recall:0.3214135135135135\n",
      "Epoch 85,loss:0.6896574291507754\n",
      "Validation Loss: 0.689357610973152,AUC: 0.5505594594594594,ACC:0.6047270270270269,F1:0.36324864864864864,Precision:0.570391891891892,Recall:0.3024108108108109\n",
      "Epoch 90,loss:0.6894672829492957\n",
      "Validation Loss: 0.6891869129361333,AUC: 0.548945945945946,ACC:0.604727027027027,F1:0.3643432432432432,Precision:0.5878351351351352,Recall:0.303327027027027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95,loss:0.6893017049384328\n",
      "Validation Loss: 0.6890394864855586,AUC: 0.5476756756756758,ACC:0.6049351351351351,F1:0.3624351351351351,Precision:0.5807243243243243,Recall:0.2998108108108108\n",
      "Epoch 100,loss:0.689155186699555\n",
      "Validation Loss: 0.6889091778445888,AUC: 0.5471702702702704,ACC:0.6059945945945945,F1:0.3669648648648648,Precision:0.5692837837837837,Recall:0.30362972972972974\n",
      "Epoch 105,loss:0.6890225610901825\n",
      "Validation Loss: 0.6887931952605376,AUC: 0.5477648648648648,ACC:0.605364864864865,F1:0.3726891891891891,Precision:0.5629702702702702,Recall:0.3153081081081081\n",
      "Epoch 110,loss:0.6889127587850115\n",
      "Validation Loss: 0.6886768614923632,AUC: 0.547827027027027,ACC:0.6068378378378378,F1:0.37026216216216223,Precision:0.5794594594594595,Recall:0.31125945945945954\n",
      "Epoch 115,loss:0.6887483971308818\n",
      "Validation Loss: 0.6887290606627593,AUC: 0.5496459459459462,ACC:0.6034621621621621,F1:0.37325675675675685,Precision:0.5759324324324323,Recall:0.32002702702702696\n",
      "早停策略触发，停止训练在第 114 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 17:52:52.288784 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 17:52:52.302147 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 17:52:52.314845 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 17:52:52.327512 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 17:52:52.340078 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 17:52:52.352699 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 17:52:52.365401 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 17:52:52.378206 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 17:52:52.390898 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 17:52:52.403581 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 17:52:52.416289 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 17:52:52.428847 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 17:52:52.441514 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 17:52:52.454094 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 17:52:52.466764 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 17:52:52.479274 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 17:52:52.492551 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 17:52:52.505250 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 17:52:52.517757 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 17:52:52.530334 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 17:52:52.542957 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 17:52:52.555547 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 17:52:52.568251 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 17:52:52.580800 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 17:52:52.593531 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 17:52:52.606142 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 17:52:52.618783 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 17:52:52.631377 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 17:52:52.644031 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 17:52:52.656595 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 17:52:52.669205 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 17:52:52.681793 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 17:52:52.694939 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 17:52:52.707726 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 17:52:52.720331 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 17:52:52.733021 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 17:52:52.745720 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 17:52:52.758493 -------------\n",
      "Test Loss: 0.6897914006903365,AUC: 0.5426297297297298,ACC:0.6032567567567567,F1:0.38120000000000004,Precision:0.5677270270270268,Recall:0.32888378378378375\n",
      "i=:2\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6933570836497619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6930767007776208,AUC: 0.545354054054054,ACC:0.6055729729729731,F1:0.33115945945945946,Precision:0.5579567567567567,Recall:0.2559513513513514\n",
      "Epoch 10,loss:0.6932686161150975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6931100536037136,AUC: 0.5415135135135135,ACC:0.6038891891891892,F1:0.3250729729729729,Precision:0.5465243243243242,Recall:0.24668918918918914\n",
      "早停策略触发，停止训练在第 9 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 17:54:55.215748 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 17:54:55.228712 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 17:54:55.241502 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 17:54:55.254189 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 17:54:55.267922 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 17:54:55.280455 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 17:54:55.293239 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 17:54:55.305943 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 17:54:55.318705 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 17:54:55.331473 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 17:54:55.344221 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 17:54:55.356874 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 17:54:55.369575 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 17:54:55.382362 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 17:54:55.395075 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 17:54:55.407798 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 17:54:55.421285 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 17:54:55.433895 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 17:54:55.446599 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 17:54:55.459282 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 17:54:55.472026 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 17:54:55.484726 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 17:54:55.497379 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 17:54:55.510086 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 17:54:55.522851 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 17:54:55.535488 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 17:54:55.548124 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 17:54:55.560823 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 17:54:55.574966 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 17:54:55.587782 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 17:54:55.601039 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 17:54:55.613525 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 17:54:55.626984 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 17:54:55.639659 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 17:54:55.652400 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 17:54:55.665174 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 17:54:55.677910 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 17:54:55.690683 -------------\n",
      "Test Loss: 0.6932637449857351,AUC: 0.5296702702702702,ACC:0.5926945945945946,F1:0.3151675675675676,Precision:0.49504864864864867,Recall:0.2473405405405405\n",
      "i=:3\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6933336400352748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6929562848967474,AUC: 0.5461567567567567,ACC:0.6036729729729731,F1:0.33724324324324323,Precision:0.5571594594594594,Recall:0.2766918918918919\n",
      "Epoch 10,loss:0.693206690581499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6929880171208769,AUC: 0.5458162162162161,ACC:0.6051486486486486,F1:0.3211297297297297,Precision:0.5632783783783784,Recall:0.24745945945945944\n",
      "早停策略触发，停止训练在第 9 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 17:56:58.142860 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 17:56:58.156135 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 17:56:58.168688 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 17:56:58.181215 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 17:56:58.194349 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 17:56:58.206944 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 17:56:58.219480 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 17:56:58.232061 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 17:56:58.244666 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 17:56:58.257594 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 17:56:58.270144 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 17:56:58.282753 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 17:56:58.295250 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 17:56:58.307857 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 17:56:58.320397 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 17:56:58.332947 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 17:56:58.346284 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 17:56:58.358930 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 17:56:58.371388 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 17:56:58.383948 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 17:56:58.396513 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 17:56:58.409247 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 17:56:58.421766 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 17:56:58.434255 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 17:56:58.446782 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 17:56:58.459339 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 17:56:58.471927 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 17:56:58.484473 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 17:56:58.497013 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 17:56:58.509566 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 17:56:58.522089 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 17:56:58.534617 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 17:56:58.547836 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 17:56:58.560461 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 17:56:58.572972 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 17:56:58.585499 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 17:56:58.598022 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 17:56:58.610690 -------------\n",
      "Test Loss: 0.6932429816271808,AUC: 0.5344054054054054,ACC:0.589108108108108,F1:0.3401702702702702,Precision:0.4919432432432433,Recall:0.2762513513513513\n",
      "i=:4\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6934173576599729\n",
      "Validation Loss: 0.6930244307260256,AUC: 0.5472135135135133,ACC:0.6000837837837838,F1:0.3566243243243242,Precision:0.5382729729729729,Recall:0.28717837837837845\n",
      "Epoch 10,loss:0.6932596416599983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6930339352504628,AUC: 0.5415000000000001,ACC:0.6024054054054054,F1:0.3221729729729729,Precision:0.552272972972973,Recall:0.2500216216216216\n",
      "早停策略触发，停止训练在第 9 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 17:58:56.869376 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 17:58:56.882430 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 17:58:56.895028 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 17:58:56.907619 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 17:58:56.920780 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 17:58:56.933437 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 17:58:56.945996 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 17:58:56.958638 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 17:58:56.971187 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 17:58:56.983822 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 17:58:56.996412 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 17:58:57.008992 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 17:58:57.021560 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 17:58:57.034279 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 17:58:57.046873 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 17:58:57.059452 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 17:58:57.072729 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 17:58:57.085466 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 17:58:57.097992 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 17:58:57.110570 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 17:58:57.123133 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 17:58:57.135729 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 17:58:57.148312 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 17:58:57.160925 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 17:58:57.173492 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 17:58:57.186079 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 17:58:57.198665 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 17:58:57.211204 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 17:58:57.223840 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 17:58:57.236493 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 17:58:57.249535 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 17:58:57.262094 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 17:58:57.275268 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 17:58:57.288016 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 17:58:57.300584 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 17:58:57.313220 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 17:58:57.325740 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 17:58:57.338342 -------------\n",
      "Test Loss: 0.6931796798834929,AUC: 0.5311513513513513,ACC:0.5908,F1:0.30659999999999993,Precision:0.5022243243243243,Recall:0.2448081081081081\n",
      "i=:5\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "数据划分完成\n",
      "张量生成完成\n",
      "模型搭建完成\n",
      "模型转移到GPU完成\n",
      "Epoch 5,loss:0.6933780064625022\n",
      "Validation Loss: 0.6930153353794201,AUC: 0.5487216216216216,ACC:0.6000864864864864,F1:0.3574513513513514,Precision:0.5582243243243241,Recall:0.29189189189189185\n",
      "Epoch 10,loss:0.6932602930912929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6930549950213045,AUC: 0.5439918918918919,ACC:0.6015648648648648,F1:0.3315216216216216,Precision:0.5407945945945944,Recall:0.26225945945945944\n",
      "早停策略触发，停止训练在第 9 个epoch.\n",
      "模型训练完成\n",
      "||--------训练结束时间： 2024-03-19 18:01:00.194861 -------------\n",
      "||--测试：---------- 1 个batch运行时间： 2024-03-19 18:01:00.207521 -------------\n",
      "||--测试：---------- 2 个batch运行时间： 2024-03-19 18:01:00.220308 -------------\n",
      "||--测试：---------- 3 个batch运行时间： 2024-03-19 18:01:00.233095 -------------\n",
      "||--测试：---------- 4 个batch运行时间： 2024-03-19 18:01:00.246679 -------------\n",
      "||--测试：---------- 5 个batch运行时间： 2024-03-19 18:01:00.259285 -------------\n",
      "||--测试：---------- 6 个batch运行时间： 2024-03-19 18:01:00.272074 -------------\n",
      "||--测试：---------- 7 个batch运行时间： 2024-03-19 18:01:00.284811 -------------\n",
      "||--测试：---------- 8 个batch运行时间： 2024-03-19 18:01:00.297661 -------------\n",
      "||--测试：---------- 9 个batch运行时间： 2024-03-19 18:01:00.310455 -------------\n",
      "||--测试：---------- 10 个batch运行时间： 2024-03-19 18:01:00.323463 -------------\n",
      "||--测试：---------- 11 个batch运行时间： 2024-03-19 18:01:00.336269 -------------\n",
      "||--测试：---------- 12 个batch运行时间： 2024-03-19 18:01:00.349031 -------------\n",
      "||--测试：---------- 13 个batch运行时间： 2024-03-19 18:01:00.361807 -------------\n",
      "||--测试：---------- 14 个batch运行时间： 2024-03-19 18:01:00.374582 -------------\n",
      "||--测试：---------- 15 个batch运行时间： 2024-03-19 18:01:00.387347 -------------\n",
      "||--测试：---------- 16 个batch运行时间： 2024-03-19 18:01:00.400979 -------------\n",
      "||--测试：---------- 17 个batch运行时间： 2024-03-19 18:01:00.413868 -------------\n",
      "||--测试：---------- 18 个batch运行时间： 2024-03-19 18:01:00.426731 -------------\n",
      "||--测试：---------- 19 个batch运行时间： 2024-03-19 18:01:00.439532 -------------\n",
      "||--测试：---------- 20 个batch运行时间： 2024-03-19 18:01:00.452333 -------------\n",
      "||--测试：---------- 21 个batch运行时间： 2024-03-19 18:01:00.465154 -------------\n",
      "||--测试：---------- 22 个batch运行时间： 2024-03-19 18:01:00.477922 -------------\n",
      "||--测试：---------- 23 个batch运行时间： 2024-03-19 18:01:00.490676 -------------\n",
      "||--测试：---------- 24 个batch运行时间： 2024-03-19 18:01:00.503448 -------------\n",
      "||--测试：---------- 25 个batch运行时间： 2024-03-19 18:01:00.516217 -------------\n",
      "||--测试：---------- 26 个batch运行时间： 2024-03-19 18:01:00.529149 -------------\n",
      "||--测试：---------- 27 个batch运行时间： 2024-03-19 18:01:00.541901 -------------\n",
      "||--测试：---------- 28 个batch运行时间： 2024-03-19 18:01:00.554683 -------------\n",
      "||--测试：---------- 29 个batch运行时间： 2024-03-19 18:01:00.567456 -------------\n",
      "||--测试：---------- 30 个batch运行时间： 2024-03-19 18:01:00.580825 -------------\n",
      "||--测试：---------- 31 个batch运行时间： 2024-03-19 18:01:00.593323 -------------\n",
      "||--测试：---------- 32 个batch运行时间： 2024-03-19 18:01:00.607106 -------------\n",
      "||--测试：---------- 33 个batch运行时间： 2024-03-19 18:01:00.619807 -------------\n",
      "||--测试：---------- 34 个batch运行时间： 2024-03-19 18:01:00.632680 -------------\n",
      "||--测试：---------- 35 个batch运行时间： 2024-03-19 18:01:00.645507 -------------\n",
      "||--测试：---------- 36 个batch运行时间： 2024-03-19 18:01:00.658313 -------------\n",
      "||--测试：---------- 37 个batch运行时间： 2024-03-19 18:01:00.671206 -------------\n",
      "Test Loss: 0.6932471152898427,AUC: 0.5324675675675675,ACC:0.5943864864864865,F1:0.31855945945945946,Precision:0.4985297297297296,Recall:0.25575945945945944\n",
      "结果已输出\n",
      "||--------当前时间窗 1215_0115 结束时间： 2024-03-19 18:01:00.686325 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 模型运行\n",
    "for data_time_windows in data_time_windows_list :\n",
    "    \n",
    "    path = './Dataset/' + data_time_windows + '_user_pay_pred_feature_deal.csv'\n",
    "    dataset_spilt_path = './Dataset/' + data_time_windows + '_user_pay_pred_feature_spilt_BiLSTM.csv'\n",
    "#     output_weight_result_path = './Dataset/' + data_time_windows + '_user_pay_pred_result_weight.csv'\n",
    "    data_feature_continue_discrete_namelist_path = './Dataset/maoer_timewindows_continue_discrete_feature_column.csv'    # 连续与离散划分表\n",
    "    # # 获取时间窗内连续与离散特征名的列表\n",
    "    user_history_pay_QOE_continue_column, user_history_pay_CHONGHE_continue_column, \\\n",
    "    user_history_pay_FUFEI_continue_column, user_history_pay_QOE_discrete_column,\\\n",
    "    user_history_pay_CHONGHE_discrete_column, user_history_pay_FUFEI_discrete_column = get_continue_discrete_feature_namelist(data_time_windows, data_feature_continue_discrete_namelist_path)\n",
    "    user_feature_continue_column = []\n",
    "    user_feature_discrete_column = []\n",
    "\n",
    "    # total continue feature\n",
    "    total_continue_feature = user_history_pay_CHONGHE_continue_column+user_history_pay_FUFEI_continue_column\n",
    "    total_discrete_feature = user_history_pay_CHONGHE_discrete_column+user_history_pay_FUFEI_discrete_column\n",
    "    total_discrete_feature_add_D = user_feature_discrete_column+user_history_pay_QOE_discrete_column+user_history_pay_CHONGHE_discrete_column+user_history_pay_FUFEI_discrete_column\n",
    "    total_discrete_feature_add_D.append('user_in_drama_is_pay_for_drama_in_next_time')\n",
    "    D = 'user_in_drama_is_pay_for_drama_in_next_time'\n",
    "    tensor_dict_idx = ['pay_QOE_continue','pay_QOE_discrete','pay_CHONGHE_continue','pay_CHONGHE_discrete','pay_FUFEI_continue','pay_FUFEI_discrete','target_QOE_continue','target_QOE_discrete','target_CHONGHE_continue','target_CHONGHE_discrete','target_FUFEI_continue','target_FUFEI_discrete']\n",
    "    # print(len(user_history_pay_QOE_continue_column),len(user_history_pay_CHONGHE_continue_column),len(user_history_pay_FUFEI_continue_column))\n",
    "    # 形成对应需要的特征名称列表\n",
    "    feature_column_dict = {\n",
    "        'total_continue_feature': total_continue_feature,\n",
    "        'total_discrete_feature': total_discrete_feature,\n",
    "        'D':D\n",
    "    }\n",
    "    # 创建一个空的DataFrame来存储结果\n",
    "    test_auc_df = pd.DataFrame(columns=['时间','model','运行位置','Type','dataset','train_ratio','feature_embedding','batchSize','lr','max_history_len','实验数', '测试集总损失', 'AUC','ACC','F1','Precision','Recall'])\n",
    "    test_weight_df = pd.DataFrame(columns=['时间','model','运行位置','Type','dataset','train_ratio','feature_embedding','batchSize','lr','max_history_len','实验数','se_user_pay_QOE_weight','se_user_pay_CHONGHE_weight','se_user_pay_FUFEI_weight','se_target_QOE_weight','se_target_CHONGHE_weight','se_target_FUFEI_weight',\\\n",
    "                                        'target_history_pay_attention_QOE_weight','target_history_pay_attention_CHONGHE_weight','target_history_pay_attention_FUFEI_weight'])\n",
    "    for i in range(5):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        print(f\"i=:{i+1}\")\n",
    "        n = i\n",
    "        # 数据集 train、val、test划分及总数据hash表(以user_id为key的存储对应对应行的hash表)及不同类特征数存储的字典\n",
    "        train_list, val_list, test_list, data_hash, feature_category_num_dict = data_input(data_time_windows, path, dataset_spilt_path, train_ratio, val_ratio, test_ratio, total_continue_feature)\n",
    "        # 获取训练、验证、测试集对应的数据形成的向量hash存储及label\n",
    "        train_data_tensor_hash, train_label = get_feature_to_matrix(train_list, data_hash, feature_column_dict)\n",
    "        val_data_tensor_hash, val_label = get_feature_to_matrix(val_list, data_hash, feature_column_dict)\n",
    "        test_data_tensor_hash, test_label = get_feature_to_matrix(test_list, data_hash, feature_column_dict)\n",
    "        # 输出查看结果\n",
    "        # for key1 in train_data_tensor_hash.keys():\n",
    "        #     dimensions1 = train_data_tensor_hash[key1]['pay_QOE_continue'].size()\n",
    "        #     dimensions2 = train_data_tensor_hash[key1]['pay_QOE_discrete'].size()\n",
    "        #     dimensions3 = train_data_tensor_hash[key1]['pay_CHONGHE_continue'].size()\n",
    "        #     dimensions4 = train_data_tensor_hash[key1]['target_QOE_continue'].size()\n",
    "        #     dimensions5 = train_data_tensor_hash[key1]['target_QOE_discrete'].size()\n",
    "        #     dimensions6 = train_data_tensor_hash[key1]['target_CHONGHE_continue'].size()\n",
    "        #     print(\"val_data_tensor_hash size=\", dimensions1,dimensions2,dimensions3,dimensions4,dimensions5,dimensions6)\n",
    "\n",
    "        # 生成batch再添加维度对齐张量（三个维度）这里张量输出的全是三维 (batch_size, 1 or max_history_len, feature_num)\n",
    "        train_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(train_list,train_data_tensor_hash)\n",
    "        val_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(val_list,val_data_tensor_hash)\n",
    "        test_batch_feature_tensor_dict = generate_user_feature_alignment_tensor(test_list,test_data_tensor_hash)\n",
    "        train_label_tensor = train_batch_feature_tensor_dict['label']\n",
    "        val_label_tensor = val_batch_feature_tensor_dict['label']\n",
    "        test_label_tensor = test_batch_feature_tensor_dict['label']\n",
    "        train_label_tensor = train_label_tensor.unsqueeze(-1)\n",
    "        val_label_tensor = val_label_tensor.unsqueeze(-1)\n",
    "        test_label_tensor = test_label_tensor.unsqueeze(-1)  # 在最后新增一个维度，因为TensorDataset要第一维大小相同 label变为(batch,1)\n",
    "        # mask矩阵的字典\n",
    "#         train_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(train_list,train_data_tensor_hash_history_mask, is_mask=True)\n",
    "#         val_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(val_list,val_data_tensor_hash_history_mask, is_mask=True)\n",
    "#         test_batch_feature_tensor_history_mask_dict = generate_user_feature_alignment_tensor(test_list,test_data_tensor_hash_history_mask, is_mask=True)\n",
    "        print('张量生成完成')\n",
    "        \n",
    "        # TensorDataset输入得是张量，因此由字典转为张量\n",
    "        train_batch_feature_tensor_history_discrete = train_batch_feature_tensor_dict['history_discrete']\n",
    "        train_batch_feature_tensor_history_continue = train_batch_feature_tensor_dict['history_continue']\n",
    "#         train_batch_feature_tensor_history_discrete_mask = train_batch_feature_tensor_history_mask_dict['history_discrete']\n",
    "#         train_batch_feature_tensor_history_continue_mask = train_batch_feature_tensor_history_mask_dict['history_continue']\n",
    "\n",
    "        val_batch_feature_tensor_history_discrete = val_batch_feature_tensor_dict['history_discrete']\n",
    "        val_batch_feature_tensor_history_continue = val_batch_feature_tensor_dict['history_continue']\n",
    "#         val_batch_feature_tensor_history_discrete_mask = val_batch_feature_tensor_history_mask_dict['history_discrete']\n",
    "#         val_batch_feature_tensor_history_continue_mask = val_batch_feature_tensor_history_mask_dict['history_continue']\n",
    "        \n",
    "        test_batch_feature_tensor_history_discrete = test_batch_feature_tensor_dict['history_discrete']\n",
    "        test_batch_feature_tensor_history_continue = test_batch_feature_tensor_dict['history_continue']\n",
    "#         test_batch_feature_tensor_history_discrete_mask = test_batch_feature_tensor_history_mask_dict['history_discrete']\n",
    "#         test_batch_feature_tensor_history_continue_mask = test_batch_feature_tensor_history_mask_dict['history_continue']\n",
    "#         print('val_label_tensor',val_label_tensor.shape,val_batch_feature_tensor_history_discrete.shape)\n",
    "        # 训练集\n",
    "#         print('train_dataset',train_batch_feature_tensor_history_discrete.shape,train_batch_feature_tensor_history_continue.shape,train_label_tensor.shape)\n",
    "        train_dataset = TensorDataset(train_batch_feature_tensor_history_discrete,train_batch_feature_tensor_history_continue,\n",
    "                                      train_label_tensor)\n",
    "        val_dataset = TensorDataset(val_batch_feature_tensor_history_discrete,val_batch_feature_tensor_history_continue,\n",
    "                                  val_label_tensor)\n",
    "\n",
    "        # 旧\n",
    "        # train_batch_feature_tensor = list(train_batch_feature_tensor_dict.values())\n",
    "        # train_batch_feature_tensor_history_mask = list(train_batch_feature_tensor_history_mask_dict.values())\n",
    "        # val_batch_feature_tensor = list(val_batch_feature_tensor_dict.values())\n",
    "        # val_batch_feature_tensor_history_mask = list(val_batch_feature_tensor_history_mask_dict.values())\n",
    "        # test_batch_feature_tensor = list(test_batch_feature_tensor_dict.values())\n",
    "        # test_batch_feature_tensor_history_mask = list(test_batch_feature_tensor_history_mask_dict.values())  \n",
    "        # # 训练集\n",
    "        # train_dataset = TensorDataset(*train_batch_feature_tensor, *train_batch_feature_tensor_history_mask, train_label_tensor)\n",
    "        # val_dataset = TensorDataset(*val_batch_feature_tensor, *val_batch_feature_tensor_history_mask, val_label_tensor)\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)  # 记得改回随机\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "        # 确保您的计算机上有CUDA支持的GPU\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # 创建大模型的实例\n",
    "        model = MatchingModel(feature_category_num_dict, feature_column_dict, continue_embedding_dim,\n",
    "                    discrete_embedding_dim, num_heads, feature_dim, max_history_len)\n",
    "        print('模型搭建完成')\n",
    "        model.to(device)\n",
    "        # 进一步处理 列表转移到GPU\n",
    "#         for i in range(len(model.history_embedding_layer.history_discrete_embeddings)):\n",
    "#             model.history_embedding_layer.history_discrete_embeddings[i] = \\\n",
    "#             model.history_embedding_layer.history_discrete_embeddings[i].to(device)\n",
    "#         for i in range(len(model.history_embedding_layer.history_continue_embedding)):\n",
    "#             model.history_embedding_layer.history_continue_embedding[i] = \\\n",
    "#             model.history_embedding_layer.history_continue_embedding[i].to(device)\n",
    "        model.dnn_layer = model.dnn_layer.to(device)\n",
    "        print('模型转移到GPU完成')\n",
    "        lossfunction = nn.BCELoss()\n",
    "    #     optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "#         optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9)\n",
    "        optimizer = optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "        # 训练\n",
    "        model_training(model, train_loader, val_loader, lossfunction, optimizer, 500, device)\n",
    "        print('模型训练完成')\n",
    "        print('||--------训练结束时间：',datetime.datetime.now(),'-------------')\n",
    "        # 测试\n",
    "        test_dataset = TensorDataset(test_batch_feature_tensor_history_discrete,test_batch_feature_tensor_history_continue,\n",
    "                                      test_label_tensor)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "        average_loss_test, average_auc_test,average_acc_test,average_f1_test,average_precision_test,average_recall_test = test_model(model, test_loader)\n",
    "        # 测试的每个样本结果保存到csv\n",
    "        # 将本次训练的结果添加到DataFrame中\n",
    "        test_auc_df = test_auc_df.append({'时间':datetime.datetime.now(),'model':'DNN','运行位置':'GPU','Type':'Abb_QOE','dataset':data_time_windows,'train_ratio':train_ratio,'feature_embedding':feature_dim,'batchSize':batch_size,'lr':lr,'max_history_len':max_history_len,'实验数': i + 1,'测试集总损失': average_loss_test, 'AUC': average_auc_test,'ACC': average_acc_test,'F1': average_f1_test,'Precision': average_precision_test,'Recall': average_recall_test}, ignore_index=True)\n",
    "#         weight_result  = {'时间':datetime.datetime.now(),'model':'model3.1','运行位置':'GPU','Type':'Origin','dataset':data_time_windows,'train_ratio':train_ratio,'feature_embedding':feature_dim,'batchSize':batch_size,'lr':lr,'max_history_len':max_history_len,'实验数': i + 1,\\\n",
    "#                         'se_user_pay_QOE_weight':weight_result_dict['se_user_pay_QOE_weight'],'se_user_pay_CHONGHE_weight':weight_result_dict['se_user_pay_CHONGHE_weight'],\\\n",
    "#                         'se_user_pay_FUFEI_weight':weight_result_dict['se_user_pay_FUFEI_weight'],'se_target_QOE_weight':weight_result_dict['se_target_QOE_weight'],\\\n",
    "#                         'se_target_CHONGHE_weight':weight_result_dict['se_target_CHONGHE_weight'],'se_target_FUFEI_weight':weight_result_dict['se_target_FUFEI_weight'],\\\n",
    "#                         'target_history_pay_attention_QOE_weight':weight_result_dict['target_history_pay_attention_QOE_weight'],\\\n",
    "#                         'target_history_pay_attention_CHONGHE_weight':weight_result_dict['target_history_pay_attention_CHONGHE_weight'],\\\n",
    "#                         'target_history_pay_attention_FUFEI_weight':weight_result_dict['target_history_pay_attention_FUFEI_weight']}\n",
    "#         test_weight_df = test_weight_df.append(weight_result, ignore_index=True)\n",
    "    # 将结果保存到CSV文件中\n",
    "    with open('./Dataset/maoerDL_result_maoer_pay_pred_model3_1.csv', 'a') as f:\n",
    "        test_auc_df.to_csv(f, index=False)\n",
    "#     with open('./Dataset/maoerDL_result_maoer_pay_pred_weight_model3_1.csv', 'a') as f:\n",
    "#         test_weight_df.to_csv(f, index=False)\n",
    "#     test_auc_df.to_csv('./Dataset/maoerDL_result_maoer_pay_pred_model3_1.csv', index=False)\n",
    "#     test_weight_df.to_csv('./Dataset/maoerDL_result_maoer_pay_pred_weight_model3_1.csv', index=False)\n",
    "    print('结果已输出')\n",
    "    print('||--------当前时间窗',data_time_windows,'结束时间：',datetime.datetime.now(),'-------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88d40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd96c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
