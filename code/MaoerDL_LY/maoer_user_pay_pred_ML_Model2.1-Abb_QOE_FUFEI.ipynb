{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729f7f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||--------开始时间： 2024-03-18 01:13:54.738128 -------------\n"
     ]
    }
   ],
   "source": [
    "# maoer深度学习模型对比算法 -机器学习SVM&RF\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import datetime\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, recall_score, precision_score, roc_curve, confusion_matrix\n",
    "from _collections import OrderedDict  # 导入 OrderedDict 来保持字典中键值对的顺序\n",
    "\n",
    "print('||--------开始时间：', datetime.datetime.now(), '-------------')\n",
    "data_time_windows_list = ['0101_0131', '0115_0215', '0201_0230','1101_1130', '1115_1215', '1201_1231', '1215_0115']\n",
    "data_classifier_list = ['SVM']\n",
    "\n",
    "# 参数设置\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "num_heads = 10\n",
    "feature_dim = 200\n",
    "max_history_len = 15\n",
    "num_experts = 3\n",
    "num_tasks = 2\n",
    "# 设置嵌入维度\n",
    "continue_embedding_dim = 200\n",
    "discrete_embedding_dim = 200\n",
    "lr = 0.1\n",
    "batch_size = 128\n",
    "threshold = 0.5\n",
    "\n",
    "# 获取时间窗内连续与离散特征名的列表\n",
    "def get_continue_discrete_feature_namelist(time_windows, datapath):\n",
    "    data = pd.read_csv(datapath)\n",
    "    time_windows_data = data[(data['DataSet'] == time_windows)]\n",
    "    user_history_pay_QOE_continue_column = eval([time_windows_data['QOE_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_CHONGHE_continue_column = eval([time_windows_data['CHONGHE_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_FUFEI_continue_column = eval([time_windows_data['FUFEI_continue'].values.tolist()][0][0])\n",
    "    user_history_pay_QOE_discrete_column = eval([time_windows_data['QOE_discrete'].values.tolist()][0][0])\n",
    "    user_history_pay_CHONGHE_discrete_column = eval([time_windows_data['CHONGHE_discrete'].values.tolist()][0][0])\n",
    "    user_history_pay_FUFEI_discrete_column = eval([time_windows_data['FUFEI_discrete'].values.tolist()][0][0])\n",
    "\n",
    "\n",
    "    return user_history_pay_QOE_continue_column, user_history_pay_CHONGHE_continue_column,user_history_pay_FUFEI_continue_column,\\\n",
    "            user_history_pay_QOE_discrete_column,user_history_pay_CHONGHE_discrete_column,user_history_pay_FUFEI_discrete_column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe3d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.数据处理+划分训练、验证、测试集\n",
    "\n",
    "# 划分数据集 给定输出后固定结果 输出形式定为存储user_id 形成train_dataset,val_dataset,test_dataset\n",
    "def split_data_unique(input_file, output_file, train_ratio, val_ratio, test_ratio):\n",
    "    df = pd.read_csv(input_file)\n",
    "#     data = df[df.columns[0]].unique()  # 提取第一列数据并去重\n",
    "    data = np.arange(df.shape[0])  #一个从 0 到行数减 1 的整数数组\n",
    "\n",
    "    np.random.shuffle(data)  # 随机打乱数据\n",
    "    # 划分数据\n",
    "    total_len = len(data)\n",
    "    x_end = int(total_len * train_ratio)\n",
    "    y_end = x_end + int(total_len * val_ratio)\n",
    "    train_data = data[:x_end]\n",
    "    val_data = data[x_end:y_end]\n",
    "    test_data = data[y_end:]\n",
    "    # 存储结果是去重的user_id\n",
    "    result = {\n",
    "        'Train': train_data,\n",
    "        'Val': val_data,\n",
    "        'Test': test_data\n",
    "    }   \n",
    "    # 创建每个子集的DataFrame  \n",
    "    train_df = pd.DataFrame(train_data, columns=['Train'])\n",
    "    val_df = pd.DataFrame(val_data, columns=['Val'])\n",
    "    test_df = pd.DataFrame(test_data, columns=['Test'])\n",
    "    # 将每个DataFrame转换为一列Series  \n",
    "    train_series = train_df.iloc[:, 0]\n",
    "    val_series = val_df.iloc[:, 0]\n",
    "    test_series = test_df.iloc[:, 0]\n",
    "    # 为了确保所有Series有相同的长度，我们需要找到最大长度并截断较短的Series  \n",
    "    max_len = max(len(train_series), len(val_series), len(test_series))\n",
    "    train_series = train_series.reindex(range(max_len)).fillna(value=pd.NA)\n",
    "    val_series = val_series.reindex(range(max_len)).fillna(value=pd.NA)\n",
    "    test_series = test_series.reindex(range(max_len)).fillna(value=pd.NA)\n",
    "    # 创建一个新的DataFrame，将Series作为列  \n",
    "    combined_df = pd.DataFrame({\n",
    "        'Train': train_series,\n",
    "        'Val': val_series,\n",
    "        'Test': test_series\n",
    "    })\n",
    "    # 写入CSV文件，不包含索引和列名  \n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print('已输出划分数据集结果')\n",
    "\n",
    "# 数据预处理 MachineLearning特有修改版 离散值中的空值填充\n",
    "def data_pre_deal(input_path,continue_feature_list,discrete_feature_list,label_feature):\n",
    "    df = pd.read_csv(input_path)\n",
    "    deal_data_df = [] # 待修改********\n",
    "    discrete_cols_to_fill = [col for col in df.columns if col in discrete_feature_list]\n",
    "    # 离散值 使用出现次数最多的非空值填充空值\n",
    "    most_common_values = df[discrete_cols_to_fill].mode().iloc[0]\n",
    "    df[discrete_cols_to_fill] = df[discrete_cols_to_fill].fillna(most_common_values)\n",
    "    # 连续值 均值填充\n",
    "    # new_df[continue_cols_to_fill] = new_df[continue_cols_to_fill].fillna(new_df[continue_cols_to_fill].mean())\n",
    "    # print(len(discrete_cols_to_fill)+len(continue_cols_to_fill))\n",
    "    feature_list = discrete_feature_list+continue_feature_list+label_feature\n",
    "    new_df_cols = [col for col in df.columns if col in feature_list]\n",
    "    new_df = df[new_df_cols]\n",
    "    print('数据预处理结束')\n",
    "    return new_df\n",
    "\n",
    "\n",
    "# 改过 根据 BiLSTM单独改的 根据下标获取数据\n",
    "def find_data_by_list(index_list, intput_data_df):  \n",
    "    data_list = []  \n",
    "#     print('index_list',len(index_list),intput_data_df.shape)\n",
    "    for index in index_list:  \n",
    "        # index_list必须是列表 最后result_df才能是DataFrame类型\n",
    "        index = int(index)\n",
    "        index_list = []\n",
    "        index_list.append(index)\n",
    "        data_list.append(intput_data_df.iloc[index_list])\n",
    "    result_df = pd.concat(data_list, axis=0, ignore_index=True)  \n",
    "#     print('result_df',type(result_df),result_df.shape)\n",
    "    return result_df\n",
    "\n",
    "    \n",
    "# 获取列唯一值数量表，并对离散特征的值转化为从0开始的索引\n",
    "def get_unique_feature_num_and_discrete_valueChange(datadf,discrete_feature_column_list):\n",
    "    # 获取离散特征的类别数量，并存储为字典\n",
    "    feature_category_num_dict = {}\n",
    "    for column in datadf.columns:\n",
    "        unique_values_len = datadf[column].nunique()  # 获取列的唯一值数量\n",
    "        feature_category_num_dict[column] = unique_values_len\n",
    "        if column in discrete_feature_column_list:\n",
    "            unique_values = datadf[column].unique()\n",
    "            value_mapping_dict = {value: index for index, value in enumerate(unique_values) if\n",
    "                              value != -1 and value != '' and value is not None}\n",
    "            datadf[column] = datadf[column].map(value_mapping_dict)\n",
    "    return feature_category_num_dict,datadf\n",
    "\n",
    "# 总的特征输入，生成划分后数据集及其输入   ML特有修改\n",
    "def data_input(data_time_windows, path, spilt_outpath, train_ratio, val_ratio, test_ratio, feature_column_dict):\n",
    "    dataset_path = path  \n",
    "    dataset_spilt_path = spilt_outpath  \n",
    "    if os.path.exists(dataset_spilt_path):  # 划分训练、验证、测试集\n",
    "        print(\"划分文件已存在，不再进行数据划分\")\n",
    "    else:\n",
    "        split_data_unique(dataset_path, dataset_spilt_path, train_ratio, val_ratio, test_ratio)\n",
    "    deal_data_df = data_pre_deal(dataset_path, feature_column_dict['total_continue_feature'], feature_column_dict['total_discrete_feature'],feature_column_dict['D'])  # 数据预处理\n",
    "    # 获取离散特征的类别数量，并存储为字典\n",
    "    feature_category_num_dict,deal_data_df  = get_unique_feature_num_and_discrete_valueChange(deal_data_df, feature_column_dict['total_discrete_feature'])\n",
    "    # 读取划分文件的结果\n",
    "    spilt_data_df = pd.read_csv(dataset_spilt_path)\n",
    "    # 输出每一列数据为列表\n",
    "    train_list = spilt_data_df['Train'].tolist()\n",
    "    val_list = spilt_data_df['Val'].tolist()\n",
    "    test_list = spilt_data_df['Test'].tolist()\n",
    "    train_list = [x for x in train_list if not math.isnan(x)]\n",
    "    val_list = [x for x in val_list if not math.isnan(x)]\n",
    "    test_list = [x for x in test_list if not math.isnan(x)]\n",
    "\n",
    "    train_data = find_data_by_list(train_list, deal_data_df).copy()\n",
    "    val_data = find_data_by_list(val_list, deal_data_df).copy()\n",
    "    test_data = find_data_by_list(test_list, deal_data_df).copy()\n",
    "    print(type(train_data),train_data.shape)  # 检查是否是DataFrame类型  \n",
    "    # 取label\n",
    "    train_label = train_data.iloc[:,-1]\n",
    "    val_label = val_data.iloc[:,-1]\n",
    "    test_label = test_data.iloc[:,-1]\n",
    "    # 1/2 转为 0/1\n",
    "    train_label,_ = map_labels_to_int(train_label)\n",
    "    val_label,_ = map_labels_to_int(val_label)\n",
    "    test_label,_ = map_labels_to_int(test_label)\n",
    "    # 取除label外的其他列\n",
    "    train_data = train_data.iloc[:, :-1]\n",
    "    val_data = val_data.iloc[:, :-1]\n",
    "    test_data = test_data.iloc[:, :-1]\n",
    "#     print('train_data',train_data.shape)\n",
    "#     print('train_label',train_label.shape)\n",
    "    print('数据划分完成')\n",
    "    return train_data, val_data, test_data,train_label,val_label,test_label, feature_category_num_dict\n",
    "\n",
    "# # 自定义数据加载器\n",
    "# class DynamicDataLoader(DataLoader):\n",
    "#     def __init__(self, dataset, batch_size):\n",
    "#         super().__init__(dataset, batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         for batch in super().__iter__():\n",
    "#             yield batch\n",
    "#             # yield [{key: sample[key] for key in sample} for sample in batch]\n",
    "\n",
    "# 自动评估阈值，计算ACC 、 Precision 等评估指标\n",
    "def evaluate(y_true, y_pred, digits=4, cutoff='auto'):\n",
    "    '''\n",
    "    Args:\n",
    "        y_true: list, labels, y_pred: list, predictions, digits: The number of decimals to use when rounding the number. Default is 4（保留小数后几位）\n",
    "        cutoff: float or 'auto'\n",
    "    Returns:\n",
    "        evaluation: dict\n",
    "    '''\n",
    "    # 根据预测概率值y_pred计算最佳的切分阈值\n",
    "    if cutoff == 'auto':\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        youden = tpr-fpr\n",
    "        cutoff = thresholds[np.argmax(youden)]\n",
    "    y_pred_t = [1 if i > cutoff else 0 for i in y_pred]\n",
    "\n",
    "    evaluation = OrderedDict()\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_t).ravel()\n",
    "    evaluation['auc'] = round(roc_auc_score(y_true, y_pred), digits)\n",
    "    evaluation['acc'] = round(accuracy_score(y_true, y_pred_t), digits)\n",
    "    evaluation['recall'] = round(recall_score(y_true, y_pred_t), digits)\n",
    "    evaluation['precision'] = round(precision_score(y_true, y_pred_t, zero_division=1), digits)\n",
    "    evaluation['specificity'] = round(tn / (tn + fp), digits)\n",
    "    evaluation['F1'] = round(f1_score(y_true, y_pred_t), digits)\n",
    "    evaluation['cutoff'] = cutoff\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "# 选择分类器\n",
    "def classifier_chose(classifier_name):\n",
    "    clf = None\n",
    "    if classifier_name =='SVM':\n",
    "        clf = svm.SVC(C=1.0, kernel='rbf',  decision_function_shape='ovr', probability=True)\n",
    "    elif classifier_name =='RF':\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    else:\n",
    "        print('分类器选择错误，仅 SVM / RF')\n",
    "    return clf\n",
    "    \n",
    "# 标签值映射到从0开始的整数上\n",
    "def map_labels_to_int(labels):\n",
    "    label_map = {}  # 创建空字典用于存储标签值到整数的映射关系\n",
    "    mapped_labels = []  # 存储映射后的整数标签列表\n",
    "    count = 0  # 用于生成从 0 开始的整数\n",
    "\n",
    "    for label in labels:\n",
    "        if label not in label_map:\n",
    "            label_map[label] = count\n",
    "            count += 1\n",
    "        mapped_labels.append(label_map[label])\n",
    "    mapped_labels_series = pd.Series(mapped_labels)\n",
    "    return mapped_labels_series, label_map  # 映射后的整数标签列表，标签映射关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79684da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "<class 'pandas.core.frame.DataFrame'> (13696, 30)\n",
      "数据划分完成\n",
      "i=:1\n",
      "||--------当前轮次: 0 结束时间： 2024-03-18 01:17:42.655166 -------------\n",
      "i=:2\n",
      "||--------当前轮次: 1 结束时间： 2024-03-18 01:20:53.181453 -------------\n",
      "i=:3\n",
      "||--------当前轮次: 2 结束时间： 2024-03-18 01:24:02.695522 -------------\n",
      "i=:4\n",
      "||--------当前轮次: 3 结束时间： 2024-03-18 01:27:11.919004 -------------\n",
      "i=:5\n",
      "||--------当前轮次: 4 结束时间： 2024-03-18 01:30:21.298647 -------------\n",
      "Test AUC: 0.5732,ACC:0.5969,F1:0.4539000000000001,Precision:0.5201,Recall:0.40259999999999996\n",
      "结果已输出\n",
      "||--------当前时间窗 0101_0131 结束时间： 2024-03-18 01:30:21.315968 -------------\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "<class 'pandas.core.frame.DataFrame'> (12096, 21)\n",
      "数据划分完成\n",
      "i=:1\n",
      "||--------当前轮次: 0 结束时间： 2024-03-18 01:32:52.026886 -------------\n",
      "i=:2\n",
      "||--------当前轮次: 1 结束时间： 2024-03-18 01:35:08.521251 -------------\n",
      "i=:3\n",
      "||--------当前轮次: 2 结束时间： 2024-03-18 01:37:25.811890 -------------\n",
      "i=:4\n",
      "||--------当前轮次: 3 结束时间： 2024-03-18 01:39:42.601735 -------------\n",
      "i=:5\n",
      "||--------当前轮次: 4 结束时间： 2024-03-18 01:41:59.252315 -------------\n",
      "Test AUC: 0.5413,ACC:0.5308,F1:0.5538,Precision:0.6208,Recall:0.4998\n",
      "结果已输出\n",
      "||--------当前时间窗 0115_0215 结束时间： 2024-03-18 01:41:59.267826 -------------\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "<class 'pandas.core.frame.DataFrame'> (8749, 27)\n",
      "数据划分完成\n",
      "i=:1\n",
      "||--------当前轮次: 0 结束时间： 2024-03-18 01:43:35.629218 -------------\n",
      "i=:2\n",
      "||--------当前轮次: 1 结束时间： 2024-03-18 01:44:49.207337 -------------\n",
      "i=:3\n",
      "||--------当前轮次: 2 结束时间： 2024-03-18 01:46:02.754901 -------------\n",
      "i=:4\n",
      "||--------当前轮次: 3 结束时间： 2024-03-18 01:47:16.962352 -------------\n",
      "i=:5\n",
      "||--------当前轮次: 4 结束时间： 2024-03-18 01:48:30.710384 -------------\n",
      "Test AUC: 0.43026,ACC:0.4544,F1:0.624,Precision:0.45380000000000004,Recall:0.9985000000000002\n",
      "结果已输出\n",
      "||--------当前时间窗 0201_0230 结束时间： 2024-03-18 01:48:30.724726 -------------\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "<class 'pandas.core.frame.DataFrame'> (16280, 28)\n",
      "数据划分完成\n",
      "i=:1\n",
      "||--------当前轮次: 0 结束时间： 2024-03-18 01:53:31.078204 -------------\n",
      "i=:2\n",
      "||--------当前轮次: 1 结束时间： 2024-03-18 01:57:59.577538 -------------\n",
      "i=:3\n",
      "||--------当前轮次: 2 结束时间： 2024-03-18 02:02:24.616546 -------------\n",
      "i=:4\n",
      "||--------当前轮次: 3 结束时间： 2024-03-18 02:06:49.937252 -------------\n",
      "i=:5\n",
      "||--------当前轮次: 4 结束时间： 2024-03-18 02:11:15.198106 -------------\n",
      "Test AUC: 0.5863600000000001,ACC:0.5652,F1:0.591,Precision:0.5345,Recall:0.6609\n",
      "结果已输出\n",
      "||--------当前时间窗 1101_1130 结束时间： 2024-03-18 02:11:15.215215 -------------\n",
      "划分文件已存在，不再进行数据划分\n",
      "数据预处理结束\n",
      "<class 'pandas.core.frame.DataFrame'> (16304, 23)\n",
      "数据划分完成\n",
      "i=:1\n",
      "||--------当前轮次: 0 结束时间： 2024-03-18 02:15:56.145866 -------------\n",
      "i=:2\n",
      "||--------当前轮次: 1 结束时间： 2024-03-18 02:20:04.065611 -------------\n",
      "i=:3\n",
      "||--------当前轮次: 2 结束时间： 2024-03-18 02:24:10.537599 -------------\n",
      "i=:4\n"
     ]
    }
   ],
   "source": [
    "# 模型运行\n",
    "# 2个分类器与7个时间窗\n",
    "for data_classifier in data_classifier_list:\n",
    "    for data_time_windows in data_time_windows_list:\n",
    "        path = './Dataset/' + data_time_windows + '_user_pay_pred_feature_deal.csv'\n",
    "        dataset_spilt_path = './Dataset/' + data_time_windows + '_user_pay_pred_feature_spilt_BiLSTM.csv'\n",
    "    #     output_weight_result_path = './Dataset/' + data_time_windows + '_user_pay_pred_result_weight.csv'\n",
    "        data_feature_continue_discrete_namelist_path = './Dataset/maoer_timewindows_continue_discrete_feature_column.csv'    # 连续与离散划分表\n",
    "        # 获取时间窗内连续与离散特征名的列表\n",
    "        user_history_pay_QOE_continue_column, user_history_pay_CHONGHE_continue_column, \\\n",
    "        user_history_pay_FUFEI_continue_column, user_history_pay_QOE_discrete_column,\\\n",
    "        user_history_pay_CHONGHE_discrete_column, user_history_pay_FUFEI_discrete_column = get_continue_discrete_feature_namelist(data_time_windows, data_feature_continue_discrete_namelist_path)\n",
    "        user_feature_continue_column = []\n",
    "        user_feature_discrete_column = []\n",
    "        # total continue feature\n",
    "        total_continue_feature = user_history_pay_CHONGHE_continue_column\n",
    "        total_discrete_feature = user_history_pay_CHONGHE_discrete_column\n",
    "        total_discrete_feature_add_D = user_feature_discrete_column+user_history_pay_QOE_discrete_column+user_history_pay_CHONGHE_discrete_column+user_history_pay_FUFEI_discrete_column\n",
    "        total_discrete_feature_add_D.append('user_in_drama_is_pay_for_drama_in_next_time')\n",
    "        D = ['user_in_drama_is_pay_for_drama_in_next_time']\n",
    "        tensor_dict_idx = ['pay_QOE_continue','pay_QOE_discrete','pay_CHONGHE_continue','pay_CHONGHE_discrete','pay_FUFEI_continue','pay_FUFEI_discrete','target_QOE_continue','target_QOE_discrete','target_CHONGHE_continue','target_CHONGHE_discrete','target_FUFEI_continue','target_FUFEI_discrete']\n",
    "        # print(len(user_history_pay_QOE_continue_column),len(user_history_pay_CHONGHE_continue_column),len(user_history_pay_FUFEI_continue_column))\n",
    "        # 形成对应需要的特征名称列表\n",
    "        feature_column_dict = {\n",
    "            'total_continue_feature': total_continue_feature,\n",
    "            'total_discrete_feature': total_discrete_feature,\n",
    "            'D':D\n",
    "        }\n",
    "        # 创建一个空的DataFrame来存储结果\n",
    "        test_auc_df = pd.DataFrame(columns=['时间','model','运行位置','Type','dataset','train_ratio','feature_embedding','batchSize','lr','max_history_len','实验数', '测试集总损失', 'AUC','ACC','F1','Precision','Recall'])\n",
    "        \n",
    "        # 获取数据\n",
    "        train_data, val_data, test_data,\\\n",
    "        train_label,val_label,test_label, feature_category_num_dict = data_input(data_time_windows, path, dataset_spilt_path,\n",
    "                                                                         train_ratio, val_ratio, test_ratio, \n",
    "                                                                         feature_column_dict)    \n",
    "        # 将验证数据集val_data加入train_data\n",
    "        train_data = pd.concat([train_data, val_data], axis=0)\n",
    "        train_label = pd.concat([train_label, val_label], axis=0)\n",
    "#         train_data = train_data+val_data\n",
    "#         # 五折交叉\n",
    "#         kf = KFold(n_splits=10,shuffle=True)  # 初始化KFold\n",
    "#         train_files = []   # 存放10折的训练集划分\n",
    "#         test_files = []     # # 存放10折的测试集集划分\n",
    "        total_auc_test = 0.0\n",
    "        total_acc_test  = 0\n",
    "        total_f1_test = 0\n",
    "        total_precision_test = 0\n",
    "        total_recall_test = 0\n",
    "        test_time = 0\n",
    "        test_label_len = 0\n",
    "        \n",
    "        for i in range(5):\n",
    "            print(f\"i=:{i+1}\")\n",
    "            n = i\n",
    "            \n",
    "            # SVM\n",
    "            clf = classifier_chose(data_classifier)\n",
    "            clf.fit(train_data, train_label)\n",
    "            y_prob = clf.predict_proba(test_data)\n",
    "            y_prob = y_prob[:, 0]\n",
    "            evaluation = evaluate(test_label, y_prob)\n",
    "            total_acc_test += evaluation['acc']\n",
    "            total_f1_test += evaluation['F1']\n",
    "            total_recall_test += evaluation['recall']\n",
    "            total_precision_test += evaluation['precision']\n",
    "            total_auc_test += evaluation['auc']\n",
    "            test_time += 1\n",
    "            print('||--------当前轮次:',i,'结束时间：',datetime.datetime.now(),'-------------')\n",
    "\n",
    "        # 平均损失\n",
    "#             average_loss_test = total_loss_test / len(test_label_len)\n",
    "        average_auc_test = total_auc_test / 5\n",
    "        average_acc_test = total_acc_test / 5\n",
    "        average_f1_test = total_f1_test / 5\n",
    "        average_precision_test = total_precision_test / 5\n",
    "        average_recall_test = total_recall_test / 5\n",
    "        print(\n",
    "            f\"Test AUC: {average_auc_test},ACC:{average_acc_test},F1:{average_f1_test},Precision:{average_precision_test},Recall:{average_recall_test}\")\n",
    "\n",
    "        # 将本次训练的结果添加到DataFrame中\n",
    "        test_auc_df = test_auc_df.append({'时间':datetime.datetime.now(),'model':'MachineLearning-SVM','运行位置':'CPU','Type':'Abb_QOE&FUFEI','dataset':data_time_windows,'train_ratio':train_ratio,'feature_embedding':0,'batchSize':batch_size,'lr':0,'max_history_len':0,'实验数': i + 1,'测试集总损失': 0, 'AUC': average_auc_test,'ACC': average_acc_test,'F1': average_f1_test,'Precision': average_precision_test,'Recall': average_recall_test}, ignore_index=True)\n",
    "        # 将结果保存到CSV文件中\n",
    "        with open('./Dataset/maoerDL_result_maoer_pay_pred_model3_1.csv', 'a') as f:\n",
    "            test_auc_df.to_csv(f, index=False)\n",
    "    #     with open('./Dataset/maoerDL_result_maoer_pay_pred_weight_model3_1.csv', 'a') as f:\n",
    "    #         test_weight_df.to_csv(f, index=False)\n",
    "\n",
    "        print('结果已输出')\n",
    "        print('||--------当前时间窗',data_time_windows,'结束时间：',datetime.datetime.now(),'-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d89bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bb7c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
